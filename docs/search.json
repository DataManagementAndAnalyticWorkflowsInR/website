[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ID529: Data Management and Analytic Workflows in R",
    "section": "",
    "text": "Details:\n\nFind the course on my.harvard.edu\nCourse Hours: 1:30-5:30 PM\nClassroom: Our classroom will be Kresge G2.\nCourse Dates:\n\nMonday January 13th - Friday January 17th,\nTuesday January 21st - Friday January 24th, 2023\n\nOffice Hours: 11:30 AM – 12:30 PM on Wednesday January 15th, Thursday January 23rd\nLimit 60 students, priority for Population Health Science (PHS) students\n\n\n\n\nData Management and Analytic Workflows in R will introduce students to R programming and modern data management and analysis workflows applied to examples from population health science. Throughout, we will emphasize reproducibility, open science, data visualization, and dynamic document generation. Specific skills learned will include the use of the RStudio integrated development environment, tidy data management practices/workflows, how to get help in programming, and how to use GitHub to track changes in code, disseminate professional work, and integrate feedback. Coursework will consist of lectures, in-class group work, homework, peer assessment, and time for discussion. This course complements graduate-level courses in statistics and quantitative research methods by helping students develop practical skills for conducting independent research incorporating modern data science principles. Students completing this course will have a solid foundation enabling them to handle complex data management tasks and data communication skills for research and professional work.\n\n\n\n\nStudents were very happy with how the class went last winter! Here are some student testionials, shared with students’ permission:\n\n\n\n“I really enjoyed the whole learning experience in this course.”\n\n\n\n\n“Very informative and useful. As a someone who has his first exposure to R, I learned a lot.”\n\n\n\n\n“The teaching team were very supportive and very promptly acted on feedback.”\n\n\n\n\n“It was wonderful! Totally friendly to R beginners. And got a lot positive feedback and encouragement from the teaching team! Shout out to their efforts!”\n\n\n\n\n“Slides that are managed so well! Unparellel instructional team! You are so friendly and patient! I really love that homeworks are managed through Github!”\n\n\n\n\n“I loved this class!! So much was covered but it didn’t feel overwhelming at the same time because the expectation was that we all came in with different levels of experience with R and that these are resources we are introduced to and can always come back to.”\n\n\n\n\nThis course has been excellent! It was exactly what I was looking for - I wanted to kind of catch up to my peers who have had experience in R and learn best practices. R feels a lot less intimidating now, and I know where to look for help. Thank you!\n\n\n\n\nI think this course was great. I am happy that all levels of R were welcome in the course. I felt like I could just do beginner level work and still get a good grade.\n\n\n\n\nExtremely well. I think it will be the most recommended course for whoever wants to gain skills in data management and analysis\n\n\n\nAnd lots more 🙂\n\n\n\n\n\n\nChristian Testa 2nd Year PhD Student Department of Biostatistics  ctesta@hsph.harvard.edu  GitHub   Website   Mastodon   Google Scholar\n\n\n\n\nDean Marengi 4th Year PhD Student Department of Environmental Health  dean_marengi@g.harvard.edu   Google Scholar\n\n\n\n\nJarvis Chen Senior Lecturer Department of Social and Behavioral Sciences  jarvis@hsph.harvard.edu   https://www.hsph.harvard.edu/profile/jarvischen/   Google Scholar\n\n\n\n\n\n\n\nAmanda Hernandez  was an amazing masters student in Environmental Health who helped us develop a lot of material and helped teach the course in Winter Session 2023.\n\n\n\n\n\n\nClick here to go to the syllabus.\n\n\n\n\n\n\nDay 1 — Monday January 13th, 2024\nDay 2 — Tuesday January 14th, 2024\nDay 3 — Wednesday January 15th, 2024\nDay 4 — Thursday January 16th, 2024\nDay 5 — Friday January 17th, 2024\n(MLK Jr. Day on Monday January 15th)\nDay 6 — Tuesday January 21st, 2024\nDay 7 — Wednesday January 22nd, 2024\nDay 8 — Thursday January 23rd, 2024\nDay 9 — Friday January 24th, 2024\n\n\n&lt;div id=\"quarto-navigation-envelope\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden\" data-render-id=\"quarto-int-sidebar-title\"&gt;ID529: Data Management and Analytic Workflows in R&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar-title\"&gt;ID529: Data Management and Analytic Workflows in R&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Home\"&gt;Home&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/index.html\"&gt;/index.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Syllabus\"&gt;Syllabus&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/about.html\"&gt;/about.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Curriculum\"&gt;Curriculum&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 1\"&gt;Day 1&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day1.html\"&gt;/day1.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 2\"&gt;Day 2&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day2.html\"&gt;/day2.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 3\"&gt;Day 3&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day3.html\"&gt;/day3.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 4\"&gt;Day 4&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day4.html\"&gt;/day4.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 5\"&gt;Day 5&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day5.html\"&gt;/day5.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 6\"&gt;Day 6&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day6.html\"&gt;/day6.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 7\"&gt;Day 7&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day7.html\"&gt;/day7.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 8\"&gt;Day 8&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day8.html\"&gt;/day8.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 9\"&gt;Day 9&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day9.html\"&gt;/day9.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Last Years&#39; Content\"&gt;Last Years’ Content&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day1.html\"&gt;/wi24/day1.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day2.html\"&gt;/wi24/day2.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day3.html\"&gt;/wi24/day3.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day4.html\"&gt;/wi24/day4.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day5.html\"&gt;/wi24/day5.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day6.html\"&gt;/wi24/day6.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day7.html\"&gt;/wi24/day7.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day8.html\"&gt;/wi24/day8.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day9.html\"&gt;/wi24/day9.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Content from 2023\"&gt;Content from 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 1 — Monday January 9, 2023\"&gt;Day 1 — Monday January 9, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day1.html\"&gt;/wi23/day1.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 2 — Tuesday January 10, 2023\"&gt;Day 2 — Tuesday January 10, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day2.html\"&gt;/wi23/day2.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 3 — Wednesday January 11, 2023\"&gt;Day 3 — Wednesday January 11, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day3.html\"&gt;/wi23/day3.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 4 — Thursday January 12, 2023\"&gt;Day 4 — Thursday January 12, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day4.html\"&gt;/wi23/day4.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 5 — Friday January 13, 2023\"&gt;Day 5 — Friday January 13, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day5.html\"&gt;/wi23/day5.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 6 — Tuesday January 17, 2023\"&gt;Day 6 — Tuesday January 17, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day6.html\"&gt;/wi23/day6.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 7 — Wednesday January 18, 2023\"&gt;Day 7 — Wednesday January 18, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day7.html\"&gt;/wi23/day7.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 8 — Thursday January 19, 2023\"&gt;Day 8 — Thursday January 19, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day8.html\"&gt;/wi23/day8.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 9 — Friday January 20, 2023\"&gt;Day 9 — Friday January 20, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day9.html\"&gt;/wi23/day9.html&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div id=\"quarto-meta-markdown\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden\" data-render-id=\"quarto-metatitle\"&gt;ID529: Data Management and Analytic Workflows in R&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercardtitle\"&gt;ID529: Data Management and Analytic Workflows in R&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardtitle\"&gt;ID529: Data Management and Analytic Workflows in R&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-metasitename\"&gt;ID529: Data Management and Analytic Workflows in R&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercarddesc\"&gt;&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardddesc\"&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;/section&gt;\n\n&lt;/main&gt; &lt;!-- /main --&gt;\n&lt;script id = \"quarto-html-after-body\" type=\"application/javascript\"&gt;\nwindow.document.addEventListener(\"DOMContentLoaded\", function (event) {\n  const toggleBodyColorMode = (bsSheetEl) =&gt; {\n    const mode = bsSheetEl.getAttribute(\"data-mode\");\n    const bodyEl = window.document.querySelector(\"body\");\n    if (mode === \"dark\") {\n      bodyEl.classList.add(\"quarto-dark\");\n      bodyEl.classList.remove(\"quarto-light\");\n    } else {\n      bodyEl.classList.add(\"quarto-light\");\n      bodyEl.classList.remove(\"quarto-dark\");\n    }\n  }\n  const toggleBodyColorPrimary = () =&gt; {\n    const bsSheetEl = window.document.querySelector(\"link#quarto-bootstrap\");\n    if (bsSheetEl) {\n      toggleBodyColorMode(bsSheetEl);\n    }\n  }\n  toggleBodyColorPrimary();  \n  const icon = \"\";\n  const anchorJS = new window.AnchorJS();\n  anchorJS.options = {\n    placement: 'right',\n    icon: icon\n  };\n  anchorJS.add('.anchored');\n  const isCodeAnnotation = (el) =&gt; {\n    for (const clz of el.classList) {\n      if (clz.startsWith('code-annotation-')) {                     \n        return true;\n      }\n    }\n    return false;\n  }\n  const clipboard = new window.ClipboardJS('.code-copy-button', {\n    text: function(trigger) {\n      const codeEl = trigger.previousElementSibling.cloneNode(true);\n      for (const childEl of codeEl.children) {\n        if (isCodeAnnotation(childEl)) {\n          childEl.remove();\n        }\n      }\n      return codeEl.innerText;\n    }\n  });\n  clipboard.on('success', function(e) {\n    // button target\n    const button = e.trigger;\n    // don't keep focus\n    button.blur();\n    // flash \"checked\"\n    button.classList.add('code-copy-button-checked');\n    var currentTitle = button.getAttribute(\"title\");\n    button.setAttribute(\"title\", \"Copied!\");\n    let tooltip;\n    if (window.bootstrap) {\n      button.setAttribute(\"data-bs-toggle\", \"tooltip\");\n      button.setAttribute(\"data-bs-placement\", \"left\");\n      button.setAttribute(\"data-bs-title\", \"Copied!\");\n      tooltip = new bootstrap.Tooltip(button, \n        { trigger: \"manual\", \n          customClass: \"code-copy-button-tooltip\",\n          offset: [0, -8]});\n      tooltip.show();    \n    }\n    setTimeout(function() {\n      if (tooltip) {\n        tooltip.hide();\n        button.removeAttribute(\"data-bs-title\");\n        button.removeAttribute(\"data-bs-toggle\");\n        button.removeAttribute(\"data-bs-placement\");\n      }\n      button.setAttribute(\"title\", currentTitle);\n      button.classList.remove('code-copy-button-checked');\n    }, 1000);\n    // clear code selection\n    e.clearSelection();\n  });\n  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {\n    const config = {\n      allowHTML: true,\n      maxWidth: 500,\n      delay: 100,\n      arrow: false,\n      appendTo: function(el) {\n          return el.parentElement;\n      },\n      interactive: true,\n      interactiveBorder: 10,\n      theme: 'quarto',\n      placement: 'bottom-start',\n    };\n    if (contentFn) {\n      config.content = contentFn;\n    }\n    if (onTriggerFn) {\n      config.onTrigger = onTriggerFn;\n    }\n    if (onUntriggerFn) {\n      config.onUntrigger = onUntriggerFn;\n    }\n    window.tippy(el, config); \n  }\n  const noterefs = window.document.querySelectorAll('a[role=\"doc-noteref\"]');\n  for (var i=0; i&lt;noterefs.length; i++) {\n    const ref = noterefs[i];\n    tippyHover(ref, function() {\n      // use id or data attribute instead here\n      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');\n      try { href = new URL(href).hash; } catch {}\n      const id = href.replace(/^#\\/?/, \"\");\n      const note = window.document.getElementById(id);\n      return note.innerHTML;\n    });\n  }\n  const xrefs = window.document.querySelectorAll('a.quarto-xref');\n  const processXRef = (id, note) =&gt; {\n    // Strip column container classes\n    const stripColumnClz = (el) =&gt; {\n      el.classList.remove(\"page-full\", \"page-columns\");\n      if (el.children) {\n        for (const child of el.children) {\n          stripColumnClz(child);\n        }\n      }\n    }\n    stripColumnClz(note)\n    if (id === null || id.startsWith('sec-')) {\n      // Special case sections, only their first couple elements\n      const container = document.createElement(\"div\");\n      if (note.children && note.children.length &gt; 2) {\n        container.appendChild(note.children[0].cloneNode(true));\n        for (let i = 1; i &lt; note.children.length; i++) {\n          const child = note.children[i];\n          if (child.tagName === \"P\" && child.innerText === \"\") {\n            continue;\n          } else {\n            container.appendChild(child.cloneNode(true));\n            break;\n          }\n        }\n        if (window.Quarto?.typesetMath) {\n          window.Quarto.typesetMath(container);\n        }\n        return container.innerHTML\n      } else {\n        if (window.Quarto?.typesetMath) {\n          window.Quarto.typesetMath(note);\n        }\n        return note.innerHTML;\n      }\n    } else {\n      // Remove any anchor links if they are present\n      const anchorLink = note.querySelector('a.anchorjs-link');\n      if (anchorLink) {\n        anchorLink.remove();\n      }\n      if (window.Quarto?.typesetMath) {\n        window.Quarto.typesetMath(note);\n      }\n      // TODO in 1.5, we should make sure this works without a callout special case\n      if (note.classList.contains(\"callout\")) {\n        return note.outerHTML;\n      } else {\n        return note.innerHTML;\n      }\n    }\n  }\n  for (var i=0; i&lt;xrefs.length; i++) {\n    const xref = xrefs[i];\n    tippyHover(xref, undefined, function(instance) {\n      instance.disable();\n      let url = xref.getAttribute('href');\n      let hash = undefined; \n      if (url.startsWith('#')) {\n        hash = url;\n      } else {\n        try { hash = new URL(url).hash; } catch {}\n      }\n      if (hash) {\n        const id = hash.replace(/^#\\/?/, \"\");\n        const note = window.document.getElementById(id);\n        if (note !== null) {\n          try {\n            const html = processXRef(id, note.cloneNode(true));\n            instance.setContent(html);\n          } finally {\n            instance.enable();\n            instance.show();\n          }\n        } else {\n          // See if we can fetch this\n          fetch(url.split('#')[0])\n          .then(res =&gt; res.text())\n          .then(html =&gt; {\n            const parser = new DOMParser();\n            const htmlDoc = parser.parseFromString(html, \"text/html\");\n            const note = htmlDoc.getElementById(id);\n            if (note !== null) {\n              const html = processXRef(id, note);\n              instance.setContent(html);\n            } \n          }).finally(() =&gt; {\n            instance.enable();\n            instance.show();\n          });\n        }\n      } else {\n        // See if we can fetch a full url (with no hash to target)\n        // This is a special case and we should probably do some content thinning / targeting\n        fetch(url)\n        .then(res =&gt; res.text())\n        .then(html =&gt; {\n          const parser = new DOMParser();\n          const htmlDoc = parser.parseFromString(html, \"text/html\");\n          const note = htmlDoc.querySelector('main.content');\n          if (note !== null) {\n            // This should only happen for chapter cross references\n            // (since there is no id in the URL)\n            // remove the first header\n            if (note.children.length &gt; 0 && note.children[0].tagName === \"HEADER\") {\n              note.children[0].remove();\n            }\n            const html = processXRef(null, note);\n            instance.setContent(html);\n          } \n        }).finally(() =&gt; {\n          instance.enable();\n          instance.show();\n        });\n      }\n    }, function(instance) {\n    });\n  }\n      let selectedAnnoteEl;\n      const selectorForAnnotation = ( cell, annotation) =&gt; {\n        let cellAttr = 'data-code-cell=\"' + cell + '\"';\n        let lineAttr = 'data-code-annotation=\"' +  annotation + '\"';\n        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';\n        return selector;\n      }\n      const selectCodeLines = (annoteEl) =&gt; {\n        const doc = window.document;\n        const targetCell = annoteEl.getAttribute(\"data-target-cell\");\n        const targetAnnotation = annoteEl.getAttribute(\"data-target-annotation\");\n        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));\n        const lines = annoteSpan.getAttribute(\"data-code-lines\").split(\",\");\n        const lineIds = lines.map((line) =&gt; {\n          return targetCell + \"-\" + line;\n        })\n        let top = null;\n        let height = null;\n        let parent = null;\n        if (lineIds.length &gt; 0) {\n            //compute the position of the single el (top and bottom and make a div)\n            const el = window.document.getElementById(lineIds[0]);\n            top = el.offsetTop;\n            height = el.offsetHeight;\n            parent = el.parentElement.parentElement;\n          if (lineIds.length &gt; 1) {\n            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);\n            const bottom = lastEl.offsetTop + lastEl.offsetHeight;\n            height = bottom - top;\n          }\n          if (top !== null && height !== null && parent !== null) {\n            // cook up a div (if necessary) and position it \n            let div = window.document.getElementById(\"code-annotation-line-highlight\");\n            if (div === null) {\n              div = window.document.createElement(\"div\");\n              div.setAttribute(\"id\", \"code-annotation-line-highlight\");\n              div.style.position = 'absolute';\n              parent.appendChild(div);\n            }\n            div.style.top = top - 2 + \"px\";\n            div.style.height = height + 4 + \"px\";\n            div.style.left = 0;\n            let gutterDiv = window.document.getElementById(\"code-annotation-line-highlight-gutter\");\n            if (gutterDiv === null) {\n              gutterDiv = window.document.createElement(\"div\");\n              gutterDiv.setAttribute(\"id\", \"code-annotation-line-highlight-gutter\");\n              gutterDiv.style.position = 'absolute';\n              const codeCell = window.document.getElementById(targetCell);\n              const gutter = codeCell.querySelector('.code-annotation-gutter');\n              gutter.appendChild(gutterDiv);\n            }\n            gutterDiv.style.top = top - 2 + \"px\";\n            gutterDiv.style.height = height + 4 + \"px\";\n          }\n          selectedAnnoteEl = annoteEl;\n        }\n      };\n      const unselectCodeLines = () =&gt; {\n        const elementsIds = [\"code-annotation-line-highlight\", \"code-annotation-line-highlight-gutter\"];\n        elementsIds.forEach((elId) =&gt; {\n          const div = window.document.getElementById(elId);\n          if (div) {\n            div.remove();\n          }\n        });\n        selectedAnnoteEl = undefined;\n      };\n        // Handle positioning of the toggle\n    window.addEventListener(\n      \"resize\",\n      throttle(() =&gt; {\n        elRect = undefined;\n        if (selectedAnnoteEl) {\n          selectCodeLines(selectedAnnoteEl);\n        }\n      }, 10)\n    );\n    function throttle(fn, ms) {\n    let throttle = false;\n    let timer;\n      return (...args) =&gt; {\n        if(!throttle) { // first call gets through\n            fn.apply(this, args);\n            throttle = true;\n        } else { // all the others get throttled\n            if(timer) clearTimeout(timer); // cancel #2\n            timer = setTimeout(() =&gt; {\n              fn.apply(this, args);\n              timer = throttle = false;\n            }, ms);\n        }\n      };\n    }\n      // Attach click handler to the DT\n      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');\n      for (const annoteDlNode of annoteDls) {\n        annoteDlNode.addEventListener('click', (event) =&gt; {\n          const clickedEl = event.target;\n          if (clickedEl !== selectedAnnoteEl) {\n            unselectCodeLines();\n            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');\n            if (activeEl) {\n              activeEl.classList.remove('code-annotation-active');\n            }\n            selectCodeLines(clickedEl);\n            clickedEl.classList.add('code-annotation-active');\n          } else {\n            // Unselect the line\n            unselectCodeLines();\n            clickedEl.classList.remove('code-annotation-active');\n          }\n        });\n      }\n  const findCites = (el) =&gt; {\n    const parentEl = el.parentElement;\n    if (parentEl) {\n      const cites = parentEl.dataset.cites;\n      if (cites) {\n        return {\n          el,\n          cites: cites.split(' ')\n        };\n      } else {\n        return findCites(el.parentElement)\n      }\n    } else {\n      return undefined;\n    }\n  };\n  var bibliorefs = window.document.querySelectorAll('a[role=\"doc-biblioref\"]');\n  for (var i=0; i&lt;bibliorefs.length; i++) {\n    const ref = bibliorefs[i];\n    const citeInfo = findCites(ref);\n    if (citeInfo) {\n      tippyHover(citeInfo.el, function() {\n        var popup = window.document.createElement('div');\n        citeInfo.cites.forEach(function(cite) {\n          var citeDiv = window.document.createElement('div');\n          citeDiv.classList.add('hanging-indent');\n          citeDiv.classList.add('csl-entry');\n          var biblioDiv = window.document.getElementById('ref-' + cite);\n          if (biblioDiv) {\n            citeDiv.innerHTML = biblioDiv.innerHTML;\n          }\n          popup.appendChild(citeDiv);\n        });\n        return popup.innerHTML;\n      });\n    }\n  }\n});\n&lt;/script&gt;\n&lt;/div&gt; &lt;!-- /content --&gt;\n\n&lt;/body&gt;\n\n&lt;/html&gt;"
  },
  {
    "objectID": "day8.html",
    "href": "day8.html",
    "title": "Day 8",
    "section": "",
    "text": "Outline:\n\nPrinciples for Data Analysis\nFunctional Programming\nCOVID OSHA Example\nStudent Choice\nAge Standardization\nBaby Boom Visualization\nR4DS Giveaway\n\n\n\n\n\n\n\nLecture 1: Principles for data analysis\n\n\n\n\n\n\n\n\n\n\n link to view slides fullscreen    link to PDF slides \n\n\n\n\n\n\nLecture 2: Functional Programming\n\n\n\n\n\nlink to functional programming demo script\n\n\n\n\n\n\n\n\n\nCOVID OSHA Project Example\n\n\n\n\n\nLink to Project: https://github.com/ctesta01/covid_osha\n\n\n\n\n\n\n\n\n\nStudent Choice\n\n\n\n\n\nlink to script that goes over requested topics\n\n\n\n\n\n\n\n\n\nKieran Healy’s Baby Boom Data Visualization Poster\n\n\n\n\n\nTogether we took a look at this poster from Kieran Healy and the code from the repository.\nThe example was instructive on a few points:\n\nWe thought it was neat how Kieran used the legend to create a title.\nWe saw how he used cowplot::plot_grid and/or the patchwork package to construct the graphic with multiple panels.\nSeeing how png() and pdf() can be used, similar to ggsave(), to save plots was useful — especially for non-ggplot2 visualizations.\nWe had to do a little bit of debugging, figuring out that we needed to use scale_x_yearmonth() instead of scale_x_date() and we figured that out by 1) reading the error we got in R, and 2) checking what the class/type of the column mapped onto the x aesthetic was.\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording"
  },
  {
    "objectID": "day8.html#video-recording",
    "href": "day8.html#video-recording",
    "title": "Day 8 — Thursday, January 19th, 2022",
    "section": "Video Recording",
    "text": "Video Recording\n\n\nApologies the lecture recording didn’t capture the first lecture of the day."
  },
  {
    "objectID": "day8.html#resources",
    "href": "day8.html#resources",
    "title": "Day 8 — Thursday, January 19th, 2022",
    "section": "Resources",
    "text": "Resources\n  link to PDF slides   link to daily google doc  \n\nLecture 1: Principles for data analysis\n\n\n link to view slides fullscreen    link to PDF slides \n\n\nLecture 2: Functional Programming\n link to functional_programming.R script \n\n\nLecture 3: dplyr (student choice)\n dplyr_demo.R script \n\n\nLecture 4: Growing as a programmer\n\n\n link to view slides fullscreen   link to PDF slides"
  },
  {
    "objectID": "day9.html",
    "href": "day9.html",
    "title": "Day 9",
    "section": "",
    "text": "Outline:\n\nReflections on Final Projects\nGoals for Near Future R Programming (Discussion)\nVery Important Material\nR Project Examples\nGrowing as a Programmer\nCourse Evaluation Survey(s)\n\n\n\n\n\n\n\nReflections on Final Projects\n\n\n\n\n\n\nTo be determined!\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nVery Important Material\n\n\n\n\n\n(posted after class)\n\n\n\n\n\n\n\n\n\nR Project Examples\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nGrowing as a Programmer\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nVideo Recording from 2023"
  },
  {
    "objectID": "day9.html#video-recording",
    "href": "day9.html#video-recording",
    "title": "Day 9 — Friday, January 19th, 2022",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "day9.html#student-presentations",
    "href": "day9.html#student-presentations",
    "title": "Day 9 — Friday, January 19th, 2022",
    "section": "Student Presentations",
    "text": "Student Presentations\n\nClean Code and Code Hygeine\n\n\n\n\nLecture 4: Growing as a programmer\n\n\n link to view slides fullscreen   link to PDF slides\n\n\nCode Commenting and Documentation\n\n\n\n\nData Dictionaries\n\n\n\n\nData Visualization (Group 1)\n\n\n\n\nData Visualization (Group 2)\n\n\n\n\nPresenting Model Results\n\n\n\n\nGeographic Maps"
  },
  {
    "objectID": "day9.html#final-lecture-recap",
    "href": "day9.html#final-lecture-recap",
    "title": "Day 9 — Friday, January 19th, 2022",
    "section": "Final lecture: Recap",
    "text": "Final lecture: Recap\n\n\n link to view slides fullscreen    link to PDF slides"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Syllabus",
    "section": "",
    "text": "You can find more out about our course in the syllabus."
  },
  {
    "objectID": "day4.html",
    "href": "day4.html",
    "title": "Day 4",
    "section": "",
    "text": "Outline of topics:"
  },
  {
    "objectID": "day4.html#video-recording",
    "href": "day4.html#video-recording",
    "title": "Day 4 — Thursday, January 12th, 2022",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "day4.html#resources",
    "href": "day4.html#resources",
    "title": "Day 4 — Thursday, January 12th, 2022",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides\n\nLecture 1: Diverse Data Sources\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 2: Factors and Date-times\n\n\nlink to view slides fullscreen  link to follow along code   link to slide PDFs  \n\n\nLecture 3: Regression\n link to slide PDFs  link to repository \n\n\nLecture 4: Creating maps in R\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 5: Reproducible examples for getting help in R\n  link to view slides fullscreen    link to slide PDFs"
  },
  {
    "objectID": "day5.html",
    "href": "day5.html",
    "title": "Day 5",
    "section": "",
    "text": "Outline of topics:\n\nCourse Core Concept Script\nReproducibility and Robustness\nVisualizing and Reporting on Regression\nQR Code Activity\nData Linkage Methods\nOnikye et al Article\n\n\n\n\n\n\n\nCourse Core Concepts Script\n\n\n\n\n\nFind this script online here or written out below:\n# know how to install packages:\n# install.packages(\"tidyverse\")\n\n# set up a project so we could use the {here} package\n\n# dependencies ------------------------------------------------------------\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(here)\nlibrary(palmerpenguins)\nlibrary(gtsummary)\n\n\n# read in data ------------------------------------------------------------\n\n# we could use a csv dataset like this:\n# df &lt;- readr::read_csv(here(\"data.csv\"))\n\n# or use an example dataset like penguins from palmerpenguins:\n# use View to look at it in RStudio\nView(penguins)\n\n\n# data manipulation -------------------------------------------------------\n\n# use group_by and summarize together to create summary statistics per-group\npenguins_summarized &lt;- penguins |&gt;\n  group_by(species) |&gt;\n  summarize(\n    mean_flipper_length_mm = mean(flipper_length_mm, na.rm=TRUE))\n\n# know how to use mutate to update columns (either creating new ones or updating\n# existing ones):\n# here, we'll just convert species to a character vector just for an example\n# so then we can next practice making it a factor:\npenguins &lt;- penguins |&gt;\n  mutate(species = as.character(species))\n\n# convert a variable to a factor:\n#\n# method 1: base R\n# here, the levels will be assumed from the output of unique(penguins$species):\npenguins$species &lt;- factor(penguins$species)\n#\n# method 2: dplyr\npenguins &lt;- penguins |&gt;\n  mutate(species = factor(species))\n\n# if I wanted to change the reference category, I could use relevel:\npenguins$species &lt;- relevel(penguins$species, 'Chinstrap')\n\n# or the dplyr way:\npenguins &lt;- penguins |&gt;\n  mutate(species = relevel(species, 'Chinstrap'))\n# you can also use forcats::fct_relevel\n\n\n# data visualization ------------------------------------------------------\n\n# use ggplot2 to make some graphics\n# a scatter plot:\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point() +\n  ggtitle(\"Penguin Bill Lengths and Depths by Species\")\n\n# use ggsave to save your work\nggsave(here(\"output/penguins_scatterplot.png\"), width = 7, height = 5)\n\n# a histogram with facets:\nggplot(penguins, aes(x = flipper_length_mm)) +\n  geom_histogram() +\n  facet_wrap(~species) +\n  ggtitle(\"Penguin Bill Lengths and Depths by Species\")\n\n# again use ggsave and here() to save it within your project\nggsave(here(\"output/penguins_faceted_histogram.png\"), width = 8, height = 3)\n\n\n# you might also want to plot regression lines in ggplot quickly so\n# use geom_smooth:\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = 'lm') +\n  ggtitle(\"Linear regression of flipper length on body mass\")\n\n\n# analyze a model -------------------------------------------------------------\n\nmodel &lt;- lm(flipper_length_mm ~ body_mass_g + species, penguins)\n\n# use broom::tidy to extract the coefficients and their statistics\nmodel_output &lt;- broom::tidy(model, conf.int = TRUE)\n\n# visualize model results\nmodel_output |&gt;\n  filter(term != '(Intercept)') |&gt;\n  ggplot(aes(x = estimate, y = term, xmin = conf.low, xmax = conf.high)) +\n  geom_pointrange()\n\n# create a table of the results\ngtsummary::tbl_regression(model)\n\n\n# one example with multiple models --------------------------------------------\n\nmodel1 &lt;- lm(flipper_length_mm ~ species, penguins)\nmodel2 &lt;- lm(flipper_length_mm ~ species + body_mass_g, penguins)\nmodel3 &lt;- lm(flipper_length_mm ~ species + body_mass_g + island, penguins)\n\n# extract tables of results\nmodel_results &lt;- list(\n  bind_cols(model = 'model1', broom::tidy(model1, conf.int = TRUE)),\n  bind_cols(model = 'model2', broom::tidy(model2, conf.int = TRUE)),\n  bind_cols(model = 'model3', broom::tidy(model3, conf.int = TRUE)))\n\n# make into one data frame\nmodel_results &lt;- bind_rows(model_results)\n\n# create a plot of covariates from multiple models\nmodel_results |&gt;\n  filter(term %in% c('speciesGentoo', 'speciesAdelie')) |&gt;\n  ggplot(\n       aes(x = estimate,\n           y = term,\n           xmin = conf.low,\n           xmax = conf.high,\n           color = model,\n           shape = model)) +\n  geom_pointrange(position = position_dodge(width = 0.5)) +\n  ggtitle(\"Coefficient estimates for species effect\",\n          stringr::str_wrap(\n            paste(\n              \"Model 1 includes no other covariates, model 2 includes body mass,\",\n              \"and model 3 includes body mass and island effects\"\n            )\n          ))\n\n\n\n\n\n\n\n\n\nLecture 1: Reproducibility and Robustness\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \n\n\n\n\n\n\n\nLecture 2: Regression (part 2!)\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to repository \n\n\n\n\n\n\nLecture 3: Data linkage methods\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to follow along code\n\n\n\n\n\n\nBrown et al Response and Reproduction of Onikye et al\n\n\n\n\n\nPreface\nIn 2021 Brown et al published an article titled A Reproduction of the Results of Onyike et al. (2003) in Meta-Psychology, a journal that is free, open-access and conducts open peer review. The Onikye et al. article they reproducing, Is obesity associated with major depression? Results from the Third National Health and Nutrition Examination Survey, was published in the American Journal of Epidemiology has been cited 1159+ times according to Google Scholar.\nI want to point out an interesting section from the About page describing the Meta-Psychology journal that you might keep in mind as you read on:\n\nPrior to publication, all statistical analyses are reproduced by our statistical reproduction team, which consists of the Statistical Editor and our editorial assistant. This makes the article eligible for the reproducibility badge.\n\nRecommended Reading\nPlease read the article by Brown et al (https://open.lnu.se/index.php/metapsychology/article/view/2071).\nAbstract repeated here as a teaser:\n\nOnyike et al. (2003) analyzed data from a large-scale US-American data set, the Third National Health and Nutrition Examination Survey (NHANES-III), and reported an association between obesity and major depression, especially among people with severe obesity. Here, we report the results of a detailed replication of Onyike et al.’s analyses. While we were able to reproduce the majority of these authors’ descriptive statistics, this took a substantial amount of time and effort, and we found several minor errors in the univariate descriptive statistics reported in their Tables 1 and 2. We were able to reproduce most of Onyike et al.’s bivariate findings regarding the relationship between obesity and depression (Tables 3 and 4), albeit with some small discrepancies (e.g., with respect to the magnitudes of standard errors). On the other hand, we were unable to reproduce Table 5, containing Onyike et al.’s findings with respect to the relationship between obesity and depression when controlling for plausible confounding variables—arguably the paper’s most important results—because some of the included predictor variables appear to be either unavailable, or not coded in the way reported by Onyike et al., in the public NHANES-III data sets. We discuss the implications of our findings for the transparency of reporting and the reproducibility of published results.\n\nTheir code is freely, publicly accessible on OSFHOME, a file storage service provided by the Open Science Framework from the Center for Open Science.\n\nBrown et al’s code+file repository: https://osf.io/j32yw/\nDownload their code+files (direct link): https://files.osf.io/v1/resources/j32yw/providers/osfstorage/?zip=\n\nNote that in order to run their code, you will either want to a) make a new R project in the folder with their code on your computer, or b) open a new RStudio window, open up their .R file, and use setwd('filepath/goes/here/') to make sure your R session can run their R code.\nConsider the following questions:\n\nDo you believe that the results Brown et al. have shared are more likely to be correct than those that Onikye et al published? If so, why? If not, why not?\n\nWhat do you find compelling about their re-analysis and code?\nWhat do you find lacking about their re-analysis and code?\n\nHow do you think the non-reproducibility of Onikye et al.’s article could have been avoided?\nWhen, if at all, do you think articles should be required to share code and data?\n\nWhat about in situations where the data relates to private or sensitive data?\nWhat about in situations where the subject matter is highly politically charged and there might be malicious actors who could see shared data and code as additional surface area to attack?\n\nHas reading this article made you more skeptical of research publications that don’t share code?\nDo you think for articles where code & data are too sensitive to be shared, is there an alternative process that would make you similarly confident in the stated results?\n\nAn important aside\nThis isn’t a class about stigma and health, but I think being in a Population Health Science program, it’s important to leave the breadcrumbs here for you to do your own followup reading and learning.\nBecause the articles in this homework discuss body-weight and health, I want to emphatically point out that this subject matter is not at all cut and dry. It’s important to acknowledge that:\n\nWeight-based stigma is real and causes harm to health through multiple mechanisms including at least discrimination and health care practitioners’ attitudes and behaviors:\n\nhttps://ajph.aphapublications.org/doi/full/10.2105/AJPH.2009.159491\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/obr.12266\n\nThe decision by health organizations to classify obesity as a “disease” is debated:\n\nhttps://www.healthline.com/health/is-obesity-a-disease\n\nThe language and terminology that we use can perpetuate stigma:\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC5051141/?report=classic\nhttps://news.yale.edu/2012/07/12/choosing-words-wisely-when-talking-patients-about-their-weight\n\n\nIf anything, what I hope you take away from this aside is that data do not speak for themselves, but rather are subject to interpretation and leave room for either the perpetuation or casting aside of pre-existing biases (See “Data Never Speak for Themselves” from Nancy Krieger’s article Structural Racism, Health Inequities, and the Two-Edged Sword of Data: Structural Problems Require Structural Solutions). It’s not enough to engage with open-science practices and leverage sophisticated statistical analyses made possible in programs like R; instead, it’s necessary to combine advances in the state of the art in computing with advances in our conceptual frameworks to do science that can truly shift narratives in ways that benefit marginalized groups.\n\n\n\n\n\n\n\n\n\nVideo Recording from 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Recording from 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Recording from 2023"
  },
  {
    "objectID": "day5.html#video-recording",
    "href": "day5.html#video-recording",
    "title": "Day 5 — Friday, January 13th, 2022",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "day5.html#resources",
    "href": "day5.html#resources",
    "title": "Day 5 — Friday, January 13th, 2022",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides\n\nLecture 1: Reproducibility and Robustness\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 2: Regression (part 2!)\n link to slide PDFs  link to repository \n\n\nLecture 3: Data linkage methods\n\n\nlink to view slides fullscreen   link to slide PDFs   link to follow along code"
  },
  {
    "objectID": "day7.html",
    "href": "day7.html",
    "title": "Day 7",
    "section": "",
    "text": "Outline:\n\nAn Analysis Start-to-Finish: Environmental Monitoring\nLongitudinal Data Analysis\nVisualizing Missing Data\nEasy Exploratory Data Analysis\nPrinciples for Clean Code\n\n\n\n\n\n\n\nLecture 1: An Analysis Start to Finish\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen \nlink to slide pdf\n\n\n\n\n\n\nLecture 2: Exploratory data analysis – Longitudinal data analysis\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen   link to slide pdf   link to longitudinal_eda.R script    link to make_simulated_data.R script \n\n\n\n\n\n\nLecture 3: Missing data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs    link to missing-demo.R script \n\n\n\n\n\n\nLecture 4: Accessible exploratory data analysis\n\n\n\n\n\n link to eda.R script \n\n\n\n\n\n\n\n\n\nLecture 5: Clean code and considerate coding\n\n\n\n\n\n\n\nthe tidyverse style guide\n\n\n\nlink to view fullscreen \nlink to pdf \n\n\n\n\n\n\nVideo Recording from 2023"
  },
  {
    "objectID": "day7.html#video-recording",
    "href": "day7.html#video-recording",
    "title": "Day 7 — Wednesday, January 18th, 2022",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "day7.html#resources",
    "href": "day7.html#resources",
    "title": "Day 7 — Wednesday, January 18th, 2022",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides"
  },
  {
    "objectID": "day7.html#lecture-2-exploratory-data-analysis-longitudinal-data-analysis",
    "href": "day7.html#lecture-2-exploratory-data-analysis-longitudinal-data-analysis",
    "title": "Day 7 — Wednesday, January 18th, 2022",
    "section": "Lecture 2: Exploratory data analysis – Longitudinal data analysis",
    "text": "Lecture 2: Exploratory data analysis – Longitudinal data analysis\n link to longitudinal_eda.R script    link to make_simulated_data.R script"
  },
  {
    "objectID": "day7.html#lecture-3-missing-data",
    "href": "day7.html#lecture-3-missing-data",
    "title": "Day 7 — Wednesday, January 18th, 2022",
    "section": "Lecture 3: Missing data",
    "text": "Lecture 3: Missing data\n\n\nlink to view slides fullscreen   link to slide PDFs    link to missing-demo.R script"
  },
  {
    "objectID": "day7.html#lecture-4-accessible-exploratory-data-analysis",
    "href": "day7.html#lecture-4-accessible-exploratory-data-analysis",
    "title": "Day 7",
    "section": "Lecture 4: Accessible exploratory data analysis",
    "text": "Lecture 4: Accessible exploratory data analysis\n link to eda.R script \n\n\n\n\n\n\nLecture 5: Clean code and considerate coding\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording"
  },
  {
    "objectID": "day7.html#lecture-5-clean-code-and-considerate-coding",
    "href": "day7.html#lecture-5-clean-code-and-considerate-coding",
    "title": "Day 7 — Wednesday, January 18th, 2022",
    "section": "Lecture 5: Clean code and considerate coding",
    "text": "Lecture 5: Clean code and considerate coding"
  },
  {
    "objectID": "day6.html",
    "href": "day6.html",
    "title": "Day 6",
    "section": "",
    "text": "Outline of topics:\n\nR Markdown\nDebugging\nTime to work on final project\n\n\n\n\n\n\n\nLecture 1: R Markdown\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nLecture 2: Debugging\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nVideo Recording from Last Year"
  },
  {
    "objectID": "day6.html#video-recording",
    "href": "day6.html#video-recording",
    "title": "Day 6 — Tuesday, January 17th, 2022",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "day6.html#resources",
    "href": "day6.html#resources",
    "title": "Day 6 — Tuesday, January 17th, 2022",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides\n\nLecture 1: Packages\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 2: RMarkdown\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 3: Debugging\n\n\nlink to view slides fullscreen \n link to slide PDFs  \n link to live coding example reproducing a map of literacy rates in India from Wikipedia"
  },
  {
    "objectID": "day2.html",
    "href": "day2.html",
    "title": "Day 2",
    "section": "",
    "text": "Outline of topics:"
  },
  {
    "objectID": "day2.html#video-recording",
    "href": "day2.html#video-recording",
    "title": "Day 2 — Tuesday, January 10th, 2022",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "day2.html#resources",
    "href": "day2.html#resources",
    "title": "Day 2",
    "section": "Resources",
    "text": "Resources\n link to daily google doc"
  },
  {
    "objectID": "day3.html",
    "href": "day3.html",
    "title": "Day 3",
    "section": "",
    "text": "Outline of topics:"
  },
  {
    "objectID": "day3.html#video-recording",
    "href": "day3.html#video-recording",
    "title": "Day 3 — Wednesday, January 11th, 2022",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "day3.html#resources",
    "href": "day3.html#resources",
    "title": "Day 3 — Wednesday, January 11th, 2022",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides \n\nLecture 1: Projects in RStudio\n\n\nlink to view slides fullscreen\n\n\nLecture 2: Intro to dplyr\n\n\nlink to view slides fullscreen\n\n\nLecture 4: Cleaning Text Data\n\n\nlink to view slides fullscreen\n\n\nLecture 5: Functions\n\n\nlink to view slides fullscreen"
  },
  {
    "objectID": "day1.html",
    "href": "day1.html",
    "title": "Day 1",
    "section": "",
    "text": "Outline of Topics"
  },
  {
    "objectID": "day1.html#video-recording",
    "href": "day1.html#video-recording",
    "title": "Day 1 — Monday, January 8th, 2022",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "day1.html#resources",
    "href": "day1.html#resources",
    "title": "Day 1",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to slide pdfs\n\n\n\n\n\n\nSlides for Intro to ID529\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\n\n\n\n\n\n\n\nSlides for Final Presentation\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to pdf slides \n\nPositive Affirmations\n\nlink to view fullscreen\nIn text form:\nHere are some affirmations that can help you to reframe your thoughts and let go of any negative self-doubt or impostor syndrome that you may be feeling.\n\nI am capable and competent.\nI am worthy and deserving of success.\nI trust in my abilities and the effort I put forth.\nI am enough, exactly as I am.\nI am learning and growing with each challenge I face.\n\nIt’s important to remember that everyone experiences moments of self-doubt and uncertainty, and it’s okay to not feel confident all the time.\nThe key is to recognize and acknowledge those feelings, and then remind ourselves of our strengths and capabilities."
  },
  {
    "objectID": "wi23/day8.html",
    "href": "wi23/day8.html",
    "title": "Day 8 — Thursday, January 19th, 2023",
    "section": "",
    "text": "1:30-2:00 Lecture/Demo: Principles for Data Analysis from Start to Finish\n2:00-2:30 Lecture: Functional Programming\n2:30-3:00 Discussion + Demo: When does it make sense to use functional programming?\n3:00-3:10 Break\n3:10-3:40 Lecture: [Students’ Choice]\n3:40-4:10 Lecture: How to Keep Growing as a Programmer (and stay up to date)\n4:10-4:20 Details about turning in your final presentations\n4:20-5:30 Positive affirmations, free time to work together on final projects\n\n\n\n\nWork with classmates to finalize presentations and turn them in\n\n\n\n\n\nHadley Wickham on Many Models: https://youtu.be/cU0-NrUxRw4"
  },
  {
    "objectID": "wi23/day8.html#video-recording",
    "href": "wi23/day8.html#video-recording",
    "title": "Day 8 — Thursday, January 19th, 2023",
    "section": "Video Recording",
    "text": "Video Recording\n\n\nApologies the lecture recording didn’t capture the first lecture of the day."
  },
  {
    "objectID": "wi23/day8.html#resources",
    "href": "wi23/day8.html#resources",
    "title": "Day 8 — Thursday, January 19th, 2023",
    "section": "Resources",
    "text": "Resources\n  link to PDF slides   link to daily google doc  \n\nLecture 1: Principles for data analysis\n\n\n link to view slides fullscreen    link to PDF slides \n\n\nLecture 2: Functional Programming\n link to functional_programming.R script \n\n\nLecture 3: dplyr (student choice)\n dplyr_demo.R script \n\n\nLecture 4: Growing as a programmer\n\n\n link to view slides fullscreen   link to PDF slides"
  },
  {
    "objectID": "wi23/day9.html",
    "href": "wi23/day9.html",
    "title": "Day 9 — Friday, January 19th, 2023",
    "section": "",
    "text": "1:30-4:30 Final Presentations:\n\nStudents will be divided into 10 groups with 10-12 minutes presentation time and 3-5 minutes for feedback from the instructional team and Q&A from the audience.\n15 minutes × 10 groups = ~2.5 hours\nwe’ll make sure to take some breaks between every few groups\n\n4:30-5:00 Lecture: Recap of Key Takeaways\n5:00-5:30:\n\nMake sure you’ve uploaded your presentation!\nFeedback and Course Evaluations\n\n\nEnjoy being done with the class and go on to do great things with your newly learned R skills!"
  },
  {
    "objectID": "wi23/day9.html#video-recording",
    "href": "wi23/day9.html#video-recording",
    "title": "Day 9 — Friday, January 19th, 2023",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "wi23/day9.html#student-presentations",
    "href": "wi23/day9.html#student-presentations",
    "title": "Day 9 — Friday, January 19th, 2023",
    "section": "Student Presentations",
    "text": "Student Presentations\n\nClean Code and Code Hygeine\n\n\n\n\nCode Commenting and Documentation\n\n\n\n\nData Dictionaries\n\n\n\n\nData Visualization (Group 1)\n\n\n\n\nData Visualization (Group 2)\n\n\n\n\nPresenting Model Results\n\n\n\n\nGeographic Maps"
  },
  {
    "objectID": "wi23/day9.html#final-lecture-recap",
    "href": "wi23/day9.html#final-lecture-recap",
    "title": "Day 9 — Friday, January 19th, 2023",
    "section": "Final lecture: Recap",
    "text": "Final lecture: Recap\n\n\n link to view slides fullscreen    link to PDF slides"
  },
  {
    "objectID": "wi23/day4.html",
    "href": "wi23/day4.html",
    "title": "Day 4 — Thursday, January 12th, 2023",
    "section": "",
    "text": "1:30-2:00 Lecture: Diverse Data Sources (APIs [tidycensus, WHO, World Bank, qualtRics], scraping web data, tabulizer, tesseract, datapasta)\n2:00-2:20 Discussion: What kind of sources are students interested in using in their research or future work?\n2:20-2:50 Lecture: How to handle factors and date-times\n2:50-3:00 Break\n3:00-3:30 Lecture: Working with Regression Model Objects: constructing and analyzing them\n3:30-4:15 Activity: Working with Regression Models in R\n4:15-4:45 Lecture: Creating maps in R\n4:45-5:00 Lecture: Reproducible Examples for Getting Help\n5:00-5:30 Time to work on final presentation materials together, peruse recommended materials, chat with classmates\n\n\n\n\nFit and report on a regression model including categorical (factor) variables\nPeer Review for Homework 2\n\n\n\n\nRemember! You don’t have to read all of this! Just focus on what’s most useful to you:\n\nTidy Data by Hadley Wickham https://vita.had.co.nz/papers/tidy-data.pdf\nDiverse Data Sources\n\nThe readme to the datapasta package: https://github.com/MilesMcBain/datapasta\nAnalyzing US Census Data by Kyle Walker, Chapter 2: An introduction to tidycensus: https://walker-data.com/census-r/an-introduction-to-tidycensus.html\nThe readr cheatsheet: https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-import.pdf\nWorking with Qualtrics Data - Part 1: Importing Data, ROpenSci https://ropensci.org/blog/2022/08/02/working-with-qualtrics-data-importing/\n\nHandling factors and date-times in R:\n\nChapter 15: Factors, R for Data Science by Hadley Wickham and Garrett Grolemund https://r4ds.had.co.nz/factors.html\nChapter 16: Dates and Times, R for Data Science by Hadley Wickham and Garrett Grolemund https://r4ds.had.co.nz/dates-and-times.html\nForcats cheatsheet https://raw.githubusercontent.com/rstudio/cheatsheets/main/factors.pdf\nLubridate cheatsheet https://raw.githubusercontent.com/rstudio/cheatsheets/main/lubridate.pdf\n\nWorking with Regression Models:\n\nIntroduction to broom https://broom.tidymodels.org/articles/broom.html\nA nice introduction to linear model diagnostics plots: https://book.stat420.org/model-diagnostics.html\nInterpretation of R’s lm() output: https://stats.stackexchange.com/questions/5135/interpretation-of-rs-lm-output\n\nMapping:\n\nChapter 8 Plotting Spatial Data, Spatial Data Science https://r-spatial.org/book/08-Plotting.html\n\nThis focuses more on sf which is the most modern and increasingly most popular paradigm for working with spatial data in R\n\nChapter 9 Making Maps with R, Geocomputation with R https://geocompr.robinlovelace.net/adv-map.html\n\nThis chapter has a lot of focus on tmap, a package for creating thematic maps"
  },
  {
    "objectID": "wi23/day4.html#video-recording",
    "href": "wi23/day4.html#video-recording",
    "title": "Day 4 — Thursday, January 12th, 2023",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "wi23/day4.html#resources",
    "href": "wi23/day4.html#resources",
    "title": "Day 4 — Thursday, January 12th, 2023",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides\n\nLecture 1: Diverse Data Sources\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 2: Factors and Date-times\n\n\nlink to view slides fullscreen  link to follow along code   link to slide PDFs  \n\n\nLecture 3: Regression\n link to slide PDFs  link to repository \n\n\nLecture 4: Creating maps in R\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 5: Reproducible examples for getting help in R\n  link to view slides fullscreen    link to slide PDFs"
  },
  {
    "objectID": "wi23/day5.html",
    "href": "wi23/day5.html",
    "title": "Day 5 — Friday, January 13th, 2023",
    "section": "",
    "text": "1:30-2:00 Lecture: Why reproducibility and robustness are important principles in science and data analysis and acknowledging the pressures in academia that push people away from reproducible science\n2:00-2:15 Discussion\n2:15-2:45 Lecture: Visualizing and Reporting on Regression Models\n2:45-3:05 Lecture: Data Linkage Methods\n3:05-3:25 Activity: Working with Joins\n3:25-3:35 Break\n3:35-4:00 Activity: Hallway QR Code Challenges\n4:00-4:15 Lecture: Introduction of the Brown et al (partial) reproduction of Onikye et al’s results\n4:15-4:30 Homework demonstration\n4:30-5:25 Time to work on homework + chat together + work on final projects\n5:25-5:30 Giveaway for a Copy of R for Data Science\n5:30 Meet Hodu!\n\n\n\n\nRead the Brown et al reproduction of Onikye et al, run their code, and fill out the worksheet\n\nhttps://open.lnu.se/index.php/metapsychology/article/view/2071\nhttps://osf.io/j32yw/\n\nPeer review for homework 3\n\n\n\n\n\nReproducibility:\n\nDraw Me A Project https://masalmon.eu/2021/06/30/r-projects/\nReproducibility of Scientific Results https://plato.stanford.edu/entries/scientific-reproducibility/\nBest Practices for Scientific Computing https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745\nGood Enough Practices for Scientific Computing https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510\nReplicability, Robustness, and Reproducibility in Psychological Science https://pure.uvt.nl/ws/portalfiles/portal/59415163/MTO_Nuijten_replicability_robustness_and_reproducibility_Annual_Review_of_Psy_2022.pdf\nA manifesto for reproducible science https://www.nature.com/articles/s41562-016-0021\n\nRegression Modeling:\n\nIntroduction to Poisson Regression, Beyond Multiple Linear Regression https://bookdown.org/roback/bookdown-BeyondMLR/ch-poissonreg.html\nPoisson Regression https://rpubs.com/franzbischoff/poisson_regression\nLogistic Regression, Beyond Multiple Linear Regression https://bookdown.org/roback/bookdown-BeyondMLR/ch-logreg.html"
  },
  {
    "objectID": "wi23/day5.html#video-recording",
    "href": "wi23/day5.html#video-recording",
    "title": "Day 5 — Friday, January 13th, 2023",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "wi23/day5.html#resources",
    "href": "wi23/day5.html#resources",
    "title": "Day 5 — Friday, January 13th, 2023",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides\n\nLecture 1: Reproducibility and Robustness\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 2: Regression (part 2!)\n link to slide PDFs  link to repository \n\n\nLecture 3: Data linkage methods\n\n\nlink to view slides fullscreen   link to slide PDFs   link to follow along code"
  },
  {
    "objectID": "wi23/day7.html",
    "href": "wi23/day7.html",
    "title": "Day 7 — Wednesday, January 18th, 2023",
    "section": "",
    "text": "1:30-2:00 Lecture: A Data Analysis from Start to Finish\n2:00-2:30 Lecture: Longitudinal Data Analysis\n2:30-3:00 Lecture: Best practices for reporting on missing data\n3:00-3:30 Lecture: Intro to accessible exploratory data analysis methods: Correlation, principal components analysis, variable importance\n3:30-3:40 Break\n3:40-4:00 Discussion: What are the ethical principles involved in data analysis? What are the risks involved?\n4:00-4:30 Lecture: Clean Code and Considerate Coding\n4:30-5:30 Free time to work together on the final project, chat with classmates, peruse recommended materials\n\n\n\n\nPeer Review Homework 5\n\n\n\n\n\nHarms and Ethics in Data Science and Machine Learning:\n\nThe Data Science Ethics chapter from the Modern Data Science with R book: https://mdsr-book.github.io/mdsr2e/ch-ethics.html"
  },
  {
    "objectID": "wi23/day7.html#video-recording",
    "href": "wi23/day7.html#video-recording",
    "title": "Day 7 — Wednesday, January 18th, 2023",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "wi23/day7.html#resources",
    "href": "wi23/day7.html#resources",
    "title": "Day 7 — Wednesday, January 18th, 2023",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides"
  },
  {
    "objectID": "wi23/day7.html#lecture-2-exploratory-data-analysis-longitudinal-data-analysis",
    "href": "wi23/day7.html#lecture-2-exploratory-data-analysis-longitudinal-data-analysis",
    "title": "Day 7 — Wednesday, January 18th, 2023",
    "section": "Lecture 2: Exploratory data analysis – Longitudinal data analysis",
    "text": "Lecture 2: Exploratory data analysis – Longitudinal data analysis\n link to longitudinal_eda.R script    link to make_simulated_data.R script"
  },
  {
    "objectID": "wi23/day7.html#lecture-3-missing-data",
    "href": "wi23/day7.html#lecture-3-missing-data",
    "title": "Day 7 — Wednesday, January 18th, 2023",
    "section": "Lecture 3: Missing data",
    "text": "Lecture 3: Missing data\n\n\nlink to view slides fullscreen   link to slide PDFs    link to missing-demo.R script"
  },
  {
    "objectID": "wi23/day7.html#lecture-4-accessible-exploratory-data-analysis",
    "href": "wi23/day7.html#lecture-4-accessible-exploratory-data-analysis",
    "title": "Day 7 — Wednesday, January 18th, 2023",
    "section": "Lecture 4: Accessible exploratory data analysis",
    "text": "Lecture 4: Accessible exploratory data analysis\n link to eda.R script"
  },
  {
    "objectID": "wi23/day7.html#lecture-5-clean-code-and-considerate-coding",
    "href": "wi23/day7.html#lecture-5-clean-code-and-considerate-coding",
    "title": "Day 7 — Wednesday, January 18th, 2023",
    "section": "Lecture 5: Clean code and considerate coding",
    "text": "Lecture 5: Clean code and considerate coding"
  },
  {
    "objectID": "wi23/day6.html",
    "href": "wi23/day6.html",
    "title": "Day 6 — Tuesday, January 17th, 2023",
    "section": "",
    "text": "1:30-1:50 Activity: Discussion of Onikye et al reproduction article\n1:50-2:10 Lecture: Introduction to R Packages\n2:10-2:30 Demonstration of how to create R packages that standardize data loading and cleaning processes\n2:30-3:00 Lecture: How to use R Markdown to produce reproducible reports including tables, visualizations, and inline-quantitative statements.\n3:00-3:10 Break\n3:10-3:30 Activity: Experiment with different R Markdown features\n3:30-3:50 Lecture: Advice for Debugging\n3:50-4:10 Activity: Debugging\n4:10-4:30 Activity: Getting Help Online\n4:30-4:45 Demonstration of how to do the homework\n4:45-5:30 Time to do the homework, work on the final project together, peruse recommended materials\n\n\n\n\nUse R Markdown to document some exploratory data analyses\n\n\n\n\n\nR Packages:\n\nRead Karl Broman’s Why write an R package?\nFamiliarize yourself with what’s in the R Packages book: https://r-pkgs.org/ — having a rough familiarity with the different parts will be helpful. Our suggestion here is to try and approach this more in terms of “what are the ingredients in a good R Package?” rather than trying to learn how to craft all of those ingredients from the ground up immediately.\n\nR Markdown:\n\nCheck out the Get Started for R Markdown, especially the ~1 minute video intro on the first page: https://rmarkdown.rstudio.com/lesson-1.html\nHow R Helps Airbnb Make the Most of Its Data\nIf you find yourself loving R Markdown, you may find the R Markdown Cookbook useful, but it is incredibly comprehensive and we’d suggest it’s better to reference as you need it than to try to read it cover-to-cover."
  },
  {
    "objectID": "wi23/day6.html#video-recording",
    "href": "wi23/day6.html#video-recording",
    "title": "Day 6 — Tuesday, January 17th, 2023",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "wi23/day6.html#resources",
    "href": "wi23/day6.html#resources",
    "title": "Day 6 — Tuesday, January 17th, 2023",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides\n\nLecture 1: Packages\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 2: RMarkdown\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 3: Debugging\n\n\nlink to view slides fullscreen \n link to slide PDFs  \n link to live coding example reproducing a map of literacy rates in India from Wikipedia"
  },
  {
    "objectID": "wi23/day2.html",
    "href": "wi23/day2.html",
    "title": "Day 2 — Tuesday, January 10th, 2023",
    "section": "",
    "text": "1:30-2:00 Lecture: Intro to R Programming (including conditionals, control flow, etc.)\n2:00-2:15 Activity: learnr Tutorial on Conditionals and Control Flow\n2:15-2:45 Lecture: Data Dictionaries and Documentation\n2:45-3:00 Activity: Q&A + Discussion\n3:00-3:05 Break\n3:05-3:35 Lecture: Reading in data of various formats\n3:35-4:30 Lecture: Intro to ggplot2 (common types of figures, faceting, legends, patchwork, and saving figures)\n4:30-4:50 Discussion: What are the ingredients to a ggplot? What makes an effective data visualization?\n4:50-5:10 Demonstration of how to do the homework\n5:10-5:30 Time to work on homework, chat with classmates, peruse recommended materials, engage in self-affirmation\n\n\n\n\nRead in a dataset of your choice [we will give you some example datasets you can use] and create a few figures using ggplot2. We want to see students include titles, subtitles, captions, data sources, legends, etc.\n\nThe figures should include one univariate figure, one bivariate figure, and one figure using facet_wrap or facet_grid\nIf you’re feeling extra, have fun stylizing your plots! Go wild! Try to change up the background, fonts, etc.\n\n\n\n\n\n\nOur learnr tutorial on Conditionals, Control Flow, and Logic in R\nSmithsonian Data Management and Best Practices — Describing Your Data: Data Dictionaries\n\nhttps://library.si.edu/sites/default/files/tutorial/pdf/datadictionaries20180226.pdf\n\nU.S. Geological Survey, Data Dictionaries\n\nhttps://www.usgs.gov/data-management/data-dictionaries\n\nSkim the readr cheatsheet:\n\nhttps://raw.githubusercontent.com/rstudio/cheatsheets/main/data-import.pdf\nKeep in mind, your goal shouldn’t be to memorize everything, but rather to get a sense of what functionality is available to you, and how you could reference this cheatsheet or follow up on its contents to make use of it.\n\nFundamentals of Data Visualization, Chapter 2, Visualizing data: Mapping data onto aesthetics:\n\nhttps://clauswilke.com/dataviz/aesthetic-mapping.html\n\nFundamentals of Data Visualization, Chapter 17, The principle of proportional ink:\n\nhttps://clauswilke.com/dataviz/proportional-ink.html\n\n[Video] Introduction to ggplot2 https://www.youtube.com/watch?v=UiuA5sBEcFk\n[Video] BeginneR Workshop https://www.youtube.com/watch?v=7kuPnVZcot0 [lecture starts around 20:00]\n\nCheck the video description for the code files\n\n[Video] Intro to Git and GitHub https://www.youtube.com/watch?v=u4LIpYC0Yaw\n\nTruly extra reading for those interested in advancing their conceptual understanding of ggplot2 and the possibilities in data visualization:\n\nA Layered Grammar of Graphics, by Hadley Wickham http://vita.had.co.nz/papers/layered-grammar.pdf\nStart to get familiar with the ggplot2 book. We recommend starting with subsection 1.2 “What is the grammar of graphics?” here: https://ggplot2-book.org/introduction.html#what-is-the-grammar-of-graphics\nThe R Graph Gallery: https://r-graph-gallery.com/index.html\n\nWhat you can expect from the instructional team:\n\nWe will be reading your bios and working on sorting you into groups for the final presentation topics."
  },
  {
    "objectID": "wi23/day2.html#video-recording",
    "href": "wi23/day2.html#video-recording",
    "title": "Day 2 — Tuesday, January 10th, 2023",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "wi23/day2.html#resources",
    "href": "wi23/day2.html#resources",
    "title": "Day 2 — Tuesday, January 10th, 2023",
    "section": "Resources",
    "text": "Resources\n link to daily google doc  \n link to slide pdfs\n\nLecture 1: Programming with R\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 2: Data Dictionaries and Documentation\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 3: Reading in Data\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 4: Intro to ggplot2\n\n\nlink to view slides fullscreen   link to slide PDFs"
  },
  {
    "objectID": "wi23/day3.html",
    "href": "wi23/day3.html",
    "title": "Day 3 — Wednesday, January 11th, 2023",
    "section": "",
    "text": "1:30-2:00 Lecture: R Projects\n2:00-2:50 Lecture: Intro to dplyr\n2:50-3:10 Activity: Work on dplyr learnr tutorial in groups\n3:10-3:15 Break\n3:15-3:45 Lecture: Cleaning Text Data\n3:45-4:10 Lecture: Writing Functions\n4:10-4:30 Activity: Write functions together\n4:30-4:45 Activity: Discussion Q&A from ggplot2 Homework\n4:45-4:55 Survey: Checking in on Pacing\n4:55-5:10 Demonstration of how to do the homework\n5:10-5:30 Time to work on homework, chat with classmates, peruse recommended materials\n\n\n\n\nOn Projects:\n\nTidyverse Blog, Project-Oriented Workflow by Jenny Bryan: https://www.tidyverse.org/blog/2017/12/workflow-vs-script/\nR for Data Science, Chapter 8: https://r4ds.had.co.nz/workflow-projects.html\nProject-Oriented Workflow, Jenny Bryan https://www.tidyverse.org/blog/2017/12/workflow-vs-script/\n\nOn dplyr, cleaning text, and writing functions\n\nR for Data Science, Chapter 5 Data Transformation: https://r4ds.had.co.nz/transform.html\nR for Data Science, Chapter 14 Strings: https://r4ds.had.co.nz/strings.html\nR for Data Science, Chapter 19 Functions: https://r4ds.had.co.nz/functions.html\n\n\n\n\n\n\nNo homework"
  },
  {
    "objectID": "wi23/day3.html#video-recording",
    "href": "wi23/day3.html#video-recording",
    "title": "Day 3 — Wednesday, January 11th, 2023",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "wi23/day3.html#resources",
    "href": "wi23/day3.html#resources",
    "title": "Day 3 — Wednesday, January 11th, 2023",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides \n\nLecture 1: Projects in RStudio\n\n\nlink to view slides fullscreen\n\n\nLecture 2: Intro to dplyr\n\n\nlink to view slides fullscreen\n\n\nLecture 4: Cleaning Text Data\n\n\nlink to view slides fullscreen\n\n\nLecture 5: Functions\n\n\nlink to view slides fullscreen"
  },
  {
    "objectID": "wi23/day1.html",
    "href": "wi23/day1.html",
    "title": "Day 1 — Monday, January 9th, 2023",
    "section": "",
    "text": "1:30-1:40 Welcome to ID529\n1:40-2:10 Introductory Lecture: Course Details\n2:10-2:40 Live Demonstration: Modern Data Science Practices in an R Project Based Workflow\n2:40-2:55 Activity: Q&A + Group reflection on principles shown in the demonstration\n2:55-3:10 Lecture: Introduce the Final Presentations Format\n3:10-3:15 Break\n3:15-3:50: Intro to RStudio and R\n3:50-4:05: Discussion and Self-Introductions\n4:05-4:45: Lecture: Intro to Git and GitHub\n4:45-5:00: Demo of how to do the homework\n5:00-5:05: Positive Affirmations\n5:05-5:30 Activity: Setup GitHub accounts + work on the homework + peruse recommended materials + chat with classmates\n\n\n\n\nArticles:\n\nThe Introduction Chapter to R for Data Science: https://r4ds.had.co.nz/explore-intro.html (just one page)\nExcuse me, do you have a moment to talk about version control? by Jennifer Bryan: https://peerj.com/preprints/3159/\nTutorial: Getting Started with R and RStudio: https://www.dataquest.io/blog/tutorial-getting-started-with-r-and-rstudio/\nQuickstart from GitHub: https://docs.github.com/en/get-started/quickstart/hello-world\n\nVideos:\n\nRStudio for the Total Beginner, HRAnalytics101: https://www.youtube.com/watch?v=FIrsOBy5k58\nIf you haven’t already installed R and RStudio, you’ll want to do that, and you can do that by following the instructions here:\n\nInstall R: https://vimeo.com/203516510\nInstall RStudio: https://vimeo.com/203516968\n\n\n\n\n\n\n\nWrite a bio for yourself and include a picture!\nComplete the intro to course survey\nCheck that your R and RStudio installations are working on your computer"
  },
  {
    "objectID": "wi23/day1.html#video-recording",
    "href": "wi23/day1.html#video-recording",
    "title": "Day 1 — Monday, January 9th, 2023",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "wi23/day1.html#resources",
    "href": "wi23/day1.html#resources",
    "title": "Day 1 — Monday, January 9th, 2023",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to slide pdfs\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\nlink to view slides fullscreen   link to pdf slides \n\nPositive Affirmations\n\nlink to view fullscreen\nIn text form:\nHere are some affirmations that can help you to reframe your thoughts and let go of any negative self-doubt or impostor syndrome that you may be feeling.\n\nI am capable and competent.\nI am worthy and deserving of success.\nI trust in my abilities and the effort I put forth.\nI am enough, exactly as I am.\nI am learning and growing with each challenge I face.\n\nIt’s important to remember that everyone experiences moments of self-doubt and uncertainty, and it’s okay to not feel confident all the time.\nThe key is to recognize and acknowledge those feelings, and then remind ourselves of our strengths and capabilities."
  },
  {
    "objectID": "day1.html#slides",
    "href": "day1.html#slides",
    "title": "Day 1",
    "section": "Slides",
    "text": "Slides\n\n\n\n\n\n\nLecture 0 — Welcome to ID529\n\n\n\n\n\n\n\n\n\nlink to pdf slides\n\n\n\n\n\n\nView Slides for Intro to ID529\n\n\n\n\n\n\n\n\n\n\nview slides fullscreen \n\n\n\n\n\n\nSlides for Final Project Format\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \n\n\n\n\n\n\nView Slides for Intro to RStudio and R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \n\n\n\n\n\n\nView Slides for Git and GitHub\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen"
  },
  {
    "objectID": "day1.html#positive-affirmations",
    "href": "day1.html#positive-affirmations",
    "title": "Day 1",
    "section": "Positive Affirmations",
    "text": "Positive Affirmations\n\nlink to view fullscreen\nIn text form:\nHere are some affirmations that can help you to reframe your thoughts and let go of any negative self-doubt or impostor syndrome that you may be feeling.\n\nI am capable and competent.\nI am worthy and deserving of success.\nI trust in my abilities and the effort I put forth.\nI am enough, exactly as I am.\nI am learning and growing with each challenge I face.\n\nIt’s important to remember that everyone experiences moments of self-doubt and uncertainty, and it’s okay to not feel confident all the time.\nThe key is to recognize and acknowledge those feelings, and then remind ourselves of our strengths and capabilities.\n\n\n\n\n\n\nVideo Recording from 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Recording from 2024\n\n\n\n\n\n\n\nApologies we accidentally didn’t capture the RStudio and R talk on this recording. See other years’ recording for that section if you’d like.\n\n\n\n\n\n\n\n\n\nVideo Recording from 2023"
  },
  {
    "objectID": "day2.html#last-years-video-recording",
    "href": "day2.html#last-years-video-recording",
    "title": "Day 2",
    "section": "Last Year’s Video Recording",
    "text": "Last Year’s Video Recording"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "ID529: Data Management and Analytic Workflows in R",
    "section": "",
    "text": "Details:\n\nFind the course on my.harvard.edu\nCourse Hours: 1:30-5:30 PM\nClassroom: Our classroom will be Kresge G2.\nCourse Dates:\n\nMonday January 13th - Friday January 17th,\nTuesday January 21st - Friday January 24th, 2023\n\nOffice Hours: 11:30 AM – 12:30 PM on Wednesday January 15th, Thursday January 23rd\nLimit 60 students, priority for Population Health Science (PHS) students\n\n\n\n\nData Management and Analytic Workflows in R will introduce students to R programming and modern data management and analysis workflows applied to examples from population health science. Throughout, we will emphasize reproducibility, open science, data visualization, and dynamic document generation. Specific skills learned will include the use of the RStudio integrated development environment, tidy data management practices/workflows, how to get help in programming, and how to use GitHub to track changes in code, disseminate professional work, and integrate feedback. Coursework will consist of lectures, in-class group work, homework, peer assessment, and time for discussion. This course complements graduate-level courses in statistics and quantitative research methods by helping students develop practical skills for conducting independent research incorporating modern data science principles. Students completing this course will have a solid foundation enabling them to handle complex data management tasks and data communication skills for research and professional work.\n\n\n\n\nStudents were very happy with how the class went last winter! Here are some student testionials, shared with students’ permission:\n\n\n\n“I really enjoyed the whole learning experience in this course.”\n\n\n\n\n“Very informative and useful. As a someone who has his first exposure to R, I learned a lot.”\n\n\n\n\n“The teaching team were very supportive and very promptly acted on feedback.”\n\n\n\n\n“It was wonderful! Totally friendly to R beginners. And got a lot positive feedback and encouragement from the teaching team! Shout out to their efforts!”\n\n\n\n\n“Slides that are managed so well! Unparellel instructional team! You are so friendly and patient! I really love that homeworks are managed through Github!”\n\n\n\n\n“I loved this class!! So much was covered but it didn’t feel overwhelming at the same time because the expectation was that we all came in with different levels of experience with R and that these are resources we are introduced to and can always come back to.”\n\n\n\n\nThis course has been excellent! It was exactly what I was looking for - I wanted to kind of catch up to my peers who have had experience in R and learn best practices. R feels a lot less intimidating now, and I know where to look for help. Thank you!\n\n\n\n\nI think this course was great. I am happy that all levels of R were welcome in the course. I felt like I could just do beginner level work and still get a good grade.\n\n\n\n\nExtremely well. I think it will be the most recommended course for whoever wants to gain skills in data management and analysis\n\n\n\nAnd lots more 🙂\n\n\n\n\n\n\nChristian Testa 2nd Year PhD Student Department of Biostatistics  ctesta@hsph.harvard.edu  GitHub   Website   Mastodon   Google Scholar\n\n\n\n\nDean Marengi 4th Year PhD Student Department of Environmental Health  dean_marengi@g.harvard.edu   Google Scholar\n\n\n\n\nJarvis Chen Senior Lecturer Department of Social and Behavioral Sciences  jarvis@hsph.harvard.edu   https://www.hsph.harvard.edu/profile/jarvischen/   Google Scholar\n\n\n\n\n\n\n\nAmanda Hernandez  was an amazing masters student in Environmental Health who helped us develop a lot of material and helped teach the course in Winter Session 2023.\n\n\n\n\n\n\nClick here to go to the syllabus.\n\n\n\n\n\n\nDay 1 — Monday January 13th, 2024\nDay 2 — Tuesday January 14th, 2024\nDay 3 — Wednesday January 15th, 2024\nDay 4 — Thursday January 16th, 2024\nDay 5 — Friday January 17th, 2024\n(MLK Jr. Day on Monday January 15th)\nDay 6 — Tuesday January 21st, 2024\nDay 7 — Wednesday January 22nd, 2024\nDay 8 — Thursday January 23rd, 2024\nDay 9 — Friday January 24th, 2024\n\n\n&lt;div id=\"quarto-navigation-envelope\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden\" data-render-id=\"quarto-int-sidebar-title\"&gt;ID529: Data Management and Analytic Workflows in R&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar-title\"&gt;ID529: Data Management and Analytic Workflows in R&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Home\"&gt;Home&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/index.html\"&gt;/index.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Syllabus\"&gt;Syllabus&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/about.html\"&gt;/about.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Curriculum\"&gt;Curriculum&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 1\"&gt;Day 1&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day1.html\"&gt;/day1.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 2\"&gt;Day 2&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day2.html\"&gt;/day2.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 3\"&gt;Day 3&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day3.html\"&gt;/day3.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 4\"&gt;Day 4&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day4.html\"&gt;/day4.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 5\"&gt;Day 5&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day5.html\"&gt;/day5.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 6\"&gt;Day 6&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day6.html\"&gt;/day6.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 7\"&gt;Day 7&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day7.html\"&gt;/day7.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 8\"&gt;Day 8&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day8.html\"&gt;/day8.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 9\"&gt;Day 9&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/day9.html\"&gt;/day9.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Last Years&#39; Content\"&gt;Last Years’ Content&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day1.html\"&gt;/wi24/day1.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day2.html\"&gt;/wi24/day2.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day3.html\"&gt;/wi24/day3.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day4.html\"&gt;/wi24/day4.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day5.html\"&gt;/wi24/day5.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day6.html\"&gt;/wi24/day6.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day7.html\"&gt;/wi24/day7.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day8.html\"&gt;/wi24/day8.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi24/day9.html\"&gt;/wi24/day9.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Content from 2023\"&gt;Content from 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 1 — Monday January 9, 2023\"&gt;Day 1 — Monday January 9, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day1.html\"&gt;/wi23/day1.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 2 — Tuesday January 10, 2023\"&gt;Day 2 — Tuesday January 10, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day2.html\"&gt;/wi23/day2.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 3 — Wednesday January 11, 2023\"&gt;Day 3 — Wednesday January 11, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day3.html\"&gt;/wi23/day3.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 4 — Thursday January 12, 2023\"&gt;Day 4 — Thursday January 12, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day4.html\"&gt;/wi23/day4.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 5 — Friday January 13, 2023\"&gt;Day 5 — Friday January 13, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day5.html\"&gt;/wi23/day5.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 6 — Tuesday January 17, 2023\"&gt;Day 6 — Tuesday January 17, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day6.html\"&gt;/wi23/day6.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 7 — Wednesday January 18, 2023\"&gt;Day 7 — Wednesday January 18, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day7.html\"&gt;/wi23/day7.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 8 — Thursday January 19, 2023\"&gt;Day 8 — Thursday January 19, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day8.html\"&gt;/wi23/day8.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Day 9 — Friday January 20, 2023\"&gt;Day 9 — Friday January 20, 2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/wi23/day9.html\"&gt;/wi23/day9.html&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div id=\"quarto-meta-markdown\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden\" data-render-id=\"quarto-metatitle\"&gt;ID529: Data Management and Analytic Workflows in R&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercardtitle\"&gt;ID529: Data Management and Analytic Workflows in R&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardtitle\"&gt;ID529: Data Management and Analytic Workflows in R&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-metasitename\"&gt;ID529: Data Management and Analytic Workflows in R&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercarddesc\"&gt;&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardddesc\"&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;/section&gt;\n\n&lt;/main&gt; &lt;!-- /main --&gt;\n&lt;script id = \"quarto-html-after-body\" type=\"application/javascript\"&gt;\nwindow.document.addEventListener(\"DOMContentLoaded\", function (event) {\n  const toggleBodyColorMode = (bsSheetEl) =&gt; {\n    const mode = bsSheetEl.getAttribute(\"data-mode\");\n    const bodyEl = window.document.querySelector(\"body\");\n    if (mode === \"dark\") {\n      bodyEl.classList.add(\"quarto-dark\");\n      bodyEl.classList.remove(\"quarto-light\");\n    } else {\n      bodyEl.classList.add(\"quarto-light\");\n      bodyEl.classList.remove(\"quarto-dark\");\n    }\n  }\n  const toggleBodyColorPrimary = () =&gt; {\n    const bsSheetEl = window.document.querySelector(\"link#quarto-bootstrap\");\n    if (bsSheetEl) {\n      toggleBodyColorMode(bsSheetEl);\n    }\n  }\n  toggleBodyColorPrimary();  \n  const icon = \"\";\n  const anchorJS = new window.AnchorJS();\n  anchorJS.options = {\n    placement: 'right',\n    icon: icon\n  };\n  anchorJS.add('.anchored');\n  const isCodeAnnotation = (el) =&gt; {\n    for (const clz of el.classList) {\n      if (clz.startsWith('code-annotation-')) {                     \n        return true;\n      }\n    }\n    return false;\n  }\n  const clipboard = new window.ClipboardJS('.code-copy-button', {\n    text: function(trigger) {\n      const codeEl = trigger.previousElementSibling.cloneNode(true);\n      for (const childEl of codeEl.children) {\n        if (isCodeAnnotation(childEl)) {\n          childEl.remove();\n        }\n      }\n      return codeEl.innerText;\n    }\n  });\n  clipboard.on('success', function(e) {\n    // button target\n    const button = e.trigger;\n    // don't keep focus\n    button.blur();\n    // flash \"checked\"\n    button.classList.add('code-copy-button-checked');\n    var currentTitle = button.getAttribute(\"title\");\n    button.setAttribute(\"title\", \"Copied!\");\n    let tooltip;\n    if (window.bootstrap) {\n      button.setAttribute(\"data-bs-toggle\", \"tooltip\");\n      button.setAttribute(\"data-bs-placement\", \"left\");\n      button.setAttribute(\"data-bs-title\", \"Copied!\");\n      tooltip = new bootstrap.Tooltip(button, \n        { trigger: \"manual\", \n          customClass: \"code-copy-button-tooltip\",\n          offset: [0, -8]});\n      tooltip.show();    \n    }\n    setTimeout(function() {\n      if (tooltip) {\n        tooltip.hide();\n        button.removeAttribute(\"data-bs-title\");\n        button.removeAttribute(\"data-bs-toggle\");\n        button.removeAttribute(\"data-bs-placement\");\n      }\n      button.setAttribute(\"title\", currentTitle);\n      button.classList.remove('code-copy-button-checked');\n    }, 1000);\n    // clear code selection\n    e.clearSelection();\n  });\n  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {\n    const config = {\n      allowHTML: true,\n      maxWidth: 500,\n      delay: 100,\n      arrow: false,\n      appendTo: function(el) {\n          return el.parentElement;\n      },\n      interactive: true,\n      interactiveBorder: 10,\n      theme: 'quarto',\n      placement: 'bottom-start',\n    };\n    if (contentFn) {\n      config.content = contentFn;\n    }\n    if (onTriggerFn) {\n      config.onTrigger = onTriggerFn;\n    }\n    if (onUntriggerFn) {\n      config.onUntrigger = onUntriggerFn;\n    }\n    window.tippy(el, config); \n  }\n  const noterefs = window.document.querySelectorAll('a[role=\"doc-noteref\"]');\n  for (var i=0; i&lt;noterefs.length; i++) {\n    const ref = noterefs[i];\n    tippyHover(ref, function() {\n      // use id or data attribute instead here\n      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');\n      try { href = new URL(href).hash; } catch {}\n      const id = href.replace(/^#\\/?/, \"\");\n      const note = window.document.getElementById(id);\n      return note.innerHTML;\n    });\n  }\n  const xrefs = window.document.querySelectorAll('a.quarto-xref');\n  const processXRef = (id, note) =&gt; {\n    // Strip column container classes\n    const stripColumnClz = (el) =&gt; {\n      el.classList.remove(\"page-full\", \"page-columns\");\n      if (el.children) {\n        for (const child of el.children) {\n          stripColumnClz(child);\n        }\n      }\n    }\n    stripColumnClz(note)\n    if (id === null || id.startsWith('sec-')) {\n      // Special case sections, only their first couple elements\n      const container = document.createElement(\"div\");\n      if (note.children && note.children.length &gt; 2) {\n        container.appendChild(note.children[0].cloneNode(true));\n        for (let i = 1; i &lt; note.children.length; i++) {\n          const child = note.children[i];\n          if (child.tagName === \"P\" && child.innerText === \"\") {\n            continue;\n          } else {\n            container.appendChild(child.cloneNode(true));\n            break;\n          }\n        }\n        if (window.Quarto?.typesetMath) {\n          window.Quarto.typesetMath(container);\n        }\n        return container.innerHTML\n      } else {\n        if (window.Quarto?.typesetMath) {\n          window.Quarto.typesetMath(note);\n        }\n        return note.innerHTML;\n      }\n    } else {\n      // Remove any anchor links if they are present\n      const anchorLink = note.querySelector('a.anchorjs-link');\n      if (anchorLink) {\n        anchorLink.remove();\n      }\n      if (window.Quarto?.typesetMath) {\n        window.Quarto.typesetMath(note);\n      }\n      // TODO in 1.5, we should make sure this works without a callout special case\n      if (note.classList.contains(\"callout\")) {\n        return note.outerHTML;\n      } else {\n        return note.innerHTML;\n      }\n    }\n  }\n  for (var i=0; i&lt;xrefs.length; i++) {\n    const xref = xrefs[i];\n    tippyHover(xref, undefined, function(instance) {\n      instance.disable();\n      let url = xref.getAttribute('href');\n      let hash = undefined; \n      if (url.startsWith('#')) {\n        hash = url;\n      } else {\n        try { hash = new URL(url).hash; } catch {}\n      }\n      if (hash) {\n        const id = hash.replace(/^#\\/?/, \"\");\n        const note = window.document.getElementById(id);\n        if (note !== null) {\n          try {\n            const html = processXRef(id, note.cloneNode(true));\n            instance.setContent(html);\n          } finally {\n            instance.enable();\n            instance.show();\n          }\n        } else {\n          // See if we can fetch this\n          fetch(url.split('#')[0])\n          .then(res =&gt; res.text())\n          .then(html =&gt; {\n            const parser = new DOMParser();\n            const htmlDoc = parser.parseFromString(html, \"text/html\");\n            const note = htmlDoc.getElementById(id);\n            if (note !== null) {\n              const html = processXRef(id, note);\n              instance.setContent(html);\n            } \n          }).finally(() =&gt; {\n            instance.enable();\n            instance.show();\n          });\n        }\n      } else {\n        // See if we can fetch a full url (with no hash to target)\n        // This is a special case and we should probably do some content thinning / targeting\n        fetch(url)\n        .then(res =&gt; res.text())\n        .then(html =&gt; {\n          const parser = new DOMParser();\n          const htmlDoc = parser.parseFromString(html, \"text/html\");\n          const note = htmlDoc.querySelector('main.content');\n          if (note !== null) {\n            // This should only happen for chapter cross references\n            // (since there is no id in the URL)\n            // remove the first header\n            if (note.children.length &gt; 0 && note.children[0].tagName === \"HEADER\") {\n              note.children[0].remove();\n            }\n            const html = processXRef(null, note);\n            instance.setContent(html);\n          } \n        }).finally(() =&gt; {\n          instance.enable();\n          instance.show();\n        });\n      }\n    }, function(instance) {\n    });\n  }\n      let selectedAnnoteEl;\n      const selectorForAnnotation = ( cell, annotation) =&gt; {\n        let cellAttr = 'data-code-cell=\"' + cell + '\"';\n        let lineAttr = 'data-code-annotation=\"' +  annotation + '\"';\n        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';\n        return selector;\n      }\n      const selectCodeLines = (annoteEl) =&gt; {\n        const doc = window.document;\n        const targetCell = annoteEl.getAttribute(\"data-target-cell\");\n        const targetAnnotation = annoteEl.getAttribute(\"data-target-annotation\");\n        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));\n        const lines = annoteSpan.getAttribute(\"data-code-lines\").split(\",\");\n        const lineIds = lines.map((line) =&gt; {\n          return targetCell + \"-\" + line;\n        })\n        let top = null;\n        let height = null;\n        let parent = null;\n        if (lineIds.length &gt; 0) {\n            //compute the position of the single el (top and bottom and make a div)\n            const el = window.document.getElementById(lineIds[0]);\n            top = el.offsetTop;\n            height = el.offsetHeight;\n            parent = el.parentElement.parentElement;\n          if (lineIds.length &gt; 1) {\n            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);\n            const bottom = lastEl.offsetTop + lastEl.offsetHeight;\n            height = bottom - top;\n          }\n          if (top !== null && height !== null && parent !== null) {\n            // cook up a div (if necessary) and position it \n            let div = window.document.getElementById(\"code-annotation-line-highlight\");\n            if (div === null) {\n              div = window.document.createElement(\"div\");\n              div.setAttribute(\"id\", \"code-annotation-line-highlight\");\n              div.style.position = 'absolute';\n              parent.appendChild(div);\n            }\n            div.style.top = top - 2 + \"px\";\n            div.style.height = height + 4 + \"px\";\n            div.style.left = 0;\n            let gutterDiv = window.document.getElementById(\"code-annotation-line-highlight-gutter\");\n            if (gutterDiv === null) {\n              gutterDiv = window.document.createElement(\"div\");\n              gutterDiv.setAttribute(\"id\", \"code-annotation-line-highlight-gutter\");\n              gutterDiv.style.position = 'absolute';\n              const codeCell = window.document.getElementById(targetCell);\n              const gutter = codeCell.querySelector('.code-annotation-gutter');\n              gutter.appendChild(gutterDiv);\n            }\n            gutterDiv.style.top = top - 2 + \"px\";\n            gutterDiv.style.height = height + 4 + \"px\";\n          }\n          selectedAnnoteEl = annoteEl;\n        }\n      };\n      const unselectCodeLines = () =&gt; {\n        const elementsIds = [\"code-annotation-line-highlight\", \"code-annotation-line-highlight-gutter\"];\n        elementsIds.forEach((elId) =&gt; {\n          const div = window.document.getElementById(elId);\n          if (div) {\n            div.remove();\n          }\n        });\n        selectedAnnoteEl = undefined;\n      };\n        // Handle positioning of the toggle\n    window.addEventListener(\n      \"resize\",\n      throttle(() =&gt; {\n        elRect = undefined;\n        if (selectedAnnoteEl) {\n          selectCodeLines(selectedAnnoteEl);\n        }\n      }, 10)\n    );\n    function throttle(fn, ms) {\n    let throttle = false;\n    let timer;\n      return (...args) =&gt; {\n        if(!throttle) { // first call gets through\n            fn.apply(this, args);\n            throttle = true;\n        } else { // all the others get throttled\n            if(timer) clearTimeout(timer); // cancel #2\n            timer = setTimeout(() =&gt; {\n              fn.apply(this, args);\n              timer = throttle = false;\n            }, ms);\n        }\n      };\n    }\n      // Attach click handler to the DT\n      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');\n      for (const annoteDlNode of annoteDls) {\n        annoteDlNode.addEventListener('click', (event) =&gt; {\n          const clickedEl = event.target;\n          if (clickedEl !== selectedAnnoteEl) {\n            unselectCodeLines();\n            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');\n            if (activeEl) {\n              activeEl.classList.remove('code-annotation-active');\n            }\n            selectCodeLines(clickedEl);\n            clickedEl.classList.add('code-annotation-active');\n          } else {\n            // Unselect the line\n            unselectCodeLines();\n            clickedEl.classList.remove('code-annotation-active');\n          }\n        });\n      }\n  const findCites = (el) =&gt; {\n    const parentEl = el.parentElement;\n    if (parentEl) {\n      const cites = parentEl.dataset.cites;\n      if (cites) {\n        return {\n          el,\n          cites: cites.split(' ')\n        };\n      } else {\n        return findCites(el.parentElement)\n      }\n    } else {\n      return undefined;\n    }\n  };\n  var bibliorefs = window.document.querySelectorAll('a[role=\"doc-biblioref\"]');\n  for (var i=0; i&lt;bibliorefs.length; i++) {\n    const ref = bibliorefs[i];\n    const citeInfo = findCites(ref);\n    if (citeInfo) {\n      tippyHover(citeInfo.el, function() {\n        var popup = window.document.createElement('div');\n        citeInfo.cites.forEach(function(cite) {\n          var citeDiv = window.document.createElement('div');\n          citeDiv.classList.add('hanging-indent');\n          citeDiv.classList.add('csl-entry');\n          var biblioDiv = window.document.getElementById('ref-' + cite);\n          if (biblioDiv) {\n            citeDiv.innerHTML = biblioDiv.innerHTML;\n          }\n          popup.appendChild(citeDiv);\n        });\n        return popup.innerHTML;\n      });\n    }\n  }\n});\n&lt;/script&gt;\n&lt;/div&gt; &lt;!-- /content --&gt;\n\n&lt;/body&gt;\n\n&lt;/html&gt;"
  },
  {
    "objectID": "about.html#slides",
    "href": "about.html#slides",
    "title": "Day 9",
    "section": "Slides",
    "text": "Slides\n\n\n\n\n\n\nView Slides for Intro to ID529\n\n\n\n\n\n\n\n\n\n\nview slides fullscreen  link to pdf slides\n\n\n\n\n\n\nSlides for Final Project Format\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\n\n\n\n\nView Slides for Intro to RStudio and R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\n\n\n\n\nView Slides for Git and GitHub\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to pdf slides"
  },
  {
    "objectID": "about.html#positive-affirmations",
    "href": "about.html#positive-affirmations",
    "title": "Day 9",
    "section": "Positive Affirmations",
    "text": "Positive Affirmations\n\nlink to view fullscreen\nIn text form:\nHere are some affirmations that can help you to reframe your thoughts and let go of any negative self-doubt or impostor syndrome that you may be feeling.\n\nI am capable and competent.\nI am worthy and deserving of success.\nI trust in my abilities and the effort I put forth.\nI am enough, exactly as I am.\nI am learning and growing with each challenge I face.\n\nIt’s important to remember that everyone experiences moments of self-doubt and uncertainty, and it’s okay to not feel confident all the time.\nThe key is to recognize and acknowledge those feelings, and then remind ourselves of our strengths and capabilities.\n\n\n\n\n\n\nVideo Recording from Last Year\n\n\n\n\n\n\n\nApologies we accidentally didn’t capture the RStudio and R talk on this recording. See the prior years’ recording for that section if you’d like.\n\n\n\n\n\n\n\n\n\nVideo Recording from 2023\n\n\n\n\n\n\n\n\n\n\nOutline of topics:\n\nLecture: Intro to R Programming\nLecture: Project Workflow\nActivity: Learnr Tutorials\nLecture: Reading in data\nLecture: Intro to ggplot2\nDiscussion: What makes an effective data visualization?\n\n\n\n\n\n\n\nLecture 1: Programming with R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nLecture 2: Project Workflows in R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to slides PDF \n\n\n\n\n\n\nLecture 3: Reading in Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to slide PDFs  \n\n\n\n\n\n\nLecture 4: Intro to ggplot2\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Recording from 2023"
  },
  {
    "objectID": "about.html#resources",
    "href": "about.html#resources",
    "title": "Day 9",
    "section": "Resources",
    "text": "Resources\n link to daily google doc  \nOutline of topics:\n\nLecture: Intro to dplyr\nLecture: Cleaning Text Data\nActivity: Manipulating Data\nLecture: Writing Functions\nActivity: Functions\n\n\n\n\n\n\n\nLecture 1: Intro to dplyr\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \nlink to slides pdf\n\n\n\n\n\n\nLecture 2: Cleaning Text Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\nlink to slides pdf\n\n\n\n\n\n\nActivity: Cleaning Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\nlink to slides pdf\n\n\n\n\n\n\nLecture 3: Functions\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\nlink to slides pdf\n\n\n\n\n\n\nVideo Recording from Last Year\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Recording from 2023\n\n\n\n\n\n\n\n\n\n\nOutline of topics:\n\nLecture: Diverse Data Sources (APIs [tidycensus, WHO, World Bank, qualtRics], scraping web data, datapasta)\nDiscussion: What kind of sources are students interested in using in their research or future work?\nLecture: How to handle factors and date-times\nLecture: Working with Regression Model Objects: constructing and analyzing them\nActivity: Working with Regression Models\nLecture: Creating Maps in R\nLecture: Reproducible Examples for Getting Help\n\n\n\n\n\n\n\nLecture 1: Diverse Data Sources\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs \n\n\n\n\n\n\nLecture 2: Factors and Date-times\n\n\n\n\n\n\n\nlink to view slides fullscreen  \n\n\n\nlink to follow along code   link to slide PDFs \n\nLecture 3: Regression\n link to slide PDFs  link to repository\n\n\n\n\n\n\nLecture 4: Creating maps in R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs \n\n\n\n\n\n\nLecture 5: Reproducible examples for getting help in R\n\n\n\n\n\n \n\n\n\nlink to view slides fullscreen    link to slide PDFs \n\n\n\n\n\n\nVideo Recording from Last Year\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Recording from 2023\n\n\n\n\n\n\n\n\n\n\nOutline of topics:\n\nLab (1 hour in FXB G12)\nReproducibility and Robustness\nVisualizing and Reporting on Regression\nQR Code Activity\nData Linkage Methods\nOnikye et al Article\n\n\n\n\n\n\n\nCourse Core Concepts Script\n\n\n\n\n\nFind this script online here or written out below:\n# know how to install packages:\n# install.packages(\"tidyverse\")\n\n# set up a project so we could use the {here} package\n\n# dependencies ------------------------------------------------------------\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(here)\nlibrary(palmerpenguins)\nlibrary(gtsummary)\n\n\n# read in data ------------------------------------------------------------\n\n# we could use a csv dataset like this:\n# df &lt;- readr::read_csv(here(\"data.csv\"))\n\n# or use an example dataset like penguins from palmerpenguins:\n# use View to look at it in RStudio\nView(penguins)\n\n\n# data manipulation -------------------------------------------------------\n\n# use group_by and summarize together to create summary statistics per-group\npenguins_summarized &lt;- penguins |&gt;\n  group_by(species) |&gt;\n  summarize(\n    mean_flipper_length_mm = mean(flipper_length_mm, na.rm=TRUE))\n\n# know how to use mutate to update columns (either creating new ones or updating\n# existing ones):\n# here, we'll just convert species to a character vector just for an example\n# so then we can next practice making it a factor:\npenguins &lt;- penguins |&gt;\n  mutate(species = as.character(species))\n\n# convert a variable to a factor:\n#\n# method 1: base R\n# here, the levels will be assumed from the output of unique(penguins$species):\npenguins$species &lt;- factor(penguins$species)\n#\n# method 2: dplyr\npenguins &lt;- penguins |&gt;\n  mutate(species = factor(species))\n\n# if I wanted to change the reference category, I could use relevel:\npenguins$species &lt;- relevel(penguins$species, 'Chinstrap')\n\n# or the dplyr way:\npenguins &lt;- penguins |&gt;\n  mutate(species = relevel(species, 'Chinstrap'))\n# you can also use forcats::fct_relevel\n\n\n# data visualization ------------------------------------------------------\n\n# use ggplot2 to make some graphics\n# a scatter plot:\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point() +\n  ggtitle(\"Penguin Bill Lengths and Depths by Species\")\n\n# use ggsave to save your work\nggsave(here(\"output/penguins_scatterplot.png\"), width = 7, height = 5)\n\n# a histogram with facets:\nggplot(penguins, aes(x = flipper_length_mm)) +\n  geom_histogram() +\n  facet_wrap(~species) +\n  ggtitle(\"Penguin Bill Lengths and Depths by Species\")\n\n# again use ggsave and here() to save it within your project\nggsave(here(\"output/penguins_faceted_histogram.png\"), width = 8, height = 3)\n\n\n# you might also want to plot regression lines in ggplot quickly so\n# use geom_smooth:\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = 'lm') +\n  ggtitle(\"Linear regression of flipper length on body mass\")\n\n\n# analyze a model -------------------------------------------------------------\n\nmodel &lt;- lm(flipper_length_mm ~ body_mass_g + species, penguins)\n\n# use broom::tidy to extract the coefficients and their statistics\nmodel_output &lt;- broom::tidy(model, conf.int = TRUE)\n\n# visualize model results\nmodel_output |&gt;\n  filter(term != '(Intercept)') |&gt;\n  ggplot(aes(x = estimate, y = term, xmin = conf.low, xmax = conf.high)) +\n  geom_pointrange()\n\n# create a table of the results\ngtsummary::tbl_regression(model)\n\n\n# one example with multiple models --------------------------------------------\n\nmodel1 &lt;- lm(flipper_length_mm ~ species, penguins)\nmodel2 &lt;- lm(flipper_length_mm ~ species + body_mass_g, penguins)\nmodel3 &lt;- lm(flipper_length_mm ~ species + body_mass_g + island, penguins)\n\n# extract tables of results\nmodel_results &lt;- list(\n  bind_cols(model = 'model1', broom::tidy(model1, conf.int = TRUE)),\n  bind_cols(model = 'model2', broom::tidy(model2, conf.int = TRUE)),\n  bind_cols(model = 'model3', broom::tidy(model3, conf.int = TRUE)))\n\n# make into one data frame\nmodel_results &lt;- bind_rows(model_results)\n\n# create a plot of covariates from multiple models\nmodel_results |&gt;\n  filter(term %in% c('speciesGentoo', 'speciesAdelie')) |&gt;\n  ggplot(\n       aes(x = estimate,\n           y = term,\n           xmin = conf.low,\n           xmax = conf.high,\n           color = model,\n           shape = model)) +\n  geom_pointrange(position = position_dodge(width = 0.5)) +\n  ggtitle(\"Coefficient estimates for species effect\",\n          stringr::str_wrap(\n            paste(\n              \"Model 1 includes no other covariates, model 2 includes body mass,\",\n              \"and model 3 includes body mass and island effects\"\n            )\n          ))\n\n\n\n\n\n\n\n\n\nLecture 1: Reproducibility and Robustness\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\n\nLecture 2: Regression (part 2!)\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  link to repository \n\n\n\n\n\n\nLecture 3: Data linkage methods\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs   link to follow along code\n\n\n\n\n\n\nBrown et al Response and Reproduction of Onikye et al\n\n\n\n\n\nPreface\nIn 2021 Brown et al published an article titled A Reproduction of the Results of Onyike et al. (2003) in Meta-Psychology, a journal that is free, open-access and conducts open peer review. The Onikye et al. article they reproducing, Is obesity associated with major depression? Results from the Third National Health and Nutrition Examination Survey, was published in the American Journal of Epidemiology has been cited 1159+ times according to Google Scholar.\nI want to point out an interesting section from the About page describing the Meta-Psychology journal that you might keep in mind as you read on:\n\nPrior to publication, all statistical analyses are reproduced by our statistical reproduction team, which consists of the Statistical Editor and our editorial assistant. This makes the article eligible for the reproducibility badge.\n\nRecommended Reading\nPlease read the article by Brown et al (https://open.lnu.se/index.php/metapsychology/article/view/2071).\nAbstract repeated here as a teaser:\n\nOnyike et al. (2003) analyzed data from a large-scale US-American data set, the Third National Health and Nutrition Examination Survey (NHANES-III), and reported an association between obesity and major depression, especially among people with severe obesity. Here, we report the results of a detailed replication of Onyike et al.’s analyses. While we were able to reproduce the majority of these authors’ descriptive statistics, this took a substantial amount of time and effort, and we found several minor errors in the univariate descriptive statistics reported in their Tables 1 and 2. We were able to reproduce most of Onyike et al.’s bivariate findings regarding the relationship between obesity and depression (Tables 3 and 4), albeit with some small discrepancies (e.g., with respect to the magnitudes of standard errors). On the other hand, we were unable to reproduce Table 5, containing Onyike et al.’s findings with respect to the relationship between obesity and depression when controlling for plausible confounding variables—arguably the paper’s most important results—because some of the included predictor variables appear to be either unavailable, or not coded in the way reported by Onyike et al., in the public NHANES-III data sets. We discuss the implications of our findings for the transparency of reporting and the reproducibility of published results.\n\nTheir code is freely, publicly accessible on OSFHOME, a file storage service provided by the Open Science Framework from the Center for Open Science.\n\nBrown et al’s code+file repository: https://osf.io/j32yw/\nDownload their code+files (direct link): https://files.osf.io/v1/resources/j32yw/providers/osfstorage/?zip=\n\nNote that in order to run their code, you will either want to a) make a new R project in the folder with their code on your computer, or b) open a new RStudio window, open up their .R file, and use setwd('filepath/goes/here/') to make sure your R session can run their R code.\nConsider the following questions:\n\nDo you believe that the results Brown et al. have shared are more likely to be correct than those that Onikye et al published? If so, why? If not, why not?\n\nWhat do you find compelling about their re-analysis and code?\nWhat do you find lacking about their re-analysis and code?\n\nHow do you think the non-reproducibility of Onikye et al.’s article could have been avoided?\nWhen, if at all, do you think articles should be required to share code and data?\n\nWhat about in situations where the data relates to private or sensitive data?\nWhat about in situations where the subject matter is highly politically charged and there might be malicious actors who could see shared data and code as additional surface area to attack?\n\nHas reading this article made you more skeptical of research publications that don’t share code?\nDo you think for articles where code & data are too sensitive to be shared, is there an alternative process that would make you similarly confident in the stated results?\n\nAn important aside\nThis isn’t a class about stigma and health, but I think being in a Population Health Science program, it’s important to leave the breadcrumbs here for you to do your own followup reading and learning.\nBecause the articles in this homework discuss body-weight and health, I want to emphatically point out that this subject matter is not at all cut and dry. It’s important to acknowledge that:\n\nWeight-based stigma is real and causes harm to health through multiple mechanisms including at least discrimination and health care practitioners’ attitudes and behaviors:\n\nhttps://ajph.aphapublications.org/doi/full/10.2105/AJPH.2009.159491\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/obr.12266\n\nThe decision by health organizations to classify obesity as a “disease” is debated:\n\nhttps://www.healthline.com/health/is-obesity-a-disease\n\nThe language and terminology that we use can perpetuate stigma:\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC5051141/?report=classic\nhttps://news.yale.edu/2012/07/12/choosing-words-wisely-when-talking-patients-about-their-weight\n\n\nIf anything, what I hope you take away from this aside is that data do not speak for themselves, but rather are subject to interpretation and leave room for either the perpetuation or casting aside of pre-existing biases (See “Data Never Speak for Themselves” from Nancy Krieger’s article Structural Racism, Health Inequities, and the Two-Edged Sword of Data: Structural Problems Require Structural Solutions). It’s not enough to engage with open-science practices and leverage sophisticated statistical analyses made possible in programs like R; instead, it’s necessary to combine advances in the state of the art in computing with advances in our conceptual frameworks to do science that can truly shift narratives in ways that benefit marginalized groups.\n\n\n\n\n\n\n\n\n\nVideo Recording\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\nOutline of topics:\n\nR Markdown\nDebugging\nTime to work on final project\n\n\n\n\n\n\n\nLecture 1: R Markdown\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nLecture 2: Debugging\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nVideo Recording from Last Year\n\n\n\n\n\n\n\n\n\n\nOutline:\n\nAn Analysis Start-to-Finish: Environmental Monitoring\nLongitudinal Data Analysis\nVisualizing Missing Data\nEasy Exploratory Data Analysis\nPrinciples for Clean Code\n\n\n\n\n\n\n\nLecture 1: An Analysis Start to Finish\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen \nlink to slide pdf\n\n\n\n\n\n\nLecture 2: Exploratory data analysis – Longitudinal data analysis\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen   link to slide pdf   link to longitudinal_eda.R script    link to make_simulated_data.R script \n\n\n\n\n\n\nLecture 3: Missing data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs    link to missing-demo.R script \n\n\n\n\n\n\nLecture 4: Accessible exploratory data analysis\n\n\n\n\n\n link to eda.R script \n\n\n\n\n\n\n\n\n\nLecture 5: Clean code and considerate coding\n\n\n\n\n\n\n\nthe tidyverse style guide\n\n\n\nlink to view fullscreen \nlink to pdf \n\n\n\n\n\n\nVideo Recording from 2023\n\n\n\n\n\n\n\n\n\n\nOutline:\n\nPrinciples for Data Analysis\nFunctional Programming\nCOVID OSHA Example\nStudent Choice\nAge Standardization\nBaby Boom Visualization\nR4DS Giveaway\n\n\n\n\n\n\n\nLecture 1: Principles for data analysis\n\n\n\n\n\n\n\n\n\n\n link to view slides fullscreen    link to PDF slides \n\n\n\n\n\n\nLecture 2: Functional Programming\n\n\n\n\n\nlink to functional programming demo script\n\n\n\n\n\n\n\n\n\nCOVID OSHA Project Example\n\n\n\n\n\nLink to Project: https://github.com/ctesta01/covid_osha\n\n\n\n\n\n\n\n\n\nStudent Choice\n\n\n\n\n\nlink to script that goes over requested topics\n\n\n\n\n\n\n\n\n\nKieran Healy’s Baby Boom Data Visualization Poster\n\n\n\n\n\nTogether we took a look at this poster from Kieran Healy and the code from the repository.\nThe example was instructive on a few points:\n\nWe thought it was neat how Kieran used the legend to create a title.\nWe saw how he used cowplot::plot_grid and/or the patchwork package to construct the graphic with multiple panels.\nSeeing how png() and pdf() can be used, similar to ggsave(), to save plots was useful — especially for non-ggplot2 visualizations.\nWe had to do a little bit of debugging, figuring out that we needed to use scale_x_yearmonth() instead of scale_x_date() and we figured that out by 1) reading the error we got in R, and 2) checking what the class/type of the column mapped onto the x aesthetic was.\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\nOutline:\n\nReflections on Final Projects\nGoals for Near Future R Programming (Discussion)\nVery Important Material\nR Project Examples\nGrowing as a Programmer\nCourse Evaluation Survey(s)\n\n\n\n\n\n\n\nReflections on Final Projects\n\n\n\n\n\n\nTo be determined!\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nVery Important Material\n\n\n\n\n\n(posted after class)\n\n\n\n\n\n\n\n\n\nR Project Examples\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nGrowing as a Programmer\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nVideo Recording from 2023"
  },
  {
    "objectID": "about.html#welcome",
    "href": "about.html#welcome",
    "title": "Day 9",
    "section": "Welcome!",
    "text": "Welcome!\nDetails:\n\nFind the course on my.harvard.edu\nCourse Hours: 1:30-5:30 PM\nClassroom: Our classroom will be Kresge G2.\nCourse Dates:\n\nMonday January 13th - Friday January 17th,\nTuesday January 21st - Friday January 24th, 2023\n\nOffice Hours: 11:30 AM – 12:30 PM on Wednesday January 15th, Thursday January 30th\nLimit 60 students, priority for Population Health Science (PHS) students\n\n\nCourse Description\n\nData Management and Analytic Workflows in R will introduce students to R programming and modern data management and analysis workflows applied to examples from population health science. Throughout, we will emphasize reproducibility, open science, data visualization, and dynamic document generation. Specific skills learned will include the use of the RStudio integrated development environment, tidy data management practices/workflows, how to get help in programming, and how to use GitHub to track changes in code, disseminate professional work, and integrate feedback. Coursework will consist of lectures, in-class group work, homework, peer assessment, and time for discussion. This course complements graduate-level courses in statistics and quantitative research methods by helping students develop practical skills for conducting independent research incorporating modern data science principles. Students completing this course will have a solid foundation enabling them to handle complex data management tasks and data communication skills for research and professional work.\n\n\n\nStudent Testimonials\nStudents were very happy with how the class went last winter! Here are some student testionials, shared with the students’ permission:\n\n\n\n“I really enjoyed the whole learning experience in this course.”\n\n\n\n\n“Very informative and useful. As a someone who has his first exposure to R, I learned a lot.”\n\n\n\n\n“The teaching team were very supportive and very promptly acted on feedback.”\n\n\n\n\n“It was wonderful! Totally friendly to R beginners. And got a lot positive feedback and encouragement from the teaching team! Shout out to their efforts!”\n\n\n\n\n“Slides that are managed so well! Unparellel instructional team! You are so friendly and patient! I really love that homeworks are managed through Github!”\n\n\n\n\n“I loved this class!! So much was covered but it didn’t feel overwhelming at the same time because the expectation was that we all came in with different levels of experience with R and that these are resources we are introduced to and can always come back to.”\n\n\n\n\nThis course has been excellent! It was exactly what I was looking for - I wanted to kind of catch up to my peers who have had experience in R and learn best practices. R feels a lot less intimidating now, and I know where to look for help. Thank you!\n\n\n\n\nI think this course was great. I am happy that all levels of R were welcome in the course. I felt like I could just do beginner level work and still get a good grade.\n\n\n\n\nExtremely well. I think it will be the most recommended course for whoever wants to gain skills in data management and analysis\n\n\n\nAnd lots more 🙂\n\n\nInstructional Team\n\n\n\nChristian Testa 2nd Year PhD Student Department of Biostatistics  ctesta@hsph.harvard.edu  GitHub   Website   Mastodon   Google Scholar\n\n\n\n\nDean Marengi 4th Year PhD Student Department of Environmental Health  dean_marengi@g.harvard.edu   Google Scholar\n\n\n\n\nJarvis Chen Senior Lecturer Department of Social and Behavioral Sciences  jarvis@hsph.harvard.edu   https://www.hsph.harvard.edu/profile/jarvischen/   Google Scholar\n\n\n\n\n\nTeaching Alumnus\n\nAmanda Hernandez  was an amazing masters student in Environmental Health who helped us develop a lot of material and helped teach the course in Winter Session 2023.\n\n\n\nGo on to syllabus\n\n\nClick here to go to the syllabus.\n\n\n\n\nJump into the Curriculum\n\nDay 1 — Monday January 13th, 2024\nDay 2 — Tuesday January 14th, 2024\nDay 3 — Wednesday January 15th, 2024\nDay 4 — Thursday January 16th, 2024\nDay 5 — Friday January 17th, 2024\n(MLK Jr. Day on Monday January 15th)\nDay 6 — Tuesday January 21st, 2024\nDay 7 — Wednesday January 22nd, 2024\nDay 8 — Thursday January 23rd, 2024\nDay 9 — Friday January 24th, 2024\n\n\n&lt;/section&gt;\n&lt;/section&gt;\n&lt;section id=\"monday-january-9th\" class=\"level2\"&gt;\n&lt;h2&gt;Monday January 9th&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;1:30-1:40 Welcome to ID529&lt;/li&gt;\n&lt;li&gt;1:40-2:10 Introductory Lecture: Course Details&lt;/li&gt;\n&lt;li&gt;2:10-2:40 Live Demonstration: Modern Data Science Practices in an R Project Based Workflow&lt;/li&gt;\n&lt;li&gt;2:40-2:55 Activity: Q&amp;A + Group reflection on principles shown in the demonstration&lt;/li&gt;\n&lt;li&gt;2:55-3:10 Lecture: Introduce the Final Presentations Format&lt;/li&gt;\n&lt;li&gt;3:10-3:15 Break&lt;/li&gt;\n&lt;li&gt;3:15-3:50: Intro to RStudio and R&lt;/li&gt;\n&lt;li&gt;3:50-4:05: Discussion and Self-Introductions&lt;/li&gt;\n&lt;li&gt;4:05-4:45: Lecture: Intro to Git and GitHub&lt;/li&gt;\n&lt;li&gt;4:45-5:00: Demo of how to do the homework&lt;/li&gt;\n&lt;li&gt;5:00-5:05: Positive Affirmations&lt;/li&gt;\n&lt;li&gt;5:05-5:30 Activity: Setup GitHub accounts + work on the homework + peruse recommended materials + chat with classmates&lt;/li&gt;\n&lt;/ul&gt;\n&lt;section id=\"recommended-materials\" class=\"level3\"&gt;\n&lt;h3&gt;Recommended materials:&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Articles:\n&lt;ul&gt;\n&lt;li&gt;The &lt;em&gt;Introduction&lt;/em&gt; Chapter to R for Data Science: &lt;a href=\"https://r4ds.had.co.nz/explore-intro.html\" class=\"uri\"&gt;https://r4ds.had.co.nz/explore-intro.html&lt;/a&gt; (just one page)&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Excuse me, do you have a moment to talk about version control?&lt;/em&gt; by Jennifer Bryan: &lt;a href=\"https://peerj.com/preprints/3159/\" class=\"uri\"&gt;https://peerj.com/preprints/3159/&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Tutorial: Getting Started with R and RStudio: &lt;a href=\"https://www.dataquest.io/blog/tutorial-getting-started-with-r-and-rstudio/\" class=\"uri\"&gt;https://www.dataquest.io/blog/tutorial-getting-started-with-r-and-rstudio/&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Quickstart from GitHub: &lt;a href=\"https://docs.github.com/en/get-started/quickstart/hello-world\" class=\"uri\"&gt;https://docs.github.com/en/get-started/quickstart/hello-world&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Videos:\n&lt;ul&gt;\n&lt;li&gt;RStudio for the Total Beginner, HRAnalytics101: &lt;a href=\"https://www.youtube.com/watch?v=FIrsOBy5k58\" class=\"uri\"&gt;https://www.youtube.com/watch?v=FIrsOBy5k58&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;If you haven’t already installed R and RStudio, you’ll want to do that, and you can do that by following the instructions here:\n&lt;ul&gt;\n&lt;li&gt;Install R: &lt;a href=\"https://vimeo.com/203516510\" class=\"uri\"&gt;https://vimeo.com/203516510&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Install RStudio: &lt;a href=\"https://vimeo.com/203516968\" class=\"uri\"&gt;https://vimeo.com/203516968&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;section id=\"homework\" class=\"level3\"&gt;\n&lt;h3&gt;Homework:&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Write a bio for yourself and include a picture!&lt;/li&gt;\n&lt;li&gt;Complete the intro to course survey&lt;/li&gt;\n&lt;li&gt;Check that your R and RStudio installations are working on your computer&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;/section&gt;\n&lt;section id=\"video-recording-1\" class=\"level2\"&gt;\n&lt;h2&gt;Video Recording&lt;/h2&gt;\n&lt;iframe width=\"100%\" height=\"500\" src=\"https://www.youtube.com/embed/yxvROGxWys0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;\n\n\n\nResources\n link to daily google doc    link to slide pdfs\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\nlink to view slides fullscreen   link to pdf slides \n\nPositive Affirmations\n\nlink to view fullscreen\nIn text form:\nHere are some affirmations that can help you to reframe your thoughts and let go of any negative self-doubt or impostor syndrome that you may be feeling.\n\nI am capable and competent.\nI am worthy and deserving of success.\nI trust in my abilities and the effort I put forth.\nI am enough, exactly as I am.\nI am learning and growing with each challenge I face.\n\nIt’s important to remember that everyone experiences moments of self-doubt and uncertainty, and it’s okay to not feel confident all the time.\nThe key is to recognize and acknowledge those feelings, and then remind ourselves of our strengths and capabilities.\n\n\n\nTuesday January 10th\n\n1:30-2:00 Lecture: Intro to R Programming (including conditionals, control flow, etc.)\n2:00-2:15 Activity: learnr Tutorial on Conditionals and Control Flow\n2:15-2:45 Lecture: Data Dictionaries and Documentation\n2:45-3:00 Activity: Q&A + Discussion\n3:00-3:05 Break\n3:05-3:35 Lecture: Reading in data of various formats\n3:35-4:30 Lecture: Intro to ggplot2 (common types of figures, faceting, legends, patchwork, and saving figures)\n4:30-4:50 Discussion: What are the ingredients to a ggplot? What makes an effective data visualization?\n4:50-5:10 Demonstration of how to do the homework\n5:10-5:30 Time to work on homework, chat with classmates, peruse recommended materials, engage in self-affirmation\n\n\nHomework:\n\nRead in a dataset of your choice [we will give you some example datasets you can use] and create a few figures using ggplot2. We want to see students include titles, subtitles, captions, data sources, legends, etc.\n\nThe figures should include one univariate figure, one bivariate figure, and one figure using facet_wrap or facet_grid\nIf you’re feeling extra, have fun stylizing your plots! Go wild! Try to change up the background, fonts, etc.\n\n\n\n\nRecommended materials:\n\nOur learnr tutorial on Conditionals, Control Flow, and Logic in R\nSmithsonian Data Management and Best Practices — Describing Your Data: Data Dictionaries\n\nhttps://library.si.edu/sites/default/files/tutorial/pdf/datadictionaries20180226.pdf\n\nU.S. Geological Survey, Data Dictionaries\n\nhttps://www.usgs.gov/data-management/data-dictionaries\n\nSkim the readr cheatsheet:\n\nhttps://raw.githubusercontent.com/rstudio/cheatsheets/main/data-import.pdf\nKeep in mind, your goal shouldn’t be to memorize everything, but rather to get a sense of what functionality is available to you, and how you could reference this cheatsheet or follow up on its contents to make use of it.\n\nFundamentals of Data Visualization, Chapter 2, Visualizing data: Mapping data onto aesthetics:\n\nhttps://clauswilke.com/dataviz/aesthetic-mapping.html\n\nFundamentals of Data Visualization, Chapter 17, The principle of proportional ink:\n\nhttps://clauswilke.com/dataviz/proportional-ink.html\n\n[Video] Introduction to ggplot2 https://www.youtube.com/watch?v=UiuA5sBEcFk\n[Video] BeginneR Workshop https://www.youtube.com/watch?v=7kuPnVZcot0 [lecture starts around 20:00]\n\nCheck the video description for the code files\n\n[Video] Intro to Git and GitHub https://www.youtube.com/watch?v=u4LIpYC0Yaw\n\nTruly extra reading for those interested in advancing their conceptual understanding of ggplot2 and the possibilities in data visualization:\n\nA Layered Grammar of Graphics, by Hadley Wickham http://vita.had.co.nz/papers/layered-grammar.pdf\nStart to get familiar with the ggplot2 book. We recommend starting with subsection 1.2 “What is the grammar of graphics?” here: https://ggplot2-book.org/introduction.html#what-is-the-grammar-of-graphics\nThe R Graph Gallery: https://r-graph-gallery.com/index.html\n\nWhat you can expect from the instructional team:\n\nWe will be reading your bios and working on sorting you into groups for the final presentation topics.\n\n\n\n\nVideo Recording\n\n\n\n\nResources\n link to daily google doc  \n link to slide pdfs\n\nLecture 1: Programming with R\n\n\nlink to view slides fullscreen\n\n  link to slide PDFs  \n\n\nLecture 2: Data Dictionaries and Documentation\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 3: Reading in Data\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 4: Intro to ggplot2\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\nWednesday January 11th\n\n1:30-2:00 Lecture: R Projects\n2:00-2:50 Lecture: Intro to dplyr\n2:50-3:10 Activity: Work on dplyr learnr tutorial in groups\n3:10-3:15 Break\n3:15-3:45 Lecture: Cleaning Text Data\n3:45-4:10 Lecture: Writing Functions\n4:10-4:30 Activity: Write functions together\n4:30-4:45 Activity: Discussion Q&A from ggplot2 Homework\n4:45-4:55 Survey: Checking in on Pacing\n4:55-5:10 Demonstration of how to do the homework\n5:10-5:30 Time to work on homework, chat with classmates, peruse recommended materials\n\n\nRecommended reading:\n\nOn Projects:\n\nTidyverse Blog, Project-Oriented Workflow by Jenny Bryan: https://www.tidyverse.org/blog/2017/12/workflow-vs-script/\nR for Data Science, Chapter 8: https://r4ds.had.co.nz/workflow-projects.html\nProject-Oriented Workflow, Jenny Bryan https://www.tidyverse.org/blog/2017/12/workflow-vs-script/\n\nOn dplyr, cleaning text, and writing functions\n\nR for Data Science, Chapter 5 Data Transformation: https://r4ds.had.co.nz/transform.html\nR for Data Science, Chapter 14 Strings: https://r4ds.had.co.nz/strings.html\nR for Data Science, Chapter 19 Functions: https://r4ds.had.co.nz/functions.html\n\n\n\n\nHomework:\n\nNo homework\n\n\n\n\nVideo Recording\n\n\n\n\nResources\n link to daily google doc    link to PDF slides \n\nLecture 1: Projects in RStudio\n\n\nlink to view slides fullscreen\n\n\nLecture 2: Intro to dplyr\n\n\nlink to view slides fullscreen\n\n\nLecture 4: Cleaning Text Data\n\n\nlink to view slides fullscreen\n\n\nLecture 5: Functions\n\n\nlink to view slides fullscreen\n\n\n\nThursday January 12th\n\n1:30-2:00 Lecture: Diverse Data Sources (APIs [tidycensus, WHO, World Bank, qualtRics], scraping web data, tabulizer, tesseract, datapasta)\n2:00-2:20 Discussion: What kind of sources are students interested in using in their research or future work?\n2:20-2:50 Lecture: How to handle factors and date-times\n2:50-3:00 Break\n3:00-3:30 Lecture: Working with Regression Model Objects: constructing and analyzing them\n3:30-4:15 Activity: Working with Regression Models in R\n4:15-4:45 Lecture: Creating maps in R\n4:45-5:00 Lecture: Reproducible Examples for Getting Help\n5:00-5:30 Time to work on final presentation materials together, peruse recommended materials, chat with classmates\n\n\nHomework:\n\nFit and report on a regression model including categorical (factor) variables\nPeer Review for Homework 2\n\n\n\nRecommended Materials\nRemember! You don’t have to read all of this! Just focus on what’s most useful to you:\n\nTidy Data by Hadley Wickham https://vita.had.co.nz/papers/tidy-data.pdf\nDiverse Data Sources\n\nThe readme to the datapasta package: https://github.com/MilesMcBain/datapasta\nAnalyzing US Census Data by Kyle Walker, Chapter 2: An introduction to tidycensus: https://walker-data.com/census-r/an-introduction-to-tidycensus.html\nThe readr cheatsheet: https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-import.pdf\nWorking with Qualtrics Data - Part 1: Importing Data, ROpenSci https://ropensci.org/blog/2022/08/02/working-with-qualtrics-data-importing/\n\nHandling factors and date-times in R:\n\nChapter 15: Factors, R for Data Science by Hadley Wickham and Garrett Grolemund https://r4ds.had.co.nz/factors.html\nChapter 16: Dates and Times, R for Data Science by Hadley Wickham and Garrett Grolemund https://r4ds.had.co.nz/dates-and-times.html\nForcats cheatsheet https://raw.githubusercontent.com/rstudio/cheatsheets/main/factors.pdf\nLubridate cheatsheet https://raw.githubusercontent.com/rstudio/cheatsheets/main/lubridate.pdf\n\nWorking with Regression Models:\n\nIntroduction to broom https://broom.tidymodels.org/articles/broom.html\nA nice introduction to linear model diagnostics plots: https://book.stat420.org/model-diagnostics.html\nInterpretation of R’s lm() output: https://stats.stackexchange.com/questions/5135/interpretation-of-rs-lm-output\n\nMapping:\n\nChapter 8 Plotting Spatial Data, Spatial Data Science https://r-spatial.org/book/08-Plotting.html\n\nThis focuses more on sf which is the most modern and increasingly most popular paradigm for working with spatial data in R\n\nChapter 9 Making Maps with R, Geocomputation with R https://geocompr.robinlovelace.net/adv-map.html\n\nThis chapter has a lot of focus on tmap, a package for creating thematic maps\n\n\n\n\n\n\nVideo Recording\n\n\n\n\nResources\n link to daily google doc    link to PDF slides\n\nLecture 1: Diverse Data Sources\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 2: Factors and Date-times\n\n\nlink to view slides fullscreen  link to follow along code   link to slide PDFs  \n\n\nLecture 3: Regression\n link to slide PDFs  link to repository \n\n\nLecture 4: Creating maps in R\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 5: Reproducible examples for getting help in R\n  link to view slides fullscreen    link to slide PDFs  \n\n\n\nFriday January 13th\n\n1:30-2:00 Lecture: Why reproducibility and robustness are important principles in science and data analysis and acknowledging the pressures in academia that push people away from reproducible science\n2:00-2:15 Discussion\n2:15-2:45 Lecture: Visualizing and Reporting on Regression Models\n2:45-3:05 Lecture: Data Linkage Methods\n3:05-3:25 Activity: Working with Joins\n3:25-3:35 Break\n3:35-4:00 Activity: Hallway QR Code Challenges\n4:00-4:15 Lecture: Introduction of the Brown et al (partial) reproduction of Onikye et al’s results\n4:15-4:30 Homework demonstration\n4:30-5:25 Time to work on homework + chat together + work on final projects\n5:25-5:30 Giveaway for a Copy of R for Data Science\n5:30 Meet Hodu!\n\n\nHomework 4\n\nRead the Brown et al reproduction of Onikye et al, run their code, and fill out the worksheet\n\nhttps://open.lnu.se/index.php/metapsychology/article/view/2071\nhttps://osf.io/j32yw/\n\nPeer review for homework 3\n\n\n\nAvailable/Recommended Materials:\n\nReproducibility:\n\nDraw Me A Project https://masalmon.eu/2021/06/30/r-projects/\nReproducibility of Scientific Results https://plato.stanford.edu/entries/scientific-reproducibility/\nBest Practices for Scientific Computing https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745\nGood Enough Practices for Scientific Computing https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510\nReplicability, Robustness, and Reproducibility in Psychological Science https://pure.uvt.nl/ws/portalfiles/portal/59415163/MTO_Nuijten_replicability_robustness_and_reproducibility_Annual_Review_of_Psy_2022.pdf\nA manifesto for reproducible science https://www.nature.com/articles/s41562-016-0021\n\nRegression Modeling:\n\nIntroduction to Poisson Regression, Beyond Multiple Linear Regression https://bookdown.org/roback/bookdown-BeyondMLR/ch-poissonreg.html\nPoisson Regression https://rpubs.com/franzbischoff/poisson_regression\nLogistic Regression, Beyond Multiple Linear Regression https://bookdown.org/roback/bookdown-BeyondMLR/ch-logreg.html\n\n\n\n\n\nVideo Recording\n\n\n\n\nResources\n link to daily google doc    link to PDF slides\n\nLecture 1: Reproducibility and Robustness\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 2: Regression (part 2!)\n link to slide PDFs  link to repository \n\n\nLecture 3: Data linkage methods\n\n\nlink to view slides fullscreen   link to slide PDFs   link to follow along code \n\n\n\nTuesday January 17th\n\n1:30-1:50 Activity: Discussion of Onikye et al reproduction article\n1:50-2:10 Lecture: Introduction to R Packages\n2:10-2:30 Demonstration of how to create R packages that standardize data loading and cleaning processes\n2:30-3:00 Lecture: How to use R Markdown to produce reproducible reports including tables, visualizations, and inline-quantitative statements.\n3:00-3:10 Break\n3:10-3:30 Activity: Experiment with different R Markdown features\n3:30-3:50 Lecture: Advice for Debugging\n3:50-4:10 Activity: Debugging\n4:10-4:30 Activity: Getting Help Online\n4:30-4:45 Demonstration of how to do the homework\n4:45-5:30 Time to do the homework, work on the final project together, peruse recommended materials\n\n\nHomework 5:\n\nUse R Markdown to document some exploratory data analyses\n\n\n\nRecommended Materials:\n\nR Packages:\n\nRead Karl Broman’s Why write an R package?\nFamiliarize yourself with what’s in the R Packages book: https://r-pkgs.org/ — having a rough familiarity with the different parts will be helpful. Our suggestion here is to try and approach this more in terms of “what are the ingredients in a good R Package?” rather than trying to learn how to craft all of those ingredients from the ground up immediately.\n\nR Markdown:\n\nCheck out the Get Started for R Markdown, especially the ~1 minute video intro on the first page: https://rmarkdown.rstudio.com/lesson-1.html\nHow R Helps Airbnb Make the Most of Its Data\nIf you find yourself loving R Markdown, you may find the R Markdown Cookbook useful, but it is incredibly comprehensive and we’d suggest it’s better to reference as you need it than to try to read it cover-to-cover.\n\n\n\n\n\nVideo Recording\n\n\n\n\nResources\n link to daily google doc    link to PDF slides\n\nLecture 1: Packages\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 2: RMarkdown\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 3: Debugging\n\n\nlink to view slides fullscreen \n link to slide PDFs  \n link to live coding example reproducing a map of literacy rates in India from Wikipedia  \n\n\n\nWednesday January 18th\n\n1:30-2:00 Lecture: A Data Analysis from Start to Finish\n2:00-2:30 Lecture: Longitudinal Data Analysis\n2:30-3:00 Lecture: Best practices for reporting on missing data\n3:00-3:30 Lecture: Intro to accessible exploratory data analysis methods: Correlation, principal components analysis, variable importance\n3:30-3:40 Break\n3:40-4:00 Discussion: What are the ethical principles involved in data analysis? What are the risks involved?\n4:00-4:30 Lecture: Clean Code and Considerate Coding\n4:30-5:30 Free time to work together on the final project, chat with classmates, peruse recommended materials\n\n\nHomework:\n\nPeer Review Homework 5\n\n\n\nRecommended Materials:\n\nHarms and Ethics in Data Science and Machine Learning:\n\nThe Data Science Ethics chapter from the Modern Data Science with R book: https://mdsr-book.github.io/mdsr2e/ch-ethics.html\n\n\n\n\n\nVideo Recording\n\n\n\n\nResources\n link to daily google doc    link to PDF slides\n\n\nLecture 2: Exploratory data analysis – Longitudinal data analysis\n link to longitudinal_eda.R script    link to make_simulated_data.R script \n\n\nLecture 3: Missing data\n\n\nlink to view slides fullscreen   link to slide PDFs    link to missing-demo.R script \n\n\nLecture 4: Accessible exploratory data analysis\n link to eda.R script \n\n\nLecture 5: Clean code and considerate coding\n\n\n\n\nThursday January 19th\n\n1:30-2:00 Lecture/Demo: Principles for Data Analysis from Start to Finish\n2:00-2:30 Lecture: Functional Programming\n2:30-3:00 Discussion + Demo: When does it make sense to use functional programming?\n3:00-3:10 Break\n3:10-3:40 Lecture: [Students’ Choice]\n3:40-4:10 Lecture: How to Keep Growing as a Programmer (and stay up to date)\n4:10-4:20 Details about turning in your final presentations\n4:20-5:30 Positive affirmations, free time to work together on final projects\n\n\nHomework:\n\nWork with classmates to finalize presentations and turn them in\n\n\n\nRecommended materials:\n\nHadley Wickham on Many Models: https://youtu.be/cU0-NrUxRw4\n\n\n\n\nVideo Recording\n\n\nApologies the lecture recording didn’t capture the first lecture of the day.\n\n\nResources\n  link to PDF slides   link to daily google doc  \n\nLecture 1: Principles for data analysis\n\n\n link to view slides fullscreen    link to PDF slides \n\n\nLecture 2: Functional Programming\n link to functional_programming.R script \n\n\nLecture 3: dplyr (student choice)\n dplyr_demo.R script \n\n\nLecture 4: Growing as a programmer\n\n\n link to view slides fullscreen   link to PDF slides\n\n\n\nFriday January 20th\n\n1:30-4:30 Final Presentations:\n\nStudents will be divided into 10 groups with 10-12 minutes presentation time and 3-5 minutes for feedback from the instructional team and Q&A from the audience.\n15 minutes × 10 groups = ~2.5 hours\nwe’ll make sure to take some breaks between every few groups\n\n4:30-5:00 Lecture: Recap of Key Takeaways\n5:00-5:30:\n\nMake sure you’ve uploaded your presentation!\nFeedback and Course Evaluations\n\n\nEnjoy being done with the class and go on to do great things with your newly learned R skills!\n\n\nVideo Recording\n\n\n\n\nStudent Presentations\n\nClean Code and Code Hygeine\n\n\n\n\nCode Commenting and Documentation\n\n\n\n\nData Dictionaries\n\n\n\n\nData Visualization (Group 1)\n\n\n\n\nData Visualization (Group 2)\n\n\n\n\nPresenting Model Results\n\n\n\n\nGeographic Maps\n\n\n\n\n\nFinal lecture: Recap\n\n\n link to view slides fullscreen    link to PDF slides \n\nOutline of Topics\n\nWelcome\nIntro to the Course\nDemo\nRStudio and R, Git and GitHub\n\n\n\nSlides\n\n\n\n\n\n\nView Slides for Intro to ID529\n\n\n\n\n\n\n\n\n\n\nview slides fullscreen  link to pdf slides\n\n\n\n\n\n\nSlides for Final Project Format\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\n\n\n\n\nView Slides for Intro to RStudio and R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\n\n\n\n\nView Slides for Git and GitHub\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to pdf slides \n\n\nPositive Affirmations\n\nlink to view fullscreen\nIn text form:\nHere are some affirmations that can help you to reframe your thoughts and let go of any negative self-doubt or impostor syndrome that you may be feeling.\n\nI am capable and competent.\nI am worthy and deserving of success.\nI trust in my abilities and the effort I put forth.\nI am enough, exactly as I am.\nI am learning and growing with each challenge I face.\n\nIt’s important to remember that everyone experiences moments of self-doubt and uncertainty, and it’s okay to not feel confident all the time.\nThe key is to recognize and acknowledge those feelings, and then remind ourselves of our strengths and capabilities.\n\n\n\n\n\n\nVideo Recording from This Year\n\n\n\n\n\n\n\nApologies we accidentally didn’t capture the RStudio and R talk on this recording. See the prior years’ recording for that section if you’d like.\n\n\n\n\n\n\n\n\n\nVideo Recording from Last Year\n\n\n\n\n\n\n\n\n\n\nOutline of topics:\n\nLecture: Intro to R Programming\nLecture: Project Workflow\nActivity: Learnr Tutorials\nLecture: Reading in data\nLecture: Intro to ggplot2\nDiscussion: What makes an effective data visualization?\n\n\n\n\n\n\n\nLecture 1: Programming with R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nLecture 2: Project Workflows in R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to slides PDF \n\n\n\n\n\n\nLecture 3: Reading in Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to slide PDFs  \n\n\n\n\n\n\nLecture 4: Intro to ggplot2\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nThis Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\n\n\nResources\n link to daily google doc  \nOutline of topics:\n\nLecture: Intro to dplyr\nLecture: Cleaning Text Data\nActivity: Manipulating Data\nLecture: Writing Functions\nActivity: Functions\n\n\n\n\n\n\n\nLecture 1: Intro to dplyr\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \nlink to slides pdf\n\n\n\n\n\n\nLecture 2: Cleaning Text Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\nlink to slides pdf\n\n\n\n\n\n\nActivity: Cleaning Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\nlink to slides pdf\n\n\n\n\n\n\nLecture 3: Functions\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\nlink to slides pdf\n\n\n\n\n\n\nVideo Recording\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\nOutline of topics:\n\nLecture: Diverse Data Sources (APIs [tidycensus, WHO, World Bank, qualtRics], scraping web data, datapasta)\nDiscussion: What kind of sources are students interested in using in their research or future work?\nLecture: How to handle factors and date-times\nLecture: Working with Regression Model Objects: constructing and analyzing them\nActivity: Working with Regression Models\nLecture: Creating Maps in R\nLecture: Reproducible Examples for Getting Help\n\n\n\n\n\n\n\nLecture 1: Diverse Data Sources\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs \n\n\n\n\n\n\nLecture 2: Factors and Date-times\n\n\n\n\n\n\n\nlink to view slides fullscreen  \n\n\n\nlink to follow along code   link to slide PDFs \n\nLecture 3: Regression\n link to slide PDFs  link to repository\n\n\n\n\n\n\nLecture 4: Creating maps in R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs \n\n\n\n\n\n\nLecture 5: Reproducible examples for getting help in R\n\n\n\n\n\n \n\n\n\nlink to view slides fullscreen    link to slide PDFs \n\n\n\n\n\n\nVideo Recording\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\nOutline of topics:\n\nLab (1 hour in FXB G12)\nReproducibility and Robustness\nVisualizing and Reporting on Regression\nQR Code Activity\nData Linkage Methods\nOnikye et al Article\n\n\n\n\n\n\n\nCourse Core Concepts Script\n\n\n\n\n\nFind this script online here or written out below:\n# know how to install packages:\n# install.packages(\"tidyverse\")\n\n# set up a project so we could use the {here} package\n\n# dependencies ------------------------------------------------------------\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(here)\nlibrary(palmerpenguins)\nlibrary(gtsummary)\n\n\n# read in data ------------------------------------------------------------\n\n# we could use a csv dataset like this:\n# df &lt;- readr::read_csv(here(\"data.csv\"))\n\n# or use an example dataset like penguins from palmerpenguins:\n# use View to look at it in RStudio\nView(penguins)\n\n\n# data manipulation -------------------------------------------------------\n\n# use group_by and summarize together to create summary statistics per-group\npenguins_summarized &lt;- penguins |&gt;\n  group_by(species) |&gt;\n  summarize(\n    mean_flipper_length_mm = mean(flipper_length_mm, na.rm=TRUE))\n\n# know how to use mutate to update columns (either creating new ones or updating\n# existing ones):\n# here, we'll just convert species to a character vector just for an example\n# so then we can next practice making it a factor:\npenguins &lt;- penguins |&gt;\n  mutate(species = as.character(species))\n\n# convert a variable to a factor:\n#\n# method 1: base R\n# here, the levels will be assumed from the output of unique(penguins$species):\npenguins$species &lt;- factor(penguins$species)\n#\n# method 2: dplyr\npenguins &lt;- penguins |&gt;\n  mutate(species = factor(species))\n\n# if I wanted to change the reference category, I could use relevel:\npenguins$species &lt;- relevel(penguins$species, 'Chinstrap')\n\n# or the dplyr way:\npenguins &lt;- penguins |&gt;\n  mutate(species = relevel(species, 'Chinstrap'))\n# you can also use forcats::fct_relevel\n\n\n# data visualization ------------------------------------------------------\n\n# use ggplot2 to make some graphics\n# a scatter plot:\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point() +\n  ggtitle(\"Penguin Bill Lengths and Depths by Species\")\n\n# use ggsave to save your work\nggsave(here(\"output/penguins_scatterplot.png\"), width = 7, height = 5)\n\n# a histogram with facets:\nggplot(penguins, aes(x = flipper_length_mm)) +\n  geom_histogram() +\n  facet_wrap(~species) +\n  ggtitle(\"Penguin Bill Lengths and Depths by Species\")\n\n# again use ggsave and here() to save it within your project\nggsave(here(\"output/penguins_faceted_histogram.png\"), width = 8, height = 3)\n\n\n# you might also want to plot regression lines in ggplot quickly so\n# use geom_smooth:\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = 'lm') +\n  ggtitle(\"Linear regression of flipper length on body mass\")\n\n\n# analyze a model -------------------------------------------------------------\n\nmodel &lt;- lm(flipper_length_mm ~ body_mass_g + species, penguins)\n\n# use broom::tidy to extract the coefficients and their statistics\nmodel_output &lt;- broom::tidy(model, conf.int = TRUE)\n\n# visualize model results\nmodel_output |&gt;\n  filter(term != '(Intercept)') |&gt;\n  ggplot(aes(x = estimate, y = term, xmin = conf.low, xmax = conf.high)) +\n  geom_pointrange()\n\n# create a table of the results\ngtsummary::tbl_regression(model)\n\n\n# one example with multiple models --------------------------------------------\n\nmodel1 &lt;- lm(flipper_length_mm ~ species, penguins)\nmodel2 &lt;- lm(flipper_length_mm ~ species + body_mass_g, penguins)\nmodel3 &lt;- lm(flipper_length_mm ~ species + body_mass_g + island, penguins)\n\n# extract tables of results\nmodel_results &lt;- list(\n  bind_cols(model = 'model1', broom::tidy(model1, conf.int = TRUE)),\n  bind_cols(model = 'model2', broom::tidy(model2, conf.int = TRUE)),\n  bind_cols(model = 'model3', broom::tidy(model3, conf.int = TRUE)))\n\n# make into one data frame\nmodel_results &lt;- bind_rows(model_results)\n\n# create a plot of covariates from multiple models\nmodel_results |&gt;\n  filter(term %in% c('speciesGentoo', 'speciesAdelie')) |&gt;\n  ggplot(\n       aes(x = estimate,\n           y = term,\n           xmin = conf.low,\n           xmax = conf.high,\n           color = model,\n           shape = model)) +\n  geom_pointrange(position = position_dodge(width = 0.5)) +\n  ggtitle(\"Coefficient estimates for species effect\",\n          stringr::str_wrap(\n            paste(\n              \"Model 1 includes no other covariates, model 2 includes body mass,\",\n              \"and model 3 includes body mass and island effects\"\n            )\n          ))\n\n\n\n\n\n\n\n\n\nLecture 1: Reproducibility and Robustness\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\n\nLecture 2: Regression (part 2!)\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  link to repository \n\n\n\n\n\n\nLecture 3: Data linkage methods\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs   link to follow along code\n\n\n\n\n\n\nBrown et al Response and Reproduction of Onikye et al\n\n\n\n\n\nPreface\nIn 2021 Brown et al published an article titled A Reproduction of the Results of Onyike et al. (2003) in Meta-Psychology, a journal that is free, open-access and conducts open peer review. The Onikye et al. article they reproducing, Is obesity associated with major depression? Results from the Third National Health and Nutrition Examination Survey, was published in the American Journal of Epidemiology has been cited 1159+ times according to Google Scholar.\nI want to point out an interesting section from the About page describing the Meta-Psychology journal that you might keep in mind as you read on:\n\nPrior to publication, all statistical analyses are reproduced by our statistical reproduction team, which consists of the Statistical Editor and our editorial assistant. This makes the article eligible for the reproducibility badge.\n\nRecommended Reading\nPlease read the article by Brown et al (https://open.lnu.se/index.php/metapsychology/article/view/2071).\nAbstract repeated here as a teaser:\n\nOnyike et al. (2003) analyzed data from a large-scale US-American data set, the Third National Health and Nutrition Examination Survey (NHANES-III), and reported an association between obesity and major depression, especially among people with severe obesity. Here, we report the results of a detailed replication of Onyike et al.’s analyses. While we were able to reproduce the majority of these authors’ descriptive statistics, this took a substantial amount of time and effort, and we found several minor errors in the univariate descriptive statistics reported in their Tables 1 and 2. We were able to reproduce most of Onyike et al.’s bivariate findings regarding the relationship between obesity and depression (Tables 3 and 4), albeit with some small discrepancies (e.g., with respect to the magnitudes of standard errors). On the other hand, we were unable to reproduce Table 5, containing Onyike et al.’s findings with respect to the relationship between obesity and depression when controlling for plausible confounding variables—arguably the paper’s most important results—because some of the included predictor variables appear to be either unavailable, or not coded in the way reported by Onyike et al., in the public NHANES-III data sets. We discuss the implications of our findings for the transparency of reporting and the reproducibility of published results.\n\nTheir code is freely, publicly accessible on OSFHOME, a file storage service provided by the Open Science Framework from the Center for Open Science.\n\nBrown et al’s code+file repository: https://osf.io/j32yw/\nDownload their code+files (direct link): https://files.osf.io/v1/resources/j32yw/providers/osfstorage/?zip=\n\nNote that in order to run their code, you will either want to a) make a new R project in the folder with their code on your computer, or b) open a new RStudio window, open up their .R file, and use setwd('filepath/goes/here/') to make sure your R session can run their R code.\nConsider the following questions:\n\nDo you believe that the results Brown et al. have shared are more likely to be correct than those that Onikye et al published? If so, why? If not, why not?\n\nWhat do you find compelling about their re-analysis and code?\nWhat do you find lacking about their re-analysis and code?\n\nHow do you think the non-reproducibility of Onikye et al.’s article could have been avoided?\nWhen, if at all, do you think articles should be required to share code and data?\n\nWhat about in situations where the data relates to private or sensitive data?\nWhat about in situations where the subject matter is highly politically charged and there might be malicious actors who could see shared data and code as additional surface area to attack?\n\nHas reading this article made you more skeptical of research publications that don’t share code?\nDo you think for articles where code & data are too sensitive to be shared, is there an alternative process that would make you similarly confident in the stated results?\n\nAn important aside\nThis isn’t a class about stigma and health, but I think being in a Population Health Science program, it’s important to leave the breadcrumbs here for you to do your own followup reading and learning.\nBecause the articles in this homework discuss body-weight and health, I want to emphatically point out that this subject matter is not at all cut and dry. It’s important to acknowledge that:\n\nWeight-based stigma is real and causes harm to health through multiple mechanisms including at least discrimination and health care practitioners’ attitudes and behaviors:\n\nhttps://ajph.aphapublications.org/doi/full/10.2105/AJPH.2009.159491\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/obr.12266\n\nThe decision by health organizations to classify obesity as a “disease” is debated:\n\nhttps://www.healthline.com/health/is-obesity-a-disease\n\nThe language and terminology that we use can perpetuate stigma:\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC5051141/?report=classic\nhttps://news.yale.edu/2012/07/12/choosing-words-wisely-when-talking-patients-about-their-weight\n\n\nIf anything, what I hope you take away from this aside is that data do not speak for themselves, but rather are subject to interpretation and leave room for either the perpetuation or casting aside of pre-existing biases (See “Data Never Speak for Themselves” from Nancy Krieger’s article Structural Racism, Health Inequities, and the Two-Edged Sword of Data: Structural Problems Require Structural Solutions). It’s not enough to engage with open-science practices and leverage sophisticated statistical analyses made possible in programs like R; instead, it’s necessary to combine advances in the state of the art in computing with advances in our conceptual frameworks to do science that can truly shift narratives in ways that benefit marginalized groups.\n\n\n\n\n\n\n\n\n\nVideo Recording\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\nOutline of topics:\n\nR Markdown\nDebugging\nTime to work on final project\n\n\n\n\n\n\n\nLecture 1: R Markdown\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nLecture 2: Debugging\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nVideo Recording from Last Year\n\n\n\n\n\n\n\n\n\n\nOutline:\n\nAn Analysis Start-to-Finish: Environmental Monitoring\nLongitudinal Data Analysis\nVisualizing Missing Data\nEasy Exploratory Data Analysis\nPrinciples for Clean Code\n\n\n\n\n\n\n\nLecture 1: An Analysis Start to Finish\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen \nlink to slide pdf\n\n\n\n\n\n\nLecture 2: Exploratory data analysis – Longitudinal data analysis\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen   link to slide pdf   link to longitudinal_eda.R script    link to make_simulated_data.R script \n\n\n\n\n\n\nLecture 3: Missing data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs    link to missing-demo.R script \n\n\n\n\n\n\nLecture 4: Accessible exploratory data analysis\n\n\n\n\n\n link to eda.R script \n\n\n\n\n\n\n\n\n\nLecture 5: Clean code and considerate coding\n\n\n\n\n\n\n\nthe tidyverse style guide\n\n\n\nlink to view fullscreen \nlink to pdf \n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\nOutline:\n\nPrinciples for Data Analysis\nFunctional Programming\nCOVID OSHA Example\nStudent Choice\nAge Standardization\nBaby Boom Visualization\nR4DS Giveaway\n\n\n\n\n\n\n\nLecture 1: Principles for data analysis\n\n\n\n\n\n\n\n\n\n\n link to view slides fullscreen    link to PDF slides \n\n\n\n\n\n\nLecture 2: Functional Programming\n\n\n\n\n\nlink to functional programming demo script\n\n\n\n\n\n\n\n\n\nCOVID OSHA Project Example\n\n\n\n\n\nLink to Project: https://github.com/ctesta01/covid_osha\n\n\n\n\n\n\n\n\n\nStudent Choice\n\n\n\n\n\nlink to script that goes over requested topics\n\n\n\n\n\n\n\n\n\nKieran Healy’s Baby Boom Data Visualization Poster\n\n\n\n\n\nTogether we took a look at this poster from Kieran Healy and the code from the repository.\nThe example was instructive on a few points:\n\nWe thought it was neat how Kieran used the legend to create a title.\nWe saw how he used cowplot::plot_grid and/or the patchwork package to construct the graphic with multiple panels.\nSeeing how png() and pdf() can be used, similar to ggsave(), to save plots was useful — especially for non-ggplot2 visualizations.\nWe had to do a little bit of debugging, figuring out that we needed to use scale_x_yearmonth() instead of scale_x_date() and we figured that out by 1) reading the error we got in R, and 2) checking what the class/type of the column mapped onto the x aesthetic was.\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\nOutline:\n\nReflections on Final Projects\nGoals for Near Future R Programming (Discussion)\nVery Important Material\nR Project Examples\nGrowing as a Programmer\nCourse Evaluation Survey(s)\n\n\n\n\n\n\n\nReflections on Final Projects\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nVery Important Material\n\n\n\n\n\n(posted after class)\n\n\n\n\n\n\n\n\n\nR Project Examples\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nGrowing as a Programmer\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nLast Year’s Video Recording"
  },
  {
    "objectID": "about.html#resources-1",
    "href": "about.html#resources-1",
    "title": "Day 9",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to slide pdfs\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\nlink to view slides fullscreen   link to pdf slides \n\nPositive Affirmations\n\nlink to view fullscreen\nIn text form:\nHere are some affirmations that can help you to reframe your thoughts and let go of any negative self-doubt or impostor syndrome that you may be feeling.\n\nI am capable and competent.\nI am worthy and deserving of success.\nI trust in my abilities and the effort I put forth.\nI am enough, exactly as I am.\nI am learning and growing with each challenge I face.\n\nIt’s important to remember that everyone experiences moments of self-doubt and uncertainty, and it’s okay to not feel confident all the time.\nThe key is to recognize and acknowledge those feelings, and then remind ourselves of our strengths and capabilities."
  },
  {
    "objectID": "about.html#tuesday-january-10th",
    "href": "about.html#tuesday-january-10th",
    "title": "Day 9",
    "section": "Tuesday January 10th",
    "text": "Tuesday January 10th\n\n1:30-2:00 Lecture: Intro to R Programming (including conditionals, control flow, etc.)\n2:00-2:15 Activity: learnr Tutorial on Conditionals and Control Flow\n2:15-2:45 Lecture: Data Dictionaries and Documentation\n2:45-3:00 Activity: Q&A + Discussion\n3:00-3:05 Break\n3:05-3:35 Lecture: Reading in data of various formats\n3:35-4:30 Lecture: Intro to ggplot2 (common types of figures, faceting, legends, patchwork, and saving figures)\n4:30-4:50 Discussion: What are the ingredients to a ggplot? What makes an effective data visualization?\n4:50-5:10 Demonstration of how to do the homework\n5:10-5:30 Time to work on homework, chat with classmates, peruse recommended materials, engage in self-affirmation\n\n\nHomework:\n\nRead in a dataset of your choice [we will give you some example datasets you can use] and create a few figures using ggplot2. We want to see students include titles, subtitles, captions, data sources, legends, etc.\n\nThe figures should include one univariate figure, one bivariate figure, and one figure using facet_wrap or facet_grid\nIf you’re feeling extra, have fun stylizing your plots! Go wild! Try to change up the background, fonts, etc.\n\n\n\n\nRecommended materials:\n\nOur learnr tutorial on Conditionals, Control Flow, and Logic in R\nSmithsonian Data Management and Best Practices — Describing Your Data: Data Dictionaries\n\nhttps://library.si.edu/sites/default/files/tutorial/pdf/datadictionaries20180226.pdf\n\nU.S. Geological Survey, Data Dictionaries\n\nhttps://www.usgs.gov/data-management/data-dictionaries\n\nSkim the readr cheatsheet:\n\nhttps://raw.githubusercontent.com/rstudio/cheatsheets/main/data-import.pdf\nKeep in mind, your goal shouldn’t be to memorize everything, but rather to get a sense of what functionality is available to you, and how you could reference this cheatsheet or follow up on its contents to make use of it.\n\nFundamentals of Data Visualization, Chapter 2, Visualizing data: Mapping data onto aesthetics:\n\nhttps://clauswilke.com/dataviz/aesthetic-mapping.html\n\nFundamentals of Data Visualization, Chapter 17, The principle of proportional ink:\n\nhttps://clauswilke.com/dataviz/proportional-ink.html\n\n[Video] Introduction to ggplot2 https://www.youtube.com/watch?v=UiuA5sBEcFk\n[Video] BeginneR Workshop https://www.youtube.com/watch?v=7kuPnVZcot0 [lecture starts around 20:00]\n\nCheck the video description for the code files\n\n[Video] Intro to Git and GitHub https://www.youtube.com/watch?v=u4LIpYC0Yaw\n\nTruly extra reading for those interested in advancing their conceptual understanding of ggplot2 and the possibilities in data visualization:\n\nA Layered Grammar of Graphics, by Hadley Wickham http://vita.had.co.nz/papers/layered-grammar.pdf\nStart to get familiar with the ggplot2 book. We recommend starting with subsection 1.2 “What is the grammar of graphics?” here: https://ggplot2-book.org/introduction.html#what-is-the-grammar-of-graphics\nThe R Graph Gallery: https://r-graph-gallery.com/index.html\n\nWhat you can expect from the instructional team:\n\nWe will be reading your bios and working on sorting you into groups for the final presentation topics."
  },
  {
    "objectID": "about.html#video-recording-2",
    "href": "about.html#video-recording-2",
    "title": "Day 9",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "about.html#resources-2",
    "href": "about.html#resources-2",
    "title": "Day 9",
    "section": "Resources",
    "text": "Resources\n link to daily google doc  \n link to slide pdfs\n\nLecture 1: Programming with R\n\n\nlink to view slides fullscreen\n\n  link to slide PDFs  \n\n\nLecture 2: Data Dictionaries and Documentation\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 3: Reading in Data\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 4: Intro to ggplot2\n\n\nlink to view slides fullscreen   link to slide PDFs"
  },
  {
    "objectID": "about.html#wednesday-january-11th",
    "href": "about.html#wednesday-january-11th",
    "title": "Day 9",
    "section": "Wednesday January 11th",
    "text": "Wednesday January 11th\n\n1:30-2:00 Lecture: R Projects\n2:00-2:50 Lecture: Intro to dplyr\n2:50-3:10 Activity: Work on dplyr learnr tutorial in groups\n3:10-3:15 Break\n3:15-3:45 Lecture: Cleaning Text Data\n3:45-4:10 Lecture: Writing Functions\n4:10-4:30 Activity: Write functions together\n4:30-4:45 Activity: Discussion Q&A from ggplot2 Homework\n4:45-4:55 Survey: Checking in on Pacing\n4:55-5:10 Demonstration of how to do the homework\n5:10-5:30 Time to work on homework, chat with classmates, peruse recommended materials\n\n\nRecommended reading:\n\nOn Projects:\n\nTidyverse Blog, Project-Oriented Workflow by Jenny Bryan: https://www.tidyverse.org/blog/2017/12/workflow-vs-script/\nR for Data Science, Chapter 8: https://r4ds.had.co.nz/workflow-projects.html\nProject-Oriented Workflow, Jenny Bryan https://www.tidyverse.org/blog/2017/12/workflow-vs-script/\n\nOn dplyr, cleaning text, and writing functions\n\nR for Data Science, Chapter 5 Data Transformation: https://r4ds.had.co.nz/transform.html\nR for Data Science, Chapter 14 Strings: https://r4ds.had.co.nz/strings.html\nR for Data Science, Chapter 19 Functions: https://r4ds.had.co.nz/functions.html\n\n\n\n\nHomework:\n\nNo homework"
  },
  {
    "objectID": "about.html#video-recording-3",
    "href": "about.html#video-recording-3",
    "title": "Day 9",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "about.html#resources-3",
    "href": "about.html#resources-3",
    "title": "Day 9",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides \n\nLecture 1: Projects in RStudio\n\n\nlink to view slides fullscreen\n\n\nLecture 2: Intro to dplyr\n\n\nlink to view slides fullscreen\n\n\nLecture 4: Cleaning Text Data\n\n\nlink to view slides fullscreen\n\n\nLecture 5: Functions\n\n\nlink to view slides fullscreen"
  },
  {
    "objectID": "about.html#thursday-january-12th",
    "href": "about.html#thursday-january-12th",
    "title": "Day 9",
    "section": "Thursday January 12th",
    "text": "Thursday January 12th\n\n1:30-2:00 Lecture: Diverse Data Sources (APIs [tidycensus, WHO, World Bank, qualtRics], scraping web data, tabulizer, tesseract, datapasta)\n2:00-2:20 Discussion: What kind of sources are students interested in using in their research or future work?\n2:20-2:50 Lecture: How to handle factors and date-times\n2:50-3:00 Break\n3:00-3:30 Lecture: Working with Regression Model Objects: constructing and analyzing them\n3:30-4:15 Activity: Working with Regression Models in R\n4:15-4:45 Lecture: Creating maps in R\n4:45-5:00 Lecture: Reproducible Examples for Getting Help\n5:00-5:30 Time to work on final presentation materials together, peruse recommended materials, chat with classmates\n\n\nHomework:\n\nFit and report on a regression model including categorical (factor) variables\nPeer Review for Homework 2\n\n\n\nRecommended Materials\nRemember! You don’t have to read all of this! Just focus on what’s most useful to you:\n\nTidy Data by Hadley Wickham https://vita.had.co.nz/papers/tidy-data.pdf\nDiverse Data Sources\n\nThe readme to the datapasta package: https://github.com/MilesMcBain/datapasta\nAnalyzing US Census Data by Kyle Walker, Chapter 2: An introduction to tidycensus: https://walker-data.com/census-r/an-introduction-to-tidycensus.html\nThe readr cheatsheet: https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-import.pdf\nWorking with Qualtrics Data - Part 1: Importing Data, ROpenSci https://ropensci.org/blog/2022/08/02/working-with-qualtrics-data-importing/\n\nHandling factors and date-times in R:\n\nChapter 15: Factors, R for Data Science by Hadley Wickham and Garrett Grolemund https://r4ds.had.co.nz/factors.html\nChapter 16: Dates and Times, R for Data Science by Hadley Wickham and Garrett Grolemund https://r4ds.had.co.nz/dates-and-times.html\nForcats cheatsheet https://raw.githubusercontent.com/rstudio/cheatsheets/main/factors.pdf\nLubridate cheatsheet https://raw.githubusercontent.com/rstudio/cheatsheets/main/lubridate.pdf\n\nWorking with Regression Models:\n\nIntroduction to broom https://broom.tidymodels.org/articles/broom.html\nA nice introduction to linear model diagnostics plots: https://book.stat420.org/model-diagnostics.html\nInterpretation of R’s lm() output: https://stats.stackexchange.com/questions/5135/interpretation-of-rs-lm-output\n\nMapping:\n\nChapter 8 Plotting Spatial Data, Spatial Data Science https://r-spatial.org/book/08-Plotting.html\n\nThis focuses more on sf which is the most modern and increasingly most popular paradigm for working with spatial data in R\n\nChapter 9 Making Maps with R, Geocomputation with R https://geocompr.robinlovelace.net/adv-map.html\n\nThis chapter has a lot of focus on tmap, a package for creating thematic maps"
  },
  {
    "objectID": "about.html#video-recording-4",
    "href": "about.html#video-recording-4",
    "title": "Day 9",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "about.html#resources-4",
    "href": "about.html#resources-4",
    "title": "Day 9",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides\n\nLecture 1: Diverse Data Sources\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 2: Factors and Date-times\n\n\nlink to view slides fullscreen  link to follow along code   link to slide PDFs  \n\n\nLecture 3: Regression\n link to slide PDFs  link to repository \n\n\nLecture 4: Creating maps in R\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 5: Reproducible examples for getting help in R\n  link to view slides fullscreen    link to slide PDFs"
  },
  {
    "objectID": "about.html#friday-january-13th",
    "href": "about.html#friday-january-13th",
    "title": "Day 9",
    "section": "Friday January 13th",
    "text": "Friday January 13th\n\n1:30-2:00 Lecture: Why reproducibility and robustness are important principles in science and data analysis and acknowledging the pressures in academia that push people away from reproducible science\n2:00-2:15 Discussion\n2:15-2:45 Lecture: Visualizing and Reporting on Regression Models\n2:45-3:05 Lecture: Data Linkage Methods\n3:05-3:25 Activity: Working with Joins\n3:25-3:35 Break\n3:35-4:00 Activity: Hallway QR Code Challenges\n4:00-4:15 Lecture: Introduction of the Brown et al (partial) reproduction of Onikye et al’s results\n4:15-4:30 Homework demonstration\n4:30-5:25 Time to work on homework + chat together + work on final projects\n5:25-5:30 Giveaway for a Copy of R for Data Science\n5:30 Meet Hodu!\n\n\nHomework 4\n\nRead the Brown et al reproduction of Onikye et al, run their code, and fill out the worksheet\n\nhttps://open.lnu.se/index.php/metapsychology/article/view/2071\nhttps://osf.io/j32yw/\n\nPeer review for homework 3\n\n\n\nAvailable/Recommended Materials:\n\nReproducibility:\n\nDraw Me A Project https://masalmon.eu/2021/06/30/r-projects/\nReproducibility of Scientific Results https://plato.stanford.edu/entries/scientific-reproducibility/\nBest Practices for Scientific Computing https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745\nGood Enough Practices for Scientific Computing https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510\nReplicability, Robustness, and Reproducibility in Psychological Science https://pure.uvt.nl/ws/portalfiles/portal/59415163/MTO_Nuijten_replicability_robustness_and_reproducibility_Annual_Review_of_Psy_2022.pdf\nA manifesto for reproducible science https://www.nature.com/articles/s41562-016-0021\n\nRegression Modeling:\n\nIntroduction to Poisson Regression, Beyond Multiple Linear Regression https://bookdown.org/roback/bookdown-BeyondMLR/ch-poissonreg.html\nPoisson Regression https://rpubs.com/franzbischoff/poisson_regression\nLogistic Regression, Beyond Multiple Linear Regression https://bookdown.org/roback/bookdown-BeyondMLR/ch-logreg.html"
  },
  {
    "objectID": "about.html#video-recording-5",
    "href": "about.html#video-recording-5",
    "title": "Day 9",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "about.html#resources-5",
    "href": "about.html#resources-5",
    "title": "Day 9",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides\n\nLecture 1: Reproducibility and Robustness\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 2: Regression (part 2!)\n link to slide PDFs  link to repository \n\n\nLecture 3: Data linkage methods\n\n\nlink to view slides fullscreen   link to slide PDFs   link to follow along code"
  },
  {
    "objectID": "about.html#tuesday-january-17th",
    "href": "about.html#tuesday-january-17th",
    "title": "Day 9",
    "section": "Tuesday January 17th",
    "text": "Tuesday January 17th\n\n1:30-1:50 Activity: Discussion of Onikye et al reproduction article\n1:50-2:10 Lecture: Introduction to R Packages\n2:10-2:30 Demonstration of how to create R packages that standardize data loading and cleaning processes\n2:30-3:00 Lecture: How to use R Markdown to produce reproducible reports including tables, visualizations, and inline-quantitative statements.\n3:00-3:10 Break\n3:10-3:30 Activity: Experiment with different R Markdown features\n3:30-3:50 Lecture: Advice for Debugging\n3:50-4:10 Activity: Debugging\n4:10-4:30 Activity: Getting Help Online\n4:30-4:45 Demonstration of how to do the homework\n4:45-5:30 Time to do the homework, work on the final project together, peruse recommended materials\n\n\nHomework 5:\n\nUse R Markdown to document some exploratory data analyses\n\n\n\nRecommended Materials:\n\nR Packages:\n\nRead Karl Broman’s Why write an R package?\nFamiliarize yourself with what’s in the R Packages book: https://r-pkgs.org/ — having a rough familiarity with the different parts will be helpful. Our suggestion here is to try and approach this more in terms of “what are the ingredients in a good R Package?” rather than trying to learn how to craft all of those ingredients from the ground up immediately.\n\nR Markdown:\n\nCheck out the Get Started for R Markdown, especially the ~1 minute video intro on the first page: https://rmarkdown.rstudio.com/lesson-1.html\nHow R Helps Airbnb Make the Most of Its Data\nIf you find yourself loving R Markdown, you may find the R Markdown Cookbook useful, but it is incredibly comprehensive and we’d suggest it’s better to reference as you need it than to try to read it cover-to-cover."
  },
  {
    "objectID": "about.html#video-recording-6",
    "href": "about.html#video-recording-6",
    "title": "Day 9",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "about.html#resources-6",
    "href": "about.html#resources-6",
    "title": "Day 9",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides\n\nLecture 1: Packages\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 2: RMarkdown\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\nLecture 3: Debugging\n\n\nlink to view slides fullscreen \n link to slide PDFs  \n link to live coding example reproducing a map of literacy rates in India from Wikipedia"
  },
  {
    "objectID": "about.html#wednesday-january-18th",
    "href": "about.html#wednesday-january-18th",
    "title": "Day 9",
    "section": "Wednesday January 18th",
    "text": "Wednesday January 18th\n\n1:30-2:00 Lecture: A Data Analysis from Start to Finish\n2:00-2:30 Lecture: Longitudinal Data Analysis\n2:30-3:00 Lecture: Best practices for reporting on missing data\n3:00-3:30 Lecture: Intro to accessible exploratory data analysis methods: Correlation, principal components analysis, variable importance\n3:30-3:40 Break\n3:40-4:00 Discussion: What are the ethical principles involved in data analysis? What are the risks involved?\n4:00-4:30 Lecture: Clean Code and Considerate Coding\n4:30-5:30 Free time to work together on the final project, chat with classmates, peruse recommended materials\n\n\nHomework:\n\nPeer Review Homework 5\n\n\n\nRecommended Materials:\n\nHarms and Ethics in Data Science and Machine Learning:\n\nThe Data Science Ethics chapter from the Modern Data Science with R book: https://mdsr-book.github.io/mdsr2e/ch-ethics.html"
  },
  {
    "objectID": "about.html#video-recording-7",
    "href": "about.html#video-recording-7",
    "title": "Day 9",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "about.html#resources-7",
    "href": "about.html#resources-7",
    "title": "Day 9",
    "section": "Resources",
    "text": "Resources\n link to daily google doc    link to PDF slides"
  },
  {
    "objectID": "about.html#lecture-2-exploratory-data-analysis-longitudinal-data-analysis-1",
    "href": "about.html#lecture-2-exploratory-data-analysis-longitudinal-data-analysis-1",
    "title": "Day 9",
    "section": "Lecture 2: Exploratory data analysis – Longitudinal data analysis",
    "text": "Lecture 2: Exploratory data analysis – Longitudinal data analysis\n link to longitudinal_eda.R script    link to make_simulated_data.R script"
  },
  {
    "objectID": "about.html#lecture-3-missing-data-1",
    "href": "about.html#lecture-3-missing-data-1",
    "title": "Day 9",
    "section": "Lecture 3: Missing data",
    "text": "Lecture 3: Missing data\n\n\nlink to view slides fullscreen   link to slide PDFs    link to missing-demo.R script"
  },
  {
    "objectID": "about.html#lecture-4-accessible-exploratory-data-analysis-1",
    "href": "about.html#lecture-4-accessible-exploratory-data-analysis-1",
    "title": "Day 9",
    "section": "Lecture 4: Accessible exploratory data analysis",
    "text": "Lecture 4: Accessible exploratory data analysis\n link to eda.R script"
  },
  {
    "objectID": "about.html#lecture-5-clean-code-and-considerate-coding-1",
    "href": "about.html#lecture-5-clean-code-and-considerate-coding-1",
    "title": "Day 9",
    "section": "Lecture 5: Clean code and considerate coding",
    "text": "Lecture 5: Clean code and considerate coding"
  },
  {
    "objectID": "about.html#thursday-january-19th",
    "href": "about.html#thursday-january-19th",
    "title": "Day 9",
    "section": "Thursday January 19th",
    "text": "Thursday January 19th\n\n1:30-2:00 Lecture/Demo: Principles for Data Analysis from Start to Finish\n2:00-2:30 Lecture: Functional Programming\n2:30-3:00 Discussion + Demo: When does it make sense to use functional programming?\n3:00-3:10 Break\n3:10-3:40 Lecture: [Students’ Choice]\n3:40-4:10 Lecture: How to Keep Growing as a Programmer (and stay up to date)\n4:10-4:20 Details about turning in your final presentations\n4:20-5:30 Positive affirmations, free time to work together on final projects\n\n\nHomework:\n\nWork with classmates to finalize presentations and turn them in\n\n\n\nRecommended materials:\n\nHadley Wickham on Many Models: https://youtu.be/cU0-NrUxRw4"
  },
  {
    "objectID": "about.html#video-recording-8",
    "href": "about.html#video-recording-8",
    "title": "Day 9",
    "section": "Video Recording",
    "text": "Video Recording\n\n\nApologies the lecture recording didn’t capture the first lecture of the day."
  },
  {
    "objectID": "about.html#resources-8",
    "href": "about.html#resources-8",
    "title": "Day 9",
    "section": "Resources",
    "text": "Resources\n  link to PDF slides   link to daily google doc  \n\nLecture 1: Principles for data analysis\n\n\n link to view slides fullscreen    link to PDF slides \n\n\nLecture 2: Functional Programming\n link to functional_programming.R script \n\n\nLecture 3: dplyr (student choice)\n dplyr_demo.R script \n\n\nLecture 4: Growing as a programmer\n\n\n link to view slides fullscreen   link to PDF slides"
  },
  {
    "objectID": "about.html#friday-january-20th",
    "href": "about.html#friday-january-20th",
    "title": "Day 9",
    "section": "Friday January 20th",
    "text": "Friday January 20th\n\n1:30-4:30 Final Presentations:\n\nStudents will be divided into 10 groups with 10-12 minutes presentation time and 3-5 minutes for feedback from the instructional team and Q&A from the audience.\n15 minutes × 10 groups = ~2.5 hours\nwe’ll make sure to take some breaks between every few groups\n\n4:30-5:00 Lecture: Recap of Key Takeaways\n5:00-5:30:\n\nMake sure you’ve uploaded your presentation!\nFeedback and Course Evaluations\n\n\nEnjoy being done with the class and go on to do great things with your newly learned R skills!"
  },
  {
    "objectID": "about.html#video-recording-9",
    "href": "about.html#video-recording-9",
    "title": "Day 9",
    "section": "Video Recording",
    "text": "Video Recording"
  },
  {
    "objectID": "about.html#student-presentations",
    "href": "about.html#student-presentations",
    "title": "Day 9",
    "section": "Student Presentations",
    "text": "Student Presentations\n\nClean Code and Code Hygeine\n\n\n\n\nCode Commenting and Documentation\n\n\n\n\nData Dictionaries\n\n\n\n\nData Visualization (Group 1)\n\n\n\n\nData Visualization (Group 2)\n\n\n\n\nPresenting Model Results\n\n\n\n\nGeographic Maps"
  },
  {
    "objectID": "about.html#final-lecture-recap",
    "href": "about.html#final-lecture-recap",
    "title": "Day 9",
    "section": "Final lecture: Recap",
    "text": "Final lecture: Recap\n\n\n link to view slides fullscreen    link to PDF slides \n\nOutline of Topics\n\nWelcome\nIntro to the Course\nDemo\nRStudio and R, Git and GitHub"
  },
  {
    "objectID": "about.html#slides-1",
    "href": "about.html#slides-1",
    "title": "Day 9",
    "section": "Slides",
    "text": "Slides\n\n\n\n\n\n\nView Slides for Intro to ID529\n\n\n\n\n\n\n\n\n\n\nview slides fullscreen  link to pdf slides\n\n\n\n\n\n\nSlides for Final Project Format\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\n\n\n\n\nView Slides for Intro to RStudio and R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\n\n\n\n\nView Slides for Git and GitHub\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to pdf slides"
  },
  {
    "objectID": "about.html#positive-affirmations-2",
    "href": "about.html#positive-affirmations-2",
    "title": "Day 9",
    "section": "Positive Affirmations",
    "text": "Positive Affirmations\n\nlink to view fullscreen\nIn text form:\nHere are some affirmations that can help you to reframe your thoughts and let go of any negative self-doubt or impostor syndrome that you may be feeling.\n\nI am capable and competent.\nI am worthy and deserving of success.\nI trust in my abilities and the effort I put forth.\nI am enough, exactly as I am.\nI am learning and growing with each challenge I face.\n\nIt’s important to remember that everyone experiences moments of self-doubt and uncertainty, and it’s okay to not feel confident all the time.\nThe key is to recognize and acknowledge those feelings, and then remind ourselves of our strengths and capabilities.\n\n\n\n\n\n\nVideo Recording from This Year\n\n\n\n\n\n\n\nApologies we accidentally didn’t capture the RStudio and R talk on this recording. See the prior years’ recording for that section if you’d like.\n\n\n\n\n\n\n\n\n\nVideo Recording from Last Year\n\n\n\n\n\n\n\n\n\n\nOutline of topics:\n\nLecture: Intro to R Programming\nLecture: Project Workflow\nActivity: Learnr Tutorials\nLecture: Reading in data\nLecture: Intro to ggplot2\nDiscussion: What makes an effective data visualization?\n\n\n\n\n\n\n\nLecture 1: Programming with R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nLecture 2: Project Workflows in R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to slides PDF \n\n\n\n\n\n\nLecture 3: Reading in Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to slide PDFs  \n\n\n\n\n\n\nLecture 4: Intro to ggplot2\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nThis Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording"
  },
  {
    "objectID": "about.html#resources-9",
    "href": "about.html#resources-9",
    "title": "Day 9",
    "section": "Resources",
    "text": "Resources\n link to daily google doc  \nOutline of topics:\n\nLecture: Intro to dplyr\nLecture: Cleaning Text Data\nActivity: Manipulating Data\nLecture: Writing Functions\nActivity: Functions\n\n\n\n\n\n\n\nLecture 1: Intro to dplyr\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \nlink to slides pdf\n\n\n\n\n\n\nLecture 2: Cleaning Text Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\nlink to slides pdf\n\n\n\n\n\n\nActivity: Cleaning Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\nlink to slides pdf\n\n\n\n\n\n\nLecture 3: Functions\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\nlink to slides pdf\n\n\n\n\n\n\nVideo Recording\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\nOutline of topics:\n\nLecture: Diverse Data Sources (APIs [tidycensus, WHO, World Bank, qualtRics], scraping web data, datapasta)\nDiscussion: What kind of sources are students interested in using in their research or future work?\nLecture: How to handle factors and date-times\nLecture: Working with Regression Model Objects: constructing and analyzing them\nActivity: Working with Regression Models\nLecture: Creating Maps in R\nLecture: Reproducible Examples for Getting Help\n\n\n\n\n\n\n\nLecture 1: Diverse Data Sources\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs \n\n\n\n\n\n\nLecture 2: Factors and Date-times\n\n\n\n\n\n\n\nlink to view slides fullscreen  \n\n\n\nlink to follow along code   link to slide PDFs \n\nLecture 3: Regression\n link to slide PDFs  link to repository\n\n\n\n\n\n\nLecture 4: Creating maps in R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs \n\n\n\n\n\n\nLecture 5: Reproducible examples for getting help in R\n\n\n\n\n\n \n\n\n\nlink to view slides fullscreen    link to slide PDFs \n\n\n\n\n\n\nVideo Recording\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\nOutline of topics:\n\nLab (1 hour in FXB G12)\nReproducibility and Robustness\nVisualizing and Reporting on Regression\nQR Code Activity\nData Linkage Methods\nOnikye et al Article\n\n\n\n\n\n\n\nCourse Core Concepts Script\n\n\n\n\n\nFind this script online here or written out below:\n# know how to install packages:\n# install.packages(\"tidyverse\")\n\n# set up a project so we could use the {here} package\n\n# dependencies ------------------------------------------------------------\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(here)\nlibrary(palmerpenguins)\nlibrary(gtsummary)\n\n\n# read in data ------------------------------------------------------------\n\n# we could use a csv dataset like this:\n# df &lt;- readr::read_csv(here(\"data.csv\"))\n\n# or use an example dataset like penguins from palmerpenguins:\n# use View to look at it in RStudio\nView(penguins)\n\n\n# data manipulation -------------------------------------------------------\n\n# use group_by and summarize together to create summary statistics per-group\npenguins_summarized &lt;- penguins |&gt;\n  group_by(species) |&gt;\n  summarize(\n    mean_flipper_length_mm = mean(flipper_length_mm, na.rm=TRUE))\n\n# know how to use mutate to update columns (either creating new ones or updating\n# existing ones):\n# here, we'll just convert species to a character vector just for an example\n# so then we can next practice making it a factor:\npenguins &lt;- penguins |&gt;\n  mutate(species = as.character(species))\n\n# convert a variable to a factor:\n#\n# method 1: base R\n# here, the levels will be assumed from the output of unique(penguins$species):\npenguins$species &lt;- factor(penguins$species)\n#\n# method 2: dplyr\npenguins &lt;- penguins |&gt;\n  mutate(species = factor(species))\n\n# if I wanted to change the reference category, I could use relevel:\npenguins$species &lt;- relevel(penguins$species, 'Chinstrap')\n\n# or the dplyr way:\npenguins &lt;- penguins |&gt;\n  mutate(species = relevel(species, 'Chinstrap'))\n# you can also use forcats::fct_relevel\n\n\n# data visualization ------------------------------------------------------\n\n# use ggplot2 to make some graphics\n# a scatter plot:\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point() +\n  ggtitle(\"Penguin Bill Lengths and Depths by Species\")\n\n# use ggsave to save your work\nggsave(here(\"output/penguins_scatterplot.png\"), width = 7, height = 5)\n\n# a histogram with facets:\nggplot(penguins, aes(x = flipper_length_mm)) +\n  geom_histogram() +\n  facet_wrap(~species) +\n  ggtitle(\"Penguin Bill Lengths and Depths by Species\")\n\n# again use ggsave and here() to save it within your project\nggsave(here(\"output/penguins_faceted_histogram.png\"), width = 8, height = 3)\n\n\n# you might also want to plot regression lines in ggplot quickly so\n# use geom_smooth:\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = 'lm') +\n  ggtitle(\"Linear regression of flipper length on body mass\")\n\n\n# analyze a model -------------------------------------------------------------\n\nmodel &lt;- lm(flipper_length_mm ~ body_mass_g + species, penguins)\n\n# use broom::tidy to extract the coefficients and their statistics\nmodel_output &lt;- broom::tidy(model, conf.int = TRUE)\n\n# visualize model results\nmodel_output |&gt;\n  filter(term != '(Intercept)') |&gt;\n  ggplot(aes(x = estimate, y = term, xmin = conf.low, xmax = conf.high)) +\n  geom_pointrange()\n\n# create a table of the results\ngtsummary::tbl_regression(model)\n\n\n# one example with multiple models --------------------------------------------\n\nmodel1 &lt;- lm(flipper_length_mm ~ species, penguins)\nmodel2 &lt;- lm(flipper_length_mm ~ species + body_mass_g, penguins)\nmodel3 &lt;- lm(flipper_length_mm ~ species + body_mass_g + island, penguins)\n\n# extract tables of results\nmodel_results &lt;- list(\n  bind_cols(model = 'model1', broom::tidy(model1, conf.int = TRUE)),\n  bind_cols(model = 'model2', broom::tidy(model2, conf.int = TRUE)),\n  bind_cols(model = 'model3', broom::tidy(model3, conf.int = TRUE)))\n\n# make into one data frame\nmodel_results &lt;- bind_rows(model_results)\n\n# create a plot of covariates from multiple models\nmodel_results |&gt;\n  filter(term %in% c('speciesGentoo', 'speciesAdelie')) |&gt;\n  ggplot(\n       aes(x = estimate,\n           y = term,\n           xmin = conf.low,\n           xmax = conf.high,\n           color = model,\n           shape = model)) +\n  geom_pointrange(position = position_dodge(width = 0.5)) +\n  ggtitle(\"Coefficient estimates for species effect\",\n          stringr::str_wrap(\n            paste(\n              \"Model 1 includes no other covariates, model 2 includes body mass,\",\n              \"and model 3 includes body mass and island effects\"\n            )\n          ))\n\n\n\n\n\n\n\n\n\nLecture 1: Reproducibility and Robustness\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\n\nLecture 2: Regression (part 2!)\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  link to repository \n\n\n\n\n\n\nLecture 3: Data linkage methods\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs   link to follow along code\n\n\n\n\n\n\nBrown et al Response and Reproduction of Onikye et al\n\n\n\n\n\nPreface\nIn 2021 Brown et al published an article titled A Reproduction of the Results of Onyike et al. (2003) in Meta-Psychology, a journal that is free, open-access and conducts open peer review. The Onikye et al. article they reproducing, Is obesity associated with major depression? Results from the Third National Health and Nutrition Examination Survey, was published in the American Journal of Epidemiology has been cited 1159+ times according to Google Scholar.\nI want to point out an interesting section from the About page describing the Meta-Psychology journal that you might keep in mind as you read on:\n\nPrior to publication, all statistical analyses are reproduced by our statistical reproduction team, which consists of the Statistical Editor and our editorial assistant. This makes the article eligible for the reproducibility badge.\n\nRecommended Reading\nPlease read the article by Brown et al (https://open.lnu.se/index.php/metapsychology/article/view/2071).\nAbstract repeated here as a teaser:\n\nOnyike et al. (2003) analyzed data from a large-scale US-American data set, the Third National Health and Nutrition Examination Survey (NHANES-III), and reported an association between obesity and major depression, especially among people with severe obesity. Here, we report the results of a detailed replication of Onyike et al.’s analyses. While we were able to reproduce the majority of these authors’ descriptive statistics, this took a substantial amount of time and effort, and we found several minor errors in the univariate descriptive statistics reported in their Tables 1 and 2. We were able to reproduce most of Onyike et al.’s bivariate findings regarding the relationship between obesity and depression (Tables 3 and 4), albeit with some small discrepancies (e.g., with respect to the magnitudes of standard errors). On the other hand, we were unable to reproduce Table 5, containing Onyike et al.’s findings with respect to the relationship between obesity and depression when controlling for plausible confounding variables—arguably the paper’s most important results—because some of the included predictor variables appear to be either unavailable, or not coded in the way reported by Onyike et al., in the public NHANES-III data sets. We discuss the implications of our findings for the transparency of reporting and the reproducibility of published results.\n\nTheir code is freely, publicly accessible on OSFHOME, a file storage service provided by the Open Science Framework from the Center for Open Science.\n\nBrown et al’s code+file repository: https://osf.io/j32yw/\nDownload their code+files (direct link): https://files.osf.io/v1/resources/j32yw/providers/osfstorage/?zip=\n\nNote that in order to run their code, you will either want to a) make a new R project in the folder with their code on your computer, or b) open a new RStudio window, open up their .R file, and use setwd('filepath/goes/here/') to make sure your R session can run their R code.\nConsider the following questions:\n\nDo you believe that the results Brown et al. have shared are more likely to be correct than those that Onikye et al published? If so, why? If not, why not?\n\nWhat do you find compelling about their re-analysis and code?\nWhat do you find lacking about their re-analysis and code?\n\nHow do you think the non-reproducibility of Onikye et al.’s article could have been avoided?\nWhen, if at all, do you think articles should be required to share code and data?\n\nWhat about in situations where the data relates to private or sensitive data?\nWhat about in situations where the subject matter is highly politically charged and there might be malicious actors who could see shared data and code as additional surface area to attack?\n\nHas reading this article made you more skeptical of research publications that don’t share code?\nDo you think for articles where code & data are too sensitive to be shared, is there an alternative process that would make you similarly confident in the stated results?\n\nAn important aside\nThis isn’t a class about stigma and health, but I think being in a Population Health Science program, it’s important to leave the breadcrumbs here for you to do your own followup reading and learning.\nBecause the articles in this homework discuss body-weight and health, I want to emphatically point out that this subject matter is not at all cut and dry. It’s important to acknowledge that:\n\nWeight-based stigma is real and causes harm to health through multiple mechanisms including at least discrimination and health care practitioners’ attitudes and behaviors:\n\nhttps://ajph.aphapublications.org/doi/full/10.2105/AJPH.2009.159491\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/obr.12266\n\nThe decision by health organizations to classify obesity as a “disease” is debated:\n\nhttps://www.healthline.com/health/is-obesity-a-disease\n\nThe language and terminology that we use can perpetuate stigma:\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC5051141/?report=classic\nhttps://news.yale.edu/2012/07/12/choosing-words-wisely-when-talking-patients-about-their-weight\n\n\nIf anything, what I hope you take away from this aside is that data do not speak for themselves, but rather are subject to interpretation and leave room for either the perpetuation or casting aside of pre-existing biases (See “Data Never Speak for Themselves” from Nancy Krieger’s article Structural Racism, Health Inequities, and the Two-Edged Sword of Data: Structural Problems Require Structural Solutions). It’s not enough to engage with open-science practices and leverage sophisticated statistical analyses made possible in programs like R; instead, it’s necessary to combine advances in the state of the art in computing with advances in our conceptual frameworks to do science that can truly shift narratives in ways that benefit marginalized groups.\n\n\n\n\n\n\n\n\n\nVideo Recording\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\nOutline of topics:\n\nR Markdown\nDebugging\nTime to work on final project\n\n\n\n\n\n\n\nLecture 1: R Markdown\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nLecture 2: Debugging\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nVideo Recording from Last Year\n\n\n\n\n\n\n\n\n\n\nOutline:\n\nAn Analysis Start-to-Finish: Environmental Monitoring\nLongitudinal Data Analysis\nVisualizing Missing Data\nEasy Exploratory Data Analysis\nPrinciples for Clean Code\n\n\n\n\n\n\n\nLecture 1: An Analysis Start to Finish\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen \nlink to slide pdf\n\n\n\n\n\n\nLecture 2: Exploratory data analysis – Longitudinal data analysis\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen   link to slide pdf   link to longitudinal_eda.R script    link to make_simulated_data.R script \n\n\n\n\n\n\nLecture 3: Missing data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs    link to missing-demo.R script \n\n\n\n\n\n\nLecture 4: Accessible exploratory data analysis\n\n\n\n\n\n link to eda.R script \n\n\n\n\n\n\n\n\n\nLecture 5: Clean code and considerate coding\n\n\n\n\n\n\n\nthe tidyverse style guide\n\n\n\nlink to view fullscreen \nlink to pdf \n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\nOutline:\n\nPrinciples for Data Analysis\nFunctional Programming\nCOVID OSHA Example\nStudent Choice\nAge Standardization\nBaby Boom Visualization\nR4DS Giveaway\n\n\n\n\n\n\n\nLecture 1: Principles for data analysis\n\n\n\n\n\n\n\n\n\n\n link to view slides fullscreen    link to PDF slides \n\n\n\n\n\n\nLecture 2: Functional Programming\n\n\n\n\n\nlink to functional programming demo script\n\n\n\n\n\n\n\n\n\nCOVID OSHA Project Example\n\n\n\n\n\nLink to Project: https://github.com/ctesta01/covid_osha\n\n\n\n\n\n\n\n\n\nStudent Choice\n\n\n\n\n\nlink to script that goes over requested topics\n\n\n\n\n\n\n\n\n\nKieran Healy’s Baby Boom Data Visualization Poster\n\n\n\n\n\nTogether we took a look at this poster from Kieran Healy and the code from the repository.\nThe example was instructive on a few points:\n\nWe thought it was neat how Kieran used the legend to create a title.\nWe saw how he used cowplot::plot_grid and/or the patchwork package to construct the graphic with multiple panels.\nSeeing how png() and pdf() can be used, similar to ggsave(), to save plots was useful — especially for non-ggplot2 visualizations.\nWe had to do a little bit of debugging, figuring out that we needed to use scale_x_yearmonth() instead of scale_x_date() and we figured that out by 1) reading the error we got in R, and 2) checking what the class/type of the column mapped onto the x aesthetic was.\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording\n\n\n\n\n\n\n\n\n\n\nOutline:\n\nReflections on Final Projects\nGoals for Near Future R Programming (Discussion)\nVery Important Material\nR Project Examples\nGrowing as a Programmer\nCourse Evaluation Survey(s)\n\n\n\n\n\n\n\nReflections on Final Projects\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nVery Important Material\n\n\n\n\n\n(posted after class)\n\n\n\n\n\n\n\n\n\nR Project Examples\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nGrowing as a Programmer\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nLast Year’s Video Recording"
  },
  {
    "objectID": "wi24/day1.html",
    "href": "wi24/day1.html",
    "title": "Day 1",
    "section": "",
    "text": "Outline of Topics"
  },
  {
    "objectID": "wi24/day1.html#slides",
    "href": "wi24/day1.html#slides",
    "title": "Day 1",
    "section": "Slides",
    "text": "Slides\n\n\n\n\n\n\nView Slides for Intro to ID529\n\n\n\n\n\n\n\n\n\n\nview slides fullscreen  link to pdf slides\n\n\n\n\n\n\nSlides for Final Project Format\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\n\n\n\n\nView Slides for Intro to RStudio and R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen  link to pdf slides\n\n\n\n\n\n\nView Slides for Git and GitHub\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to pdf slides"
  },
  {
    "objectID": "wi24/day1.html#positive-affirmations",
    "href": "wi24/day1.html#positive-affirmations",
    "title": "Day 1",
    "section": "Positive Affirmations",
    "text": "Positive Affirmations\n\nlink to view fullscreen\nIn text form:\nHere are some affirmations that can help you to reframe your thoughts and let go of any negative self-doubt or impostor syndrome that you may be feeling.\n\nI am capable and competent.\nI am worthy and deserving of success.\nI trust in my abilities and the effort I put forth.\nI am enough, exactly as I am.\nI am learning and growing with each challenge I face.\n\nIt’s important to remember that everyone experiences moments of self-doubt and uncertainty, and it’s okay to not feel confident all the time.\nThe key is to recognize and acknowledge those feelings, and then remind ourselves of our strengths and capabilities.\n\n\n\n\n\n\nVideo Recording from This Year\n\n\n\n\n\n\n\nApologies we accidentally didn’t capture the RStudio and R talk on this recording. See the prior years’ recording for that section if you’d like.\n\n\n\n\n\n\n\n\n\nVideo Recording from Last Year"
  },
  {
    "objectID": "wi24/day2.html",
    "href": "wi24/day2.html",
    "title": "Day 2",
    "section": "",
    "text": "Outline of topics:\nlink to view slides fullscreen   link to slide PDFs\nlink to view slides fullscreen  link to slides PDF\nlink to view slides fullscreen  link to slide PDFs\nlink to view slides fullscreen   link to slide PDFs"
  },
  {
    "objectID": "wi24/day2.html#resources",
    "href": "wi24/day2.html#resources",
    "title": "Day 2",
    "section": "Resources",
    "text": "Resources\n link to daily google doc"
  },
  {
    "objectID": "wi24/day7.html",
    "href": "wi24/day7.html",
    "title": "Day 7",
    "section": "",
    "text": "Outline:\n\nAn Analysis Start-to-Finish: Environmental Monitoring\nLongitudinal Data Analysis\nVisualizing Missing Data\nEasy Exploratory Data Analysis\nPrinciples for Clean Code\n\n\n\n\n\n\n\nLecture 1: An Analysis Start to Finish\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen \nlink to slide pdf\n\n\n\n\n\n\nLecture 2: Exploratory data analysis – Longitudinal data analysis\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen   link to slide pdf   link to longitudinal_eda.R script    link to make_simulated_data.R script \n\n\n\n\n\n\nLecture 3: Missing data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs    link to missing-demo.R script \n\n\n\n\n\n\nLecture 4: Accessible exploratory data analysis\n\n\n\n\n\n link to eda.R script \n\n\n\n\n\n\n\n\n\nLecture 5: Clean code and considerate coding\n\n\n\n\n\n\n\nthe tidyverse style guide\n\n\n\nlink to view fullscreen \nlink to pdf \n\n\n\n\n\n\nLast Year’s Video Recording"
  },
  {
    "objectID": "wi24/day4.html",
    "href": "wi24/day4.html",
    "title": "Day 4",
    "section": "",
    "text": "Outline of topics:\n\nLecture: Diverse Data Sources (APIs [tidycensus, WHO, World Bank, qualtRics], scraping web data, datapasta)\nDiscussion: What kind of sources are students interested in using in their research or future work?\nLecture: How to handle factors and date-times\nLecture: Working with Regression Model Objects: constructing and analyzing them\nActivity: Working with Regression Models\nLecture: Creating Maps in R\nLecture: Reproducible Examples for Getting Help\n\n\n\n\n\n\n\nLecture 1: Diverse Data Sources\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs \n\n\n\n\n\n\nLecture 2: Factors and Date-times\n\n\n\n\n\n\n\nlink to view slides fullscreen  \n\n\n\nlink to follow along code   link to slide PDFs \n\nLecture 3: Regression\n link to slide PDFs  link to repository\n\n\n\n\n\n\nLecture 4: Creating maps in R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs \n\n\n\n\n\n\nLecture 5: Reproducible examples for getting help in R\n\n\n\n\n\n \n\n\n\nlink to view slides fullscreen    link to slide PDFs \n\n\n\n\n\n\nVideo Recording\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording"
  },
  {
    "objectID": "wi24/day8.html",
    "href": "wi24/day8.html",
    "title": "Day 8",
    "section": "",
    "text": "Outline:\n\nPrinciples for Data Analysis\nFunctional Programming\nCOVID OSHA Example\nStudent Choice\nAge Standardization\nBaby Boom Visualization\nR4DS Giveaway\n\n\n\n\n\n\n\nLecture 1: Principles for data analysis\n\n\n\n\n\n\n\n\n\n\n link to view slides fullscreen    link to PDF slides \n\n\n\n\n\n\nLecture 2: Functional Programming\n\n\n\n\n\nlink to functional programming demo script\n\n\n\n\n\n\n\n\n\nCOVID OSHA Project Example\n\n\n\n\n\nLink to Project: https://github.com/ctesta01/covid_osha\n\n\n\n\n\n\n\n\n\nStudent Choice\n\n\n\n\n\nlink to script that goes over requested topics\n\n\n\n\n\n\n\n\n\nKieran Healy’s Baby Boom Data Visualization Poster\n\n\n\n\n\nTogether we took a look at this poster from Kieran Healy and the code from the repository.\nThe example was instructive on a few points:\n\nWe thought it was neat how Kieran used the legend to create a title.\nWe saw how he used cowplot::plot_grid and/or the patchwork package to construct the graphic with multiple panels.\nSeeing how png() and pdf() can be used, similar to ggsave(), to save plots was useful — especially for non-ggplot2 visualizations.\nWe had to do a little bit of debugging, figuring out that we needed to use scale_x_yearmonth() instead of scale_x_date() and we figured that out by 1) reading the error we got in R, and 2) checking what the class/type of the column mapped onto the x aesthetic was.\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording"
  },
  {
    "objectID": "wi24/day9.html",
    "href": "wi24/day9.html",
    "title": "Day 9",
    "section": "",
    "text": "Outline:\n\nReflections on Final Projects\nGoals for Near Future R Programming (Discussion)\nVery Important Material\nR Project Examples\nGrowing as a Programmer\nCourse Evaluation Survey(s)\n\n\n\n\n\n\n\nReflections on Final Projects\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nVery Important Material\n\n\n\n\n\n(posted after class)\n\n\n\n\n\n\n\n\n\nR Project Examples\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nGrowing as a Programmer\n\n\n\n\n\n\n\n\n\n\nlink to view fullscreen\n\n\n\n\n\n\nLast Year’s Video Recording"
  },
  {
    "objectID": "wi24/day5.html",
    "href": "wi24/day5.html",
    "title": "Day 5",
    "section": "",
    "text": "Outline of topics:\n\nLab (1 hour in FXB G12)\nReproducibility and Robustness\nVisualizing and Reporting on Regression\nQR Code Activity\nData Linkage Methods\nOnikye et al Article\n\n\n\n\n\n\n\nCourse Core Concepts Script\n\n\n\n\n\nFind this script online here or written out below:\n# know how to install packages:\n# install.packages(\"tidyverse\")\n\n# set up a project so we could use the {here} package\n\n# dependencies ------------------------------------------------------------\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(here)\nlibrary(palmerpenguins)\nlibrary(gtsummary)\n\n\n# read in data ------------------------------------------------------------\n\n# we could use a csv dataset like this:\n# df &lt;- readr::read_csv(here(\"data.csv\"))\n\n# or use an example dataset like penguins from palmerpenguins:\n# use View to look at it in RStudio\nView(penguins)\n\n\n# data manipulation -------------------------------------------------------\n\n# use group_by and summarize together to create summary statistics per-group\npenguins_summarized &lt;- penguins |&gt;\n  group_by(species) |&gt;\n  summarize(\n    mean_flipper_length_mm = mean(flipper_length_mm, na.rm=TRUE))\n\n# know how to use mutate to update columns (either creating new ones or updating\n# existing ones):\n# here, we'll just convert species to a character vector just for an example\n# so then we can next practice making it a factor:\npenguins &lt;- penguins |&gt;\n  mutate(species = as.character(species))\n\n# convert a variable to a factor:\n#\n# method 1: base R\n# here, the levels will be assumed from the output of unique(penguins$species):\npenguins$species &lt;- factor(penguins$species)\n#\n# method 2: dplyr\npenguins &lt;- penguins |&gt;\n  mutate(species = factor(species))\n\n# if I wanted to change the reference category, I could use relevel:\npenguins$species &lt;- relevel(penguins$species, 'Chinstrap')\n\n# or the dplyr way:\npenguins &lt;- penguins |&gt;\n  mutate(species = relevel(species, 'Chinstrap'))\n# you can also use forcats::fct_relevel\n\n\n# data visualization ------------------------------------------------------\n\n# use ggplot2 to make some graphics\n# a scatter plot:\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point() +\n  ggtitle(\"Penguin Bill Lengths and Depths by Species\")\n\n# use ggsave to save your work\nggsave(here(\"output/penguins_scatterplot.png\"), width = 7, height = 5)\n\n# a histogram with facets:\nggplot(penguins, aes(x = flipper_length_mm)) +\n  geom_histogram() +\n  facet_wrap(~species) +\n  ggtitle(\"Penguin Bill Lengths and Depths by Species\")\n\n# again use ggsave and here() to save it within your project\nggsave(here(\"output/penguins_faceted_histogram.png\"), width = 8, height = 3)\n\n\n# you might also want to plot regression lines in ggplot quickly so\n# use geom_smooth:\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = 'lm') +\n  ggtitle(\"Linear regression of flipper length on body mass\")\n\n\n# analyze a model -------------------------------------------------------------\n\nmodel &lt;- lm(flipper_length_mm ~ body_mass_g + species, penguins)\n\n# use broom::tidy to extract the coefficients and their statistics\nmodel_output &lt;- broom::tidy(model, conf.int = TRUE)\n\n# visualize model results\nmodel_output |&gt;\n  filter(term != '(Intercept)') |&gt;\n  ggplot(aes(x = estimate, y = term, xmin = conf.low, xmax = conf.high)) +\n  geom_pointrange()\n\n# create a table of the results\ngtsummary::tbl_regression(model)\n\n\n# one example with multiple models --------------------------------------------\n\nmodel1 &lt;- lm(flipper_length_mm ~ species, penguins)\nmodel2 &lt;- lm(flipper_length_mm ~ species + body_mass_g, penguins)\nmodel3 &lt;- lm(flipper_length_mm ~ species + body_mass_g + island, penguins)\n\n# extract tables of results\nmodel_results &lt;- list(\n  bind_cols(model = 'model1', broom::tidy(model1, conf.int = TRUE)),\n  bind_cols(model = 'model2', broom::tidy(model2, conf.int = TRUE)),\n  bind_cols(model = 'model3', broom::tidy(model3, conf.int = TRUE)))\n\n# make into one data frame\nmodel_results &lt;- bind_rows(model_results)\n\n# create a plot of covariates from multiple models\nmodel_results |&gt;\n  filter(term %in% c('speciesGentoo', 'speciesAdelie')) |&gt;\n  ggplot(\n       aes(x = estimate,\n           y = term,\n           xmin = conf.low,\n           xmax = conf.high,\n           color = model,\n           shape = model)) +\n  geom_pointrange(position = position_dodge(width = 0.5)) +\n  ggtitle(\"Coefficient estimates for species effect\",\n          stringr::str_wrap(\n            paste(\n              \"Model 1 includes no other covariates, model 2 includes body mass,\",\n              \"and model 3 includes body mass and island effects\"\n            )\n          ))\n\n\n\n\n\n\n\n\n\nLecture 1: Reproducibility and Robustness\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\n\nLecture 2: Regression (part 2!)\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  link to repository \n\n\n\n\n\n\nLecture 3: Data linkage methods\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs   link to follow along code\n\n\n\n\n\n\nBrown et al Response and Reproduction of Onikye et al\n\n\n\n\n\nPreface\nIn 2021 Brown et al published an article titled A Reproduction of the Results of Onyike et al. (2003) in Meta-Psychology, a journal that is free, open-access and conducts open peer review. The Onikye et al. article they reproducing, Is obesity associated with major depression? Results from the Third National Health and Nutrition Examination Survey, was published in the American Journal of Epidemiology has been cited 1159+ times according to Google Scholar.\nI want to point out an interesting section from the About page describing the Meta-Psychology journal that you might keep in mind as you read on:\n\nPrior to publication, all statistical analyses are reproduced by our statistical reproduction team, which consists of the Statistical Editor and our editorial assistant. This makes the article eligible for the reproducibility badge.\n\nRecommended Reading\nPlease read the article by Brown et al (https://open.lnu.se/index.php/metapsychology/article/view/2071).\nAbstract repeated here as a teaser:\n\nOnyike et al. (2003) analyzed data from a large-scale US-American data set, the Third National Health and Nutrition Examination Survey (NHANES-III), and reported an association between obesity and major depression, especially among people with severe obesity. Here, we report the results of a detailed replication of Onyike et al.’s analyses. While we were able to reproduce the majority of these authors’ descriptive statistics, this took a substantial amount of time and effort, and we found several minor errors in the univariate descriptive statistics reported in their Tables 1 and 2. We were able to reproduce most of Onyike et al.’s bivariate findings regarding the relationship between obesity and depression (Tables 3 and 4), albeit with some small discrepancies (e.g., with respect to the magnitudes of standard errors). On the other hand, we were unable to reproduce Table 5, containing Onyike et al.’s findings with respect to the relationship between obesity and depression when controlling for plausible confounding variables—arguably the paper’s most important results—because some of the included predictor variables appear to be either unavailable, or not coded in the way reported by Onyike et al., in the public NHANES-III data sets. We discuss the implications of our findings for the transparency of reporting and the reproducibility of published results.\n\nTheir code is freely, publicly accessible on OSFHOME, a file storage service provided by the Open Science Framework from the Center for Open Science.\n\nBrown et al’s code+file repository: https://osf.io/j32yw/\nDownload their code+files (direct link): https://files.osf.io/v1/resources/j32yw/providers/osfstorage/?zip=\n\nNote that in order to run their code, you will either want to a) make a new R project in the folder with their code on your computer, or b) open a new RStudio window, open up their .R file, and use setwd('filepath/goes/here/') to make sure your R session can run their R code.\nConsider the following questions:\n\nDo you believe that the results Brown et al. have shared are more likely to be correct than those that Onikye et al published? If so, why? If not, why not?\n\nWhat do you find compelling about their re-analysis and code?\nWhat do you find lacking about their re-analysis and code?\n\nHow do you think the non-reproducibility of Onikye et al.’s article could have been avoided?\nWhen, if at all, do you think articles should be required to share code and data?\n\nWhat about in situations where the data relates to private or sensitive data?\nWhat about in situations where the subject matter is highly politically charged and there might be malicious actors who could see shared data and code as additional surface area to attack?\n\nHas reading this article made you more skeptical of research publications that don’t share code?\nDo you think for articles where code & data are too sensitive to be shared, is there an alternative process that would make you similarly confident in the stated results?\n\nAn important aside\nThis isn’t a class about stigma and health, but I think being in a Population Health Science program, it’s important to leave the breadcrumbs here for you to do your own followup reading and learning.\nBecause the articles in this homework discuss body-weight and health, I want to emphatically point out that this subject matter is not at all cut and dry. It’s important to acknowledge that:\n\nWeight-based stigma is real and causes harm to health through multiple mechanisms including at least discrimination and health care practitioners’ attitudes and behaviors:\n\nhttps://ajph.aphapublications.org/doi/full/10.2105/AJPH.2009.159491\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/obr.12266\n\nThe decision by health organizations to classify obesity as a “disease” is debated:\n\nhttps://www.healthline.com/health/is-obesity-a-disease\n\nThe language and terminology that we use can perpetuate stigma:\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC5051141/?report=classic\nhttps://news.yale.edu/2012/07/12/choosing-words-wisely-when-talking-patients-about-their-weight\n\n\nIf anything, what I hope you take away from this aside is that data do not speak for themselves, but rather are subject to interpretation and leave room for either the perpetuation or casting aside of pre-existing biases (See “Data Never Speak for Themselves” from Nancy Krieger’s article Structural Racism, Health Inequities, and the Two-Edged Sword of Data: Structural Problems Require Structural Solutions). It’s not enough to engage with open-science practices and leverage sophisticated statistical analyses made possible in programs like R; instead, it’s necessary to combine advances in the state of the art in computing with advances in our conceptual frameworks to do science that can truly shift narratives in ways that benefit marginalized groups.\n\n\n\n\n\n\n\n\n\nVideo Recording\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording"
  },
  {
    "objectID": "wi24/day6.html",
    "href": "wi24/day6.html",
    "title": "Day 6",
    "section": "",
    "text": "Outline of topics:\n\nR Markdown\nDebugging\nTime to work on final project\n\n\n\n\n\n\n\nLecture 1: R Markdown\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nLecture 2: Debugging\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen   link to slide PDFs  \n\n\n\n\n\n\nVideo Recording from Last Year"
  },
  {
    "objectID": "wi24/day3.html",
    "href": "wi24/day3.html",
    "title": "Day 3",
    "section": "",
    "text": "Outline of topics:\n\nLecture: Intro to dplyr\nLecture: Cleaning Text Data\nActivity: Manipulating Data\nLecture: Writing Functions\nActivity: Functions\n\n\n\n\n\n\n\nLecture 1: Intro to dplyr\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \nlink to slides pdf\n\n\n\n\n\n\nLecture 2: Cleaning Text Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\nlink to slides pdf\n\n\n\n\n\n\nActivity: Cleaning Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\nlink to slides pdf\n\n\n\n\n\n\nLecture 3: Functions\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\nlink to slides pdf\n\n\n\n\n\n\nVideo Recording\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast Year’s Video Recording"
  },
  {
    "objectID": "wi23/day1.html#monday-january-9th",
    "href": "wi23/day1.html#monday-january-9th",
    "title": "Day 1 — Monday, January 9th, 2023",
    "section": "",
    "text": "1:30-1:40 Welcome to ID529\n1:40-2:10 Introductory Lecture: Course Details\n2:10-2:40 Live Demonstration: Modern Data Science Practices in an R Project Based Workflow\n2:40-2:55 Activity: Q&A + Group reflection on principles shown in the demonstration\n2:55-3:10 Lecture: Introduce the Final Presentations Format\n3:10-3:15 Break\n3:15-3:50: Intro to RStudio and R\n3:50-4:05: Discussion and Self-Introductions\n4:05-4:45: Lecture: Intro to Git and GitHub\n4:45-5:00: Demo of how to do the homework\n5:00-5:05: Positive Affirmations\n5:05-5:30 Activity: Setup GitHub accounts + work on the homework + peruse recommended materials + chat with classmates\n\n\n\n\nArticles:\n\nThe Introduction Chapter to R for Data Science: https://r4ds.had.co.nz/explore-intro.html (just one page)\nExcuse me, do you have a moment to talk about version control? by Jennifer Bryan: https://peerj.com/preprints/3159/\nTutorial: Getting Started with R and RStudio: https://www.dataquest.io/blog/tutorial-getting-started-with-r-and-rstudio/\nQuickstart from GitHub: https://docs.github.com/en/get-started/quickstart/hello-world\n\nVideos:\n\nRStudio for the Total Beginner, HRAnalytics101: https://www.youtube.com/watch?v=FIrsOBy5k58\nIf you haven’t already installed R and RStudio, you’ll want to do that, and you can do that by following the instructions here:\n\nInstall R: https://vimeo.com/203516510\nInstall RStudio: https://vimeo.com/203516968\n\n\n\n\n\n\n\nWrite a bio for yourself and include a picture!\nComplete the intro to course survey\nCheck that your R and RStudio installations are working on your computer"
  },
  {
    "objectID": "wi23/day2.html#tuesday-january-10th",
    "href": "wi23/day2.html#tuesday-january-10th",
    "title": "Day 2 — Tuesday, January 10th, 2023",
    "section": "",
    "text": "1:30-2:00 Lecture: Intro to R Programming (including conditionals, control flow, etc.)\n2:00-2:15 Activity: learnr Tutorial on Conditionals and Control Flow\n2:15-2:45 Lecture: Data Dictionaries and Documentation\n2:45-3:00 Activity: Q&A + Discussion\n3:00-3:05 Break\n3:05-3:35 Lecture: Reading in data of various formats\n3:35-4:30 Lecture: Intro to ggplot2 (common types of figures, faceting, legends, patchwork, and saving figures)\n4:30-4:50 Discussion: What are the ingredients to a ggplot? What makes an effective data visualization?\n4:50-5:10 Demonstration of how to do the homework\n5:10-5:30 Time to work on homework, chat with classmates, peruse recommended materials, engage in self-affirmation\n\n\n\n\nRead in a dataset of your choice [we will give you some example datasets you can use] and create a few figures using ggplot2. We want to see students include titles, subtitles, captions, data sources, legends, etc.\n\nThe figures should include one univariate figure, one bivariate figure, and one figure using facet_wrap or facet_grid\nIf you’re feeling extra, have fun stylizing your plots! Go wild! Try to change up the background, fonts, etc.\n\n\n\n\n\n\nOur learnr tutorial on Conditionals, Control Flow, and Logic in R\nSmithsonian Data Management and Best Practices — Describing Your Data: Data Dictionaries\n\nhttps://library.si.edu/sites/default/files/tutorial/pdf/datadictionaries20180226.pdf\n\nU.S. Geological Survey, Data Dictionaries\n\nhttps://www.usgs.gov/data-management/data-dictionaries\n\nSkim the readr cheatsheet:\n\nhttps://raw.githubusercontent.com/rstudio/cheatsheets/main/data-import.pdf\nKeep in mind, your goal shouldn’t be to memorize everything, but rather to get a sense of what functionality is available to you, and how you could reference this cheatsheet or follow up on its contents to make use of it.\n\nFundamentals of Data Visualization, Chapter 2, Visualizing data: Mapping data onto aesthetics:\n\nhttps://clauswilke.com/dataviz/aesthetic-mapping.html\n\nFundamentals of Data Visualization, Chapter 17, The principle of proportional ink:\n\nhttps://clauswilke.com/dataviz/proportional-ink.html\n\n[Video] Introduction to ggplot2 https://www.youtube.com/watch?v=UiuA5sBEcFk\n[Video] BeginneR Workshop https://www.youtube.com/watch?v=7kuPnVZcot0 [lecture starts around 20:00]\n\nCheck the video description for the code files\n\n[Video] Intro to Git and GitHub https://www.youtube.com/watch?v=u4LIpYC0Yaw\n\nTruly extra reading for those interested in advancing their conceptual understanding of ggplot2 and the possibilities in data visualization:\n\nA Layered Grammar of Graphics, by Hadley Wickham http://vita.had.co.nz/papers/layered-grammar.pdf\nStart to get familiar with the ggplot2 book. We recommend starting with subsection 1.2 “What is the grammar of graphics?” here: https://ggplot2-book.org/introduction.html#what-is-the-grammar-of-graphics\nThe R Graph Gallery: https://r-graph-gallery.com/index.html\n\nWhat you can expect from the instructional team:\n\nWe will be reading your bios and working on sorting you into groups for the final presentation topics."
  },
  {
    "objectID": "wi23/day3.html#wednesday-january-11th",
    "href": "wi23/day3.html#wednesday-january-11th",
    "title": "Day 3 — Wednesday, January 11th, 2023",
    "section": "",
    "text": "1:30-2:00 Lecture: R Projects\n2:00-2:50 Lecture: Intro to dplyr\n2:50-3:10 Activity: Work on dplyr learnr tutorial in groups\n3:10-3:15 Break\n3:15-3:45 Lecture: Cleaning Text Data\n3:45-4:10 Lecture: Writing Functions\n4:10-4:30 Activity: Write functions together\n4:30-4:45 Activity: Discussion Q&A from ggplot2 Homework\n4:45-4:55 Survey: Checking in on Pacing\n4:55-5:10 Demonstration of how to do the homework\n5:10-5:30 Time to work on homework, chat with classmates, peruse recommended materials\n\n\n\n\nOn Projects:\n\nTidyverse Blog, Project-Oriented Workflow by Jenny Bryan: https://www.tidyverse.org/blog/2017/12/workflow-vs-script/\nR for Data Science, Chapter 8: https://r4ds.had.co.nz/workflow-projects.html\nProject-Oriented Workflow, Jenny Bryan https://www.tidyverse.org/blog/2017/12/workflow-vs-script/\n\nOn dplyr, cleaning text, and writing functions\n\nR for Data Science, Chapter 5 Data Transformation: https://r4ds.had.co.nz/transform.html\nR for Data Science, Chapter 14 Strings: https://r4ds.had.co.nz/strings.html\nR for Data Science, Chapter 19 Functions: https://r4ds.had.co.nz/functions.html\n\n\n\n\n\n\nNo homework"
  },
  {
    "objectID": "wi23/day4.html#thursday-january-12th",
    "href": "wi23/day4.html#thursday-january-12th",
    "title": "Day 4 — Thursday, January 12th, 2023",
    "section": "",
    "text": "1:30-2:00 Lecture: Diverse Data Sources (APIs [tidycensus, WHO, World Bank, qualtRics], scraping web data, tabulizer, tesseract, datapasta)\n2:00-2:20 Discussion: What kind of sources are students interested in using in their research or future work?\n2:20-2:50 Lecture: How to handle factors and date-times\n2:50-3:00 Break\n3:00-3:30 Lecture: Working with Regression Model Objects: constructing and analyzing them\n3:30-4:15 Activity: Working with Regression Models in R\n4:15-4:45 Lecture: Creating maps in R\n4:45-5:00 Lecture: Reproducible Examples for Getting Help\n5:00-5:30 Time to work on final presentation materials together, peruse recommended materials, chat with classmates\n\n\n\n\nFit and report on a regression model including categorical (factor) variables\nPeer Review for Homework 2\n\n\n\n\nRemember! You don’t have to read all of this! Just focus on what’s most useful to you:\n\nTidy Data by Hadley Wickham https://vita.had.co.nz/papers/tidy-data.pdf\nDiverse Data Sources\n\nThe readme to the datapasta package: https://github.com/MilesMcBain/datapasta\nAnalyzing US Census Data by Kyle Walker, Chapter 2: An introduction to tidycensus: https://walker-data.com/census-r/an-introduction-to-tidycensus.html\nThe readr cheatsheet: https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-import.pdf\nWorking with Qualtrics Data - Part 1: Importing Data, ROpenSci https://ropensci.org/blog/2022/08/02/working-with-qualtrics-data-importing/\n\nHandling factors and date-times in R:\n\nChapter 15: Factors, R for Data Science by Hadley Wickham and Garrett Grolemund https://r4ds.had.co.nz/factors.html\nChapter 16: Dates and Times, R for Data Science by Hadley Wickham and Garrett Grolemund https://r4ds.had.co.nz/dates-and-times.html\nForcats cheatsheet https://raw.githubusercontent.com/rstudio/cheatsheets/main/factors.pdf\nLubridate cheatsheet https://raw.githubusercontent.com/rstudio/cheatsheets/main/lubridate.pdf\n\nWorking with Regression Models:\n\nIntroduction to broom https://broom.tidymodels.org/articles/broom.html\nA nice introduction to linear model diagnostics plots: https://book.stat420.org/model-diagnostics.html\nInterpretation of R’s lm() output: https://stats.stackexchange.com/questions/5135/interpretation-of-rs-lm-output\n\nMapping:\n\nChapter 8 Plotting Spatial Data, Spatial Data Science https://r-spatial.org/book/08-Plotting.html\n\nThis focuses more on sf which is the most modern and increasingly most popular paradigm for working with spatial data in R\n\nChapter 9 Making Maps with R, Geocomputation with R https://geocompr.robinlovelace.net/adv-map.html\n\nThis chapter has a lot of focus on tmap, a package for creating thematic maps"
  },
  {
    "objectID": "wi23/day6.html#tuesday-january-17th",
    "href": "wi23/day6.html#tuesday-january-17th",
    "title": "Day 6 — Tuesday, January 17th, 2023",
    "section": "",
    "text": "1:30-1:50 Activity: Discussion of Onikye et al reproduction article\n1:50-2:10 Lecture: Introduction to R Packages\n2:10-2:30 Demonstration of how to create R packages that standardize data loading and cleaning processes\n2:30-3:00 Lecture: How to use R Markdown to produce reproducible reports including tables, visualizations, and inline-quantitative statements.\n3:00-3:10 Break\n3:10-3:30 Activity: Experiment with different R Markdown features\n3:30-3:50 Lecture: Advice for Debugging\n3:50-4:10 Activity: Debugging\n4:10-4:30 Activity: Getting Help Online\n4:30-4:45 Demonstration of how to do the homework\n4:45-5:30 Time to do the homework, work on the final project together, peruse recommended materials\n\n\n\n\nUse R Markdown to document some exploratory data analyses\n\n\n\n\n\nR Packages:\n\nRead Karl Broman’s Why write an R package?\nFamiliarize yourself with what’s in the R Packages book: https://r-pkgs.org/ — having a rough familiarity with the different parts will be helpful. Our suggestion here is to try and approach this more in terms of “what are the ingredients in a good R Package?” rather than trying to learn how to craft all of those ingredients from the ground up immediately.\n\nR Markdown:\n\nCheck out the Get Started for R Markdown, especially the ~1 minute video intro on the first page: https://rmarkdown.rstudio.com/lesson-1.html\nHow R Helps Airbnb Make the Most of Its Data\nIf you find yourself loving R Markdown, you may find the R Markdown Cookbook useful, but it is incredibly comprehensive and we’d suggest it’s better to reference as you need it than to try to read it cover-to-cover."
  },
  {
    "objectID": "wi23/day7.html#wednesday-january-18th",
    "href": "wi23/day7.html#wednesday-january-18th",
    "title": "Day 7 — Wednesday, January 18th, 2023",
    "section": "",
    "text": "1:30-2:00 Lecture: A Data Analysis from Start to Finish\n2:00-2:30 Lecture: Longitudinal Data Analysis\n2:30-3:00 Lecture: Best practices for reporting on missing data\n3:00-3:30 Lecture: Intro to accessible exploratory data analysis methods: Correlation, principal components analysis, variable importance\n3:30-3:40 Break\n3:40-4:00 Discussion: What are the ethical principles involved in data analysis? What are the risks involved?\n4:00-4:30 Lecture: Clean Code and Considerate Coding\n4:30-5:30 Free time to work together on the final project, chat with classmates, peruse recommended materials\n\n\n\n\nPeer Review Homework 5\n\n\n\n\n\nHarms and Ethics in Data Science and Machine Learning:\n\nThe Data Science Ethics chapter from the Modern Data Science with R book: https://mdsr-book.github.io/mdsr2e/ch-ethics.html"
  },
  {
    "objectID": "wi23/day8.html#thursday-january-19th",
    "href": "wi23/day8.html#thursday-january-19th",
    "title": "Day 8 — Thursday, January 19th, 2023",
    "section": "",
    "text": "1:30-2:00 Lecture/Demo: Principles for Data Analysis from Start to Finish\n2:00-2:30 Lecture: Functional Programming\n2:30-3:00 Discussion + Demo: When does it make sense to use functional programming?\n3:00-3:10 Break\n3:10-3:40 Lecture: [Students’ Choice]\n3:40-4:10 Lecture: How to Keep Growing as a Programmer (and stay up to date)\n4:10-4:20 Details about turning in your final presentations\n4:20-5:30 Positive affirmations, free time to work together on final projects\n\n\n\n\nWork with classmates to finalize presentations and turn them in\n\n\n\n\n\nHadley Wickham on Many Models: https://youtu.be/cU0-NrUxRw4"
  },
  {
    "objectID": "wi23/day9.html#friday-january-20th",
    "href": "wi23/day9.html#friday-january-20th",
    "title": "Day 9 — Friday, January 19th, 2023",
    "section": "",
    "text": "1:30-4:30 Final Presentations:\n\nStudents will be divided into 10 groups with 10-12 minutes presentation time and 3-5 minutes for feedback from the instructional team and Q&A from the audience.\n15 minutes × 10 groups = ~2.5 hours\nwe’ll make sure to take some breaks between every few groups\n\n4:30-5:00 Lecture: Recap of Key Takeaways\n5:00-5:30:\n\nMake sure you’ve uploaded your presentation!\nFeedback and Course Evaluations\n\n\nEnjoy being done with the class and go on to do great things with your newly learned R skills!"
  },
  {
    "objectID": "wi23/day5.html#friday-january-13th",
    "href": "wi23/day5.html#friday-january-13th",
    "title": "Day 5 — Friday, January 13th, 2023",
    "section": "",
    "text": "1:30-2:00 Lecture: Why reproducibility and robustness are important principles in science and data analysis and acknowledging the pressures in academia that push people away from reproducible science\n2:00-2:15 Discussion\n2:15-2:45 Lecture: Visualizing and Reporting on Regression Models\n2:45-3:05 Lecture: Data Linkage Methods\n3:05-3:25 Activity: Working with Joins\n3:25-3:35 Break\n3:35-4:00 Activity: Hallway QR Code Challenges\n4:00-4:15 Lecture: Introduction of the Brown et al (partial) reproduction of Onikye et al’s results\n4:15-4:30 Homework demonstration\n4:30-5:25 Time to work on homework + chat together + work on final projects\n5:25-5:30 Giveaway for a Copy of R for Data Science\n5:30 Meet Hodu!\n\n\n\n\nRead the Brown et al reproduction of Onikye et al, run their code, and fill out the worksheet\n\nhttps://open.lnu.se/index.php/metapsychology/article/view/2071\nhttps://osf.io/j32yw/\n\nPeer review for homework 3\n\n\n\n\n\nReproducibility:\n\nDraw Me A Project https://masalmon.eu/2021/06/30/r-projects/\nReproducibility of Scientific Results https://plato.stanford.edu/entries/scientific-reproducibility/\nBest Practices for Scientific Computing https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745\nGood Enough Practices for Scientific Computing https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510\nReplicability, Robustness, and Reproducibility in Psychological Science https://pure.uvt.nl/ws/portalfiles/portal/59415163/MTO_Nuijten_replicability_robustness_and_reproducibility_Annual_Review_of_Psy_2022.pdf\nA manifesto for reproducible science https://www.nature.com/articles/s41562-016-0021\n\nRegression Modeling:\n\nIntroduction to Poisson Regression, Beyond Multiple Linear Regression https://bookdown.org/roback/bookdown-BeyondMLR/ch-poissonreg.html\nPoisson Regression https://rpubs.com/franzbischoff/poisson_regression\nLogistic Regression, Beyond Multiple Linear Regression https://bookdown.org/roback/bookdown-BeyondMLR/ch-logreg.html"
  },
  {
    "objectID": "day2.html#recordings",
    "href": "day2.html#recordings",
    "title": "Day 2",
    "section": "Recordings",
    "text": "Recordings\n\n\n\n\n\n\nVideo Recording from 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Recording from 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Recording from 2023"
  },
  {
    "objectID": "day2.html#slides",
    "href": "day2.html#slides",
    "title": "Day 2",
    "section": "Slides",
    "text": "Slides\n\n\n\n\n\n\nLecture 1: Programming with R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \n\n\n\n\n\n\nLecture 2: Project Workflows in R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \n\n\n\n\n\n\nLecture 3: Reading in Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \n\n\n\n\n\n\nLecture 4: Intro to ggplot2\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \n\n\n\n\n\n\nActivity: Data Visualization\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen"
  },
  {
    "objectID": "day4.html#slides",
    "href": "day4.html#slides",
    "title": "Day 4",
    "section": "Slides",
    "text": "Slides\n\n\n\n\n\n\nLecture 1: Diverse Data Sources\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \n\n\n\n\n\n\nLecture 2: Factors and Date-times\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\nlink to follow along code \n\n\n\n\n\n\nLecture 3: Regression\n\n\n\n\n\n\n\n\n\n\nlink to fullscreen  link to repository\n\n\n\n\n\n\nLecture 4: Creating maps in R\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\n\n\n\n\n\n\nLecture 5: Reproducible examples for getting help in R\n\n\n\n\n\n \n\n\n\nlink to view slides fullscreen"
  },
  {
    "objectID": "day4.html#recordings",
    "href": "day4.html#recordings",
    "title": "Day 4",
    "section": "Recordings",
    "text": "Recordings\n\n\n\n\n\n\nVideo Recording from 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Recording from 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Recording from 2023"
  },
  {
    "objectID": "day3.html#slides",
    "href": "day3.html#slides",
    "title": "Day 3",
    "section": "Slides",
    "text": "Slides\n\n\n\n\n\n\nLecture 1: Intro to dplyr\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \n\n\n\n\n\n\nLecture 2: Cleaning Text Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen\n\n\n\n\n\n\nActivity: Cleaning Data\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen \nlink to github repository\n\n\n\n\n\n\nLecture 3: Functions\n\n\n\n\n\n\n\n\n\n\nlink to view slides fullscreen"
  },
  {
    "objectID": "day3.html#recordings",
    "href": "day3.html#recordings",
    "title": "Day 3",
    "section": "Recordings",
    "text": "Recordings\n\n\n\n\n\n\nVideo Recording from 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Recording from 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Recording from 2023"
  }
]